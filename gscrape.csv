,Blog Title,Blog Link,Blog Content,Sub Headings,Hyperlinks
0,Machine Learning Terminology,https://www.python-course.eu/machine_learning_terminology.php,"Machine Learning with Python: Machine Learning Terminology 
 
 
 
 - remove in and out prompt from ipython notebook 
%%HTML

div.prompt {display:none}

 - 
 
 
 
 
 Python Machine Learning Tutorial 
 
  Begin Top Menu  
 
 Home Python 2 Tutorial Python 3 Tutorial Advanced Topics Numerical Programming Machine Learning Tkinter Tutorial Contact 
 
  End Top Menu  
 Machine Learning 
 
 
 Machine Learning Terminology k-nearest Neighbor Classifier Neural Networks from Scratch in Python Neural Network in Python using Numpy Backpropagation in Neural Networks Confusion Matrix Training and Testing with MNIST Dropout Neural Networks Neural Networks with Scikit Machine Learning with Scikit and Python Introduction Naive Bayes Classifier Naive Bayes Classifier with Scikit Introduction into Text Classification using Naive Bayes Python Implementation of Text Classification Decision Trees Regression Trees Random Forests Boosting Algorithm Principal Component Analysis Linear Discriminant Analysis Expectation Maximization and Gaussian Mixture Model Introduction into TensorFlow 
 
 
 
 Help Needed 

This website is free of annoying ads. We want to keep it like this. You can help with your donation:
 
 
 
 
 
 
 
 
 The need for donations 
 
 
 
 
 
 
 
This website is created by: 
 Python Training Courses in Toronto, Canada 
 
On site trainings in Europe, Canada and the US.
 
 
 
  Dieses Tag dort einfügen, wo die +1-Schaltfläche dargestellt werden soll  
 
 
 Help Needed 

This website is free of annoying ads. We want to keep it like this. You can help with your donation:
 
 
 
 
 
 
 
 
 
 The need for donations 
 
 Job Applications 
 
 Python Lecturer 
 bodenseo is looking for a new trainer and software developper. You need to live in Germany and know German. Interested? Find out  more !
 Python Programmer 
We are looking for a qualified Python programmer to further improve our website. This is a work from home job, wherever you live in the world! 
If you think that you are the right person or if you have further questions, please do not hesitate to  contact us .
 
 
 
 Bernd Klein on Facebook 
 
 
 
Search this website:
 
 
 
 Classroom Training Courses 
 
This website contains a free and extensive online tutorial by Bernd Klein, using
material from his classroom Python training courses Python classes 
 
 © kabliczech - Fotolia.com Quote of the Day: ""The question of whether a computer can think is no more interesting than the 
question of whether a submarine can swim."" (Edsger Wybe Dijkstra)   Help Needed 
 
 
 
 
 
 The need for donations Data Protection Declaration Data Protection Declaration 
 Next Chapter:  k-nearest Neighbor Classifier 
 
 
 
 
 Machine Learning Terminology 
 Classifier A program or a function which maps from unlabeled instances to  classes is called a classifier. 
 Confusion Matrix A confusion matrix, also called a contingeny table or error matrix,
is used to visualize the performance of a classifier. 
 The columns of the matrix represent the instances of the predicted  classes and the rows represent the instances of the actual class. (Note: It can be the other way around as well.) 
 In the case of binary classification the table has 2 rows and 2 columns. 
 Example: 
 
 
 
 Confusion Matrix 
 Predicted classes 
 
 
 male 
 female 
 
 
 
 Actual 
classes 
 male 
 42 
 8 
 
 
 female 
 18 
 32 
 
 This means that the classifier correctly predicted a male person in 42 cases and it wrongly predicted 8 male instances as female.
It correctly predicted 32 instances as female. 18 cases had been wrongly predicted as male instead of female. 
 
 
 
 
 
 
 Accuracy (error rate) Accuracy is a statistical measure which is defined as the quotient of correct predictions made by a classifier divided by the sum of predictions made by the classifier. 
 The classifier in our previous example predicted correctly predicted 42 male instances and 32 female instance. 
 Therefore, the accuracy can be calculated by: 
 accuracy = $(42 + 32) / (42 + 8 + 18 + 32)$ 
 which is 0.72 
 Let's assume we have a classifier, which always predicts ""female"". We have an accuracy of 50 % in this case. 
 
 
 
 
 
 
 
 
 Confusion Matrix 
 Predicted classes 
 
 
 male 
 female 
 
 
 
 Actual 
classes 
 male 
 0 
 50 
 
 
 female 
 0 
 50 
 
 
 
 
 
 
 
 
 We will demonstrate the so-called accuracy paradox. 
 A spam recogition classifier is described by the following confusion matrix: 
 
 
 
 
 
 
 
 
 Confusion Matrix 
 Predicted classes 
 
 
 spam 
 ham 
 
 
 
 Actual 
classes 
 spam 
 4 
 1 
 
 
 ham 
 4 
 91 
 
 
 
 
 
 
 
 
 The accuracy of this classifier is (4 + 91) / 100, i.e. 95 %. 
 The following classifier predicts solely ""ham"" and has the same accuracy. 
 
 
 
 
 
 
 
 
 Confusion Matrix 
 Predicted classes 
 
 
 spam 
 ham 
 
 
 
 Actual 
classes 
 spam 
 0 
 5 
 
 
 ham 
 0 
 95 
 
 
 
 
 
 
 
 
 The accuracy of this classifier is 95%, even though it is not capable of recognizing any spam at all. 
 
 
 
 
 
 
 Precision and Recall 
 
 
 
 
 
 
 
 
 Confusion Matrix 
 Predicted classes 
 
 
 negative 
 positive 
 
 
 
 Actual 
classes 
 negative 
 TN 
 FP 
 
 
 positive 
 FN 
 TP 
 
 
 
 
 
 
 
 
 Accuracy: $(TN + TP)/(TN + TP + FN + FP)$ 
 Precision: $TP / (TP + FP)$ 
 Recall: $ TP / (TP + FN)$ 
 
 
 
 
 
 
 Supervised learning The machine learning program is both given the input data and the corresponding labelling. This means that the learn data has to be labelled by a human being beforehand. 
 Unsupervised learning No labels are provided to the learning algorithm. The algorithm has to figure out the a clustering of the input data. 
 Reinforcement learning A computer program dynamically interacts with its environment. This means that the program receives positive and/or negative feedback to improve it performance. 
 
 
 
 Next Chapter:  k-nearest Neighbor Classifier 
 
   © 2011 - 2019, Bernd Klein,
Bodenseo; 
Design by Denise Mitchinson adapted for python-course.eu by Bernd Klein "," None,None,None,None,None,None,None,None,None,None,None,None,", https://www.python-course.eu/http://www.python-kurs.eu/stellengesuch/Stellenanzeige.pdf
1,k-nearest Neighbor Classifier,https://www.python-course.eu/k_nearest_neighbor_classifier.php,"Machine Learning with Python: k-Nearest Neighbor Classifier in Python 
 
 
 
 - remove in and out prompt from ipython notebook 
%%HTML

div.prompt {display:none}

 - 
 
 
 
 
 Python Machine Learning Tutorial 
 
  Begin Top Menu  
 
 Home Python 2 Tutorial Python 3 Tutorial Advanced Topics Numerical Programming Machine Learning Tkinter Tutorial Contact 
 
  End Top Menu  
 Machine Learning 
 
 
 Machine Learning Terminology k-nearest Neighbor Classifier Neural Networks from Scratch in Python Neural Network in Python using Numpy Backpropagation in Neural Networks Confusion Matrix Training and Testing with MNIST Dropout Neural Networks Neural Networks with Scikit Machine Learning with Scikit and Python Introduction Naive Bayes Classifier Naive Bayes Classifier with Scikit Introduction into Text Classification using Naive Bayes Python Implementation of Text Classification Decision Trees Regression Trees Random Forests Boosting Algorithm Principal Component Analysis Linear Discriminant Analysis Expectation Maximization and Gaussian Mixture Model Introduction into TensorFlow 
 
 
 
 Help Needed 

This website is free of annoying ads. We want to keep it like this. You can help with your donation:
 
 
 
 
 
 
 
 
 The need for donations 
 
 
 
 
 k-Nearest Neighbor 

The k-NN is an instance-based classifier. The underlying idea is that the likelihood that two instances of the instance space belong to the same category or class increases with the proximity of the instance. Proximity or closeness can be defined with a   distance or similarity function. 

 Learning 
""Tell me and I forget, teach me and I may remember, involve me and I learn.""
 (Benjamin Franklin)
 
""The more I read, the more I acquire, the more certain I am that I know nothing.""
(Voltaire)
 
 
""You live and learn. At any rate, you live.""
(Douglas Adams, Mostly Harmless)
 
If learning means living, some computers live!
 
""In learning you will teach, and in teaching you will learn.""
 (Phil Collins)
 
 
This website is created by: 
 Python Training Courses in Toronto, Canada 
 
On site trainings in Europe, Canada and the US.
 
 
 
  Dieses Tag dort einfügen, wo die +1-Schaltfläche dargestellt werden soll  
 
 
 Help Needed 

This website is free of annoying ads. We want to keep it like this. You can help with your donation:
 
 
 
 
 
 
 
 
 
 The need for donations 
 
 Job Applications 
 
 Python Lecturer 
 bodenseo is looking for a new trainer and software developper. You need to live in Germany and know German. Interested? Find out  more !
 Python Programmer 
We are looking for a qualified Python programmer to further improve our website. This is a work from home job, wherever you live in the world! 
If you think that you are the right person or if you have further questions, please do not hesitate to  contact us .
 
 
 
 Bernd Klein on Facebook 
 
 
 
Search this website:
 
 
 
 Classroom Training Courses 
 
This website contains a free and extensive online tutorial by Bernd Klein, using
material from his classroom Python training courses Python classes 
 
 © kabliczech - Fotolia.com Quote of the Day: ""The digital revolution is far more significant than the invention of writing or even of printing.""  (Douglas Engelbart)
   Help Needed 
 
 
 
 
 
 The need for donations Data Protection Declaration Data Protection Declaration 
 Previous Chapter:  Machine Learning Terminology 
 Next Chapter:  Neural Networks from Scratch in Python 
 
 
 
 
 k-Nearest-Neighbor Classifier 
 ""Show me who your friends are and I’ll tell you who you are?"" 
 The concept of the k-nearest neighbor classifier can hardly be simpler described. This is an old saying, which can be found in many languages and many cultures. It's also metnioned in other words in the Bible: ""He who walks with wise men will be wise, but the companion of fools will suffer harm"" (Proverbs 13:20 ) 
 This means that the concept of the k-nearest neighbor classifier is part of our everyday life and judging: Imagine you meet a group of people, they are all very young, stylish and sportive. They talk about there friend Ben, who isn't with them. So, what is your imagination of Ben? Right, you imagine him as being yong, stylish and sportive as well. 
 If you learn that Ben lives in a neighborhood where people vote conservative and that the average income is above 200000 dollars a year?
Both his neighbors make even more than 300,000 dollars per year? What do you think of Ben? Most probably, you do not consider him to be an underdog and you may suspect him to be a conservative as well? 
 The principle behind nearest neighbor classification consists in finding a predefined number, i.e. the 'k' - of training samples closest in distance to a new sample, which has to be classified. The label of the new sample will be defined from these neighbors. k-nearest neighbor classifiers have a fixed user defined constant for the number of neighbors which have to be determined. There are also radius-based neighbor learning algorithms, which have a varying number of neighbors based on the local density of points, all the samples inside of a fixed radius. The distance can, in general, be any metric measure: standard Euclidean distance is the most common choice. Neighbors-based methods are known as non-generalizing machine learning methods, since they simply ""remember"" all of its training data. Classification can be computed by a majority vote of the nearest neighbors of the unknown sample. 
 The k-NN algorithm is among the simplest of all machine learning algorithms, but despite its simplicity, it has been quite successful in a large number of classification and regression problems, for example character recognition or image analysis. 
 Now let's get a little bit more mathematically: 
 The k-Nearest-Neighbor Classifier (k-NN) works directly on the learned samples, instead of creating rules compared to other classification methods. 
 Nearest Neighbor Algorithm: 
 Given a set of categories $\{c_1, c_2, ... c_n\}$, also called classes, e.g. {""male"", ""female""}.
There is also a learnset $LS$ consisting of labelled instances. 
 The task of classification consists in assigning a category or class to an arbitrary instance. If the instance $o$ is an element of $LS$, the label of the instance will be used. 
 Now, we will look at the case where $o$ is not in $LS$: 
 $o$ is compared with all instances of $LS$. A distance metric is used for comparison. 
We determine the $k$ closest neighbors of $o$, i.e. the items with the smallest distances. 
$k$ is a user defined constant and a positive integer, which is usually small. 
 The most common class of $LS$ will be assigned to the instance $o$. If k = 1, then the object is simply assigned to the class of that single nearest neighbor. 
 The algorithm for the k-nearest neighbor classifier is among the simplest of all machine learning algorithms. k-NN is a type of instance-based learning, or lazy learning, where the function is only approximated locally and all the computations are performed, when we do the actual classification. 
 k-nearest-neighbor from Scratch Preparing the Dataset 
 
 
 
 
 
 
 
 
 
 
 
 
 
 Before we actually start with writing a nearest neighbor classifier, we need to think about the data, i.e. the learnset. We will use the ""iris"" dataset provided by the datasets of the sklearn module. 
 The data set consists of 50 samples from each of three species of Iris 
 
 Iris setosa,  
 Iris virginica and  
 Iris versicolor.  
 
 Four features were measured from each sample: the length and the width of the sepals and petals, in centimetres. 
 
 
 
 
 
 
 
 
 import   numpy   as   np 
 from   sklearn   import   datasets 


 iris   =   datasets . load_iris () 
 iris_data   =   iris . data 
 iris_labels   =   iris . target 
 print ( iris_data [ 0 ],   iris_data [ 79 ],   iris_data [ 100 ]) 
 print ( iris_labels [ 0 ],   iris_labels [ 79 ],   iris_labels [ 100 ]) 
 
 
 
 
 
 
 
 
 
 [5.1 3.5 1.4 0.2] [5.7 2.6 3.5 1. ] [6.3 3.3 6.  2.5]
0 1 2
 
 
 
 
 
 
 
 
 
 We create a learnset from the sets above. We use permutation from np.random to split the data randomly. 
 
 
 
 
 
 
 
 
 np . random . seed ( 42 ) 
 indices   =   np . random . permutation ( len ( iris_data )) 
 n_training_samples   =   12 
 learnset_data   =   iris_data [ indices [: - n_training_samples ]] 
 learnset_labels   =   iris_labels [ indices [: - n_training_samples ]] 
 testset_data   =   iris_data [ indices [ - n_training_samples :]] 
 testset_labels   =   iris_labels [ indices [ - n_training_samples :]] 
 print ( learnset_data [: 4 ],   learnset_labels [: 4 ]) 
 print ( testset_data [: 4 ],   testset_labels [: 4 ]) 
 
 
 
 
 
 
 
 
 
 [[6.1 2.8 4.7 1.2]
 [5.7 3.8 1.7 0.3]
 [7.7 2.6 6.9 2.3]
 [6.  2.9 4.5 1.5]] [1 0 2 1]
[[5.7 2.8 4.1 1.3]
 [6.5 3.  5.5 1.8]
 [6.3 2.3 4.4 1.3]
 [6.4 2.9 4.3 1.3]] [1 2 1 1]
 
 
 
 
 
 
 
 
 
 The following code is only necessary to visualize the data of our learnset. Our data consists of four values per iris item, so we will reduce the data to three values by summing up the third and fourth value. This way, we are capable of depicting the data in 3-dimensional space: 
 
 
 
 
 
 
 
 
 # following line is only necessary, if you use ipython notebook!!! 
 % matplotlib  inline 

 import   matplotlib.pyplot   as   plt 
 from   mpl_toolkits.mplot3d   import   Axes3D 

 colours   =   ( ""r"" ,   ""b"" ) 
 X   =   [] 
 for   iclass   in   range ( 3 ): 
     X . append ([[],   [],   []]) 
     for   i   in   range ( len ( learnset_data )): 
         if   learnset_labels [ i ]   ==   iclass : 
             X [ iclass ][ 0 ] . append ( learnset_data [ i ][ 0 ]) 
             X [ iclass ][ 1 ] . append ( learnset_data [ i ][ 1 ]) 
             X [ iclass ][ 2 ] . append ( sum ( learnset_data [ i ][ 2 :])) 

 colours   =   ( ""r"" ,   ""g"" ,   ""y"" ) 

 fig   =   plt . figure () 
 ax   =   fig . add_subplot ( 111 ,   projection = '3d' ) 

 for   iclass   in   range ( 3 ): 
        ax . scatter ( X [ iclass ][ 0 ],   X [ iclass ][ 1 ],   X [ iclass ][ 2 ],   c = colours [ iclass ]) 
 plt . show () 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 Determining the Neighbors To determine the similarity between two instances, we need a distance function. In our example, the Euclidean distance is ideal: 
 
 
 
 
 
 
 
 
 def   distance ( instance1 ,   instance2 ): 
     # just in case, if the instances are lists or tuples: 
     instance1   =   np . array ( instance1 )  
     instance2   =   np . array ( instance2 ) 
    
     return   np . linalg . norm ( instance1   -   instance2 ) 

 print ( distance ([ 3 ,   5 ],   [ 1 ,   1 ])) 
 print ( distance ( learnset_data [ 3 ],   learnset_data [ 44 ])) 
 
 
 
 
 
 
 
 
 
 4.47213595499958
3.4190641994557516
 
 
 
 
 
 
 
 
 
 The function 'get_neighbors returns a list with 'k' neighbors, which are closest to the instance 'test_instance': 
 
 
 
 
 
 
 
 
 def   get_neighbors ( training_set ,  
                   labels ,  
                   test_instance ,  
                   k ,  
                   distance = distance ): 
     """""" 
     get_neighors calculates a list of the k nearest neighbors 
     of an instance 'test_instance'. 
     The list neighbors contains 3-tuples with   
     (index, dist, label) 
     where  
     index    is the index from the training_set,  
     dist     is the distance between the test_instance and the  
              instance training_set[index] 
     distance is a reference to a function used to calculate the  
              distances 
     """""" 
     distances   =   [] 
     for   index   in   range ( len ( training_set )): 
         dist   =   distance ( test_instance ,   training_set [ index ]) 
         distances . append (( training_set [ index ],   dist ,   labels [ index ])) 
     distances . sort ( key = lambda   x :   x [ 1 ]) 
     neighbors   =   distances [: k ] 
     return   neighbors 
 
 
 
 
 
 
 
 
 We will test the function with our iris samples: 
 
 
 
 
 
 
 
 
 for   i   in   range ( 5 ): 
     neighbors   =   get_neighbors ( learnset_data ,  
                               learnset_labels ,  
                               testset_data [ i ],  
                               3 ,  
                               distance = distance ) 
     print ( i ,  
           testset_data [ i ],  
           testset_labels [ i ],  
           neighbors ) 
    
 
 
 
 
 
 
 
 
 
 0 [5.7 2.8 4.1 1.3] 1 [(array([5.7, 2.9, 4.2, 1.3]), 0.14142135623730995, 1), (array([5.6, 2.7, 4.2, 1.3]), 0.17320508075688815, 1), (array([5.6, 3. , 4.1, 1.3]), 0.22360679774997935, 1)]
1 [6.5 3.  5.5 1.8] 2 [(array([6.4, 3.1, 5.5, 1.8]), 0.1414213562373093, 2), (array([6.3, 2.9, 5.6, 1.8]), 0.24494897427831783, 2), (array([6.5, 3. , 5.2, 2. ]), 0.3605551275463988, 2)]
2 [6.3 2.3 4.4 1.3] 1 [(array([6.2, 2.2, 4.5, 1.5]), 0.2645751311064586, 1), (array([6.3, 2.5, 4.9, 1.5]), 0.574456264653803, 1), (array([6. , 2.2, 4. , 1. ]), 0.5916079783099617, 1)]
3 [6.4 2.9 4.3 1.3] 1 [(array([6.2, 2.9, 4.3, 1.3]), 0.20000000000000018, 1), (array([6.6, 3. , 4.4, 1.4]), 0.2645751311064587, 1), (array([6.6, 2.9, 4.6, 1.3]), 0.3605551275463984, 1)]
4 [5.6 2.8 4.9 2. ] 2 [(array([5.8, 2.7, 5.1, 1.9]), 0.3162277660168375, 2), (array([5.8, 2.7, 5.1, 1.9]), 0.3162277660168375, 2), (array([5.7, 2.5, 5. , 2. ]), 0.33166247903553986, 2)]
 
 
 
 
 
 
 
 
 
 Voting to get a Single Result We will write a vote function now. This functions uses the class 'Counter' from collections to count the quantity of the classes inside of an instance list. This instance list will be the neighbors of course. The function 'vote' returns the most common class: 
 
 
 
 
 
 
 
 
 from   collections   import   Counter 

 def   vote ( neighbors ): 
     class_counter   =   Counter () 
     for   neighbor   in   neighbors : 
         class_counter [ neighbor [ 2 ]]   +=   1 
     return   class_counter . most_common ( 1 )[ 0 ][ 0 ] 
 
 
 
 
 
 
 
 
 We will test 'vote' on our training samples: 
 
 
 
 
 
 
 
 
 for   i   in   range ( n_training_samples ): 
     neighbors   =   get_neighbors ( learnset_data ,  
                               learnset_labels ,  
                               testset_data [ i ],  
                               3 ,  
                               distance = distance ) 
     print ( ""index: "" ,   i ,  
           "", result of vote: "" ,   vote ( neighbors ),  
           "", label: "" ,   testset_labels [ i ],  
           "", data: "" ,   testset_data [ i ]) 
 
 
 
 
 
 
 
 
 
 index:  0 , result of vote:  1 , label:  1 , data:  [5.7 2.8 4.1 1.3]
index:  1 , result of vote:  2 , label:  2 , data:  [6.5 3.  5.5 1.8]
index:  2 , result of vote:  1 , label:  1 , data:  [6.3 2.3 4.4 1.3]
index:  3 , result of vote:  1 , label:  1 , data:  [6.4 2.9 4.3 1.3]
index:  4 , result of vote:  2 , label:  2 , data:  [5.6 2.8 4.9 2. ]
index:  5 , result of vote:  2 , label:  2 , data:  [5.9 3.  5.1 1.8]
index:  6 , result of vote:  0 , label:  0 , data:  [5.4 3.4 1.7 0.2]
index:  7 , result of vote:  1 , label:  1 , data:  [6.1 2.8 4.  1.3]
index:  8 , result of vote:  1 , label:  2 , data:  [4.9 2.5 4.5 1.7]
index:  9 , result of vote:  0 , label:  0 , data:  [5.8 4.  1.2 0.2]
index:  10 , result of vote:  1 , label:  1 , data:  [5.8 2.6 4.  1.2]
index:  11 , result of vote:  2 , label:  2 , data:  [7.1 3.  5.9 2.1]
 
 
 
 
 
 
 
 
 
 We can see that the predictions correspond to the labelled results, except in case of the item with the index 8. 
 'vote_prob' is a function like 'vote' but returns the class name and the probability for this class: 
 
 
 
 
 
 
 
 
 def   vote_prob ( neighbors ): 
     class_counter   =   Counter () 
     for   neighbor   in   neighbors : 
         class_counter [ neighbor [ 2 ]]   +=   1 
     labels ,   votes   =   zip ( * class_counter . most_common ()) 
     winner   =   class_counter . most_common ( 1 )[ 0 ][ 0 ] 
     votes4winner   =   class_counter . most_common ( 1 )[ 0 ][ 1 ] 
     return   winner ,   votes4winner / sum ( votes ) 
 
 
 
 
 
 
 
 
 
 
 for   i   in   range ( n_training_samples ): 
     neighbors   =   get_neighbors ( learnset_data ,  
                               learnset_labels ,  
                               testset_data [ i ],  
                               5 ,  
                               distance = distance ) 
     print ( ""index: "" ,   i ,  
           "", vote_prob: "" ,   vote_prob ( neighbors ),  
           "", label: "" ,   testset_labels [ i ],  
           "", data: "" ,   testset_data [ i ]) 
 
 
 
 
 
 
 
 
 
 index:  0 , vote_prob:  (1, 1.0) , label:  1 , data:  [5.7 2.8 4.1 1.3]
index:  1 , vote_prob:  (2, 1.0) , label:  2 , data:  [6.5 3.  5.5 1.8]
index:  2 , vote_prob:  (1, 1.0) , label:  1 , data:  [6.3 2.3 4.4 1.3]
index:  3 , vote_prob:  (1, 1.0) , label:  1 , data:  [6.4 2.9 4.3 1.3]
index:  4 , vote_prob:  (2, 1.0) , label:  2 , data:  [5.6 2.8 4.9 2. ]
index:  5 , vote_prob:  (2, 0.8) , label:  2 , data:  [5.9 3.  5.1 1.8]
index:  6 , vote_prob:  (0, 1.0) , label:  0 , data:  [5.4 3.4 1.7 0.2]
index:  7 , vote_prob:  (1, 1.0) , label:  1 , data:  [6.1 2.8 4.  1.3]
index:  8 , vote_prob:  (1, 1.0) , label:  2 , data:  [4.9 2.5 4.5 1.7]
index:  9 , vote_prob:  (0, 1.0) , label:  0 , data:  [5.8 4.  1.2 0.2]
index:  10 , vote_prob:  (1, 1.0) , label:  1 , data:  [5.8 2.6 4.  1.2]
index:  11 , vote_prob:  (2, 1.0) , label:  2 , data:  [7.1 3.  5.9 2.1]
 
 
 
 
 
 
 
 
 
 The Weighted Nearest Neighbour Classifier We looked only at k items in the vicinity of an unknown object „UO"", and had a majority vote. Using the majority vote has shown quite efficient in our previous example, but this didn't take into account the following reasoning: The farther a neighbor is, the more it ""deviates"" from the ""real"" result. Or in other words, we can trust the closest neighbors more than the farther ones. Let's assume, we have 11 neighbors of an unknown item UO. The closest five neighbors belong to a class A and all the other six, which are farther away belong to a class B. What class should be assigned to UO? The previous approach says B, because we have a 6 to 5 vote in favor of B. On the other hand the closest 5 are all A and this should count more. 
 To pursue this strategy, we can assign weights to the neighbors in the following way:
The nearest neighbor of an instance gets a weight $1 / 1$, the second closest gets a weight of $1 / 2$ and then going on up to $1/k$ for the farthest away neighbor. 
 This means that we are using the harmonic series as weights: 
$$\sum_{i}^{k}{1/(i+1)} = 1 + \frac{1}{2} + \frac{1}{3} + ... + \frac{1}{k}$$ We implement this in the following function: 
 
 
 
 
 
 
 
 
 def   vote_harmonic_weights ( neighbors ,   all_results = True ): 
     class_counter   =   Counter () 
     number_of_neighbors   =   len ( neighbors ) 
     for   index   in   range ( number_of_neighbors ): 
         class_counter [ neighbors [ index ][ 2 ]]   +=   1 / ( index + 1 ) 
     labels ,   votes   =   zip ( * class_counter . most_common ()) 
     #print(labels, votes) 
     winner   =   class_counter . most_common ( 1 )[ 0 ][ 0 ] 
     votes4winner   =   class_counter . most_common ( 1 )[ 0 ][ 1 ] 
     if   all_results : 
         total   =   sum ( class_counter . values (),   0.0 ) 
         for   key   in   class_counter : 
              class_counter [ key ]   /=   total 
         return   winner ,   class_counter . most_common () 
     else : 
         return   winner ,   votes4winner   /   sum ( votes ) 
        
 
 
 
 
 
 
 
 
 
 
 for   i   in   range ( n_training_samples ): 
     neighbors   =   get_neighbors ( learnset_data ,  
                               learnset_labels ,  
                               testset_data [ i ],  
                               6 ,  
                               distance = distance ) 
     print ( ""index: "" ,   i ,  
           "", result of vote: "" ,  
           vote_harmonic_weights ( neighbors , 
                                 all_results = True )) 
 
 
 
 
 
 
 
 
 
 index:  0 , result of vote:  (1, [(1, 1.0)])
index:  1 , result of vote:  (2, [(2, 1.0)])
index:  2 , result of vote:  (1, [(1, 1.0)])
index:  3 , result of vote:  (1, [(1, 1.0)])
index:  4 , result of vote:  (2, [(2, 0.9319727891156463), (1, 0.06802721088435375)])
index:  5 , result of vote:  (2, [(2, 0.8503401360544217), (1, 0.14965986394557826)])
index:  6 , result of vote:  (0, [(0, 1.0)])
index:  7 , result of vote:  (1, [(1, 1.0)])
index:  8 , result of vote:  (1, [(1, 1.0)])
index:  9 , result of vote:  (0, [(0, 1.0)])
index:  10 , result of vote:  (1, [(1, 1.0)])
index:  11 , result of vote:  (2, [(2, 1.0)])
 
 
 
 
 
 
 
 
 
 The previous approach took only the ranking of the neighbors according to their distance in account. We can improve the voting by using the actual distance. To this purpos we will write a new voting function: 
 
 
 
 
 
 
 
 
 def   vote_distance_weights ( neighbors ,   all_results = True ): 
     class_counter   =   Counter () 
     number_of_neighbors   =   len ( neighbors ) 
     for   index   in   range ( number_of_neighbors ): 
         dist   =   neighbors [ index ][ 1 ] 
         label   =   neighbors [ index ][ 2 ] 
         class_counter [ label ]   +=   1   /   ( dist ** 2   +   1 ) 
     labels ,   votes   =   zip ( * class_counter . most_common ()) 
     #print(labels, votes) 
     winner   =   class_counter . most_common ( 1 )[ 0 ][ 0 ] 
     votes4winner   =   class_counter . most_common ( 1 )[ 0 ][ 1 ] 
     if   all_results : 
         total   =   sum ( class_counter . values (),   0.0 ) 
         for   key   in   class_counter : 
              class_counter [ key ]   /=   total 
         return   winner ,   class_counter . most_common () 
     else : 
         return   winner ,   votes4winner   /   sum ( votes ) 
 
 
 
 
 
 
 
 
 
 
 for   i   in   range ( n_training_samples ): 
     neighbors   =   get_neighbors ( learnset_data ,  
                               learnset_labels ,  
                               testset_data [ i ],  
                               6 ,  
                               distance = distance ) 
     print ( ""index: "" ,   i ,  
           "", result of vote: "" ,   vote_distance_weights ( neighbors , 
                                                       all_results = True )) 
 
 
 
 
 
 
 
 
 
 index:  0 , result of vote:  (1, [(1, 1.0)])
index:  1 , result of vote:  (2, [(2, 1.0)])
index:  2 , result of vote:  (1, [(1, 1.0)])
index:  3 , result of vote:  (1, [(1, 1.0)])
index:  4 , result of vote:  (2, [(2, 0.8490154592118361), (1, 0.15098454078816387)])
index:  5 , result of vote:  (2, [(2, 0.6736137462184478), (1, 0.3263862537815521)])
index:  6 , result of vote:  (0, [(0, 1.0)])
index:  7 , result of vote:  (1, [(1, 1.0)])
index:  8 , result of vote:  (1, [(1, 1.0)])
index:  9 , result of vote:  (0, [(0, 1.0)])
index:  10 , result of vote:  (1, [(1, 1.0)])
index:  11 , result of vote:  (2, [(2, 1.0)])
 
 
 
 
 
 
 
 
 
 Another Example for Nearest Neighbor Classification We want to test the previous functions with another very simple dataset: 
 
 
 
 
 
 
 
 
 train_set   =   [( 1 ,   2 ,   2 ),  
              ( - 3 ,   - 2 ,   0 ), 
              ( 1 ,   1 ,   3 ),  
              ( - 3 ,   - 3 ,   - 1 ), 
              ( - 3 ,   - 2 ,   - 0.5 ), 
              ( 0 ,   0.3 ,   0.8 ), 
              ( - 0.5 ,   0.6 ,   0.7 ), 
              ( 0 ,   0 ,   0 ) 
             ] 

 labels   =   [ 'apple' ,    'banana' ,   'apple' ,  
           'banana' ,   'apple' ,   ""orange"" , 
           'orange' ,   'orange' ] 

 k   =   1 
 for   test_instance   in   [( 0 ,   0 ,   0 ),   ( 2 ,   2 ,   2 ),  
                       ( - 3 ,   - 1 ,   0 ),   ( 0 ,   1 ,   0.9 ), 
                       ( 1 ,   1.5 ,   1.8 ),   ( 0.9 ,   0.8 ,   1.6 )]: 
     neighbors   =   get_neighbors ( train_set ,  
                               labels ,  
                               test_instance ,  
                               2 ) 

     print ( ""vote distance weights: "" ,   vote_distance_weights ( neighbors )) 
 
 
 
 
 
 
 
 
 
 vote distance weights:  ('orange', [('orange', 1.0)])
vote distance weights:  ('apple', [('apple', 1.0)])
vote distance weights:  ('banana', [('banana', 0.5294117647058824), ('apple', 0.47058823529411764)])
vote distance weights:  ('orange', [('orange', 1.0)])
vote distance weights:  ('apple', [('apple', 1.0)])
vote distance weights:  ('apple', [('apple', 0.5084745762711865), ('orange', 0.4915254237288135)])
 
 
 
 
 
 
 
 
 
 kNN in Linguistics The next example comes from computer linguistics. We show how we can use a k-nearest neighbor classifier to recognize misspelled words. 
 We use a module called levenshtein, which we have implemented in our tutorial on  Levenshtein Distance . 
 
 
 
 
 
 
 
 
 from   levenshtein   import   levenshtein 

 cities   =   open ( ""data/city_names.txt"" ) . readlines () 
 cities   =   [ city . strip ()   for   city   in   cities ] 

 for   city   in   [ ""Freiburg"" ,   ""Frieburg"" ,   ""Freiborg"" ,  
              ""Hamborg"" ,   ""Sahrluis"" ]: 
     neighbors   =   get_neighbors ( cities ,  
                               cities ,  
                               city ,  
                               2 , 
                               distance = levenshtein ) 

     print ( ""vote_distance_weights: "" ,   vote_distance_weights ( neighbors )) 
 
 
 
 
 
 
 
 
 
 vote_distance_weights:  ('Freiberg', [('Freiberg', 0.8333333333333334), ('Freising', 0.16666666666666669)])
vote_distance_weights:  ('Lüneburg', [('Lüneburg', 0.5), ('Duisburg', 0.5)])
vote_distance_weights:  ('Freiberg', [('Freiberg', 0.8333333333333334), ('Freising', 0.16666666666666669)])
vote_distance_weights:  ('Hamburg', [('Hamburg', 0.7142857142857143), ('Bamberg', 0.28571428571428575)])
vote_distance_weights:  ('Saarlouis', [('Saarlouis', 0.8387096774193549), ('Bayreuth', 0.16129032258064516)])
 
 
 
 
 
 
 
 
 
 If you work under Linux (especially Ubuntu), you can find a file with a British-English dictionary under /usr/share/dict/british-english. Windows users and others can download the file as 
 
 
 british-english.txt 
 
 
 
 We use extremely misspelled words in the following example. We see that our simple vote_prob function is doing well only in two cases: In correcting ""holpposs"" to ""helpless""
and ""blagrufoo"" to ""barefoot"". Whereas our distance voting is doing well in all cases. 
Okay, we have to admit that we had ""liberty"" in mind, when we wrote ""liberdi"", but suggesting ""liberal"" is a good choice. 
 
 
 
 
 
 
 
 
 words   =   [] 
 with   open ( ""british-english.txt"" )   as   fh : 
     for   line   in   fh : 
         word   =   line . strip () 
         words . append ( word ) 

 for   word   in   [ ""holpful"" ,   ""kundnoss"" ,   ""holpposs"" ,   ""blagrufoo"" ,   ""liberdi"" ]: 
     neighbors   =   get_neighbors ( words ,  
                               words ,  
                               word ,  
                               3 , 
                               distance = levenshtein ) 

     print ( ""vote_distance_weights: "" ,   vote_distance_weights ( neighbors ,  
                                                            all_results = False )) 
     print ( ""vote_prob: "" ,   vote_prob ( neighbors )) 
 
 
 
 
 
 
 
 
 
 vote_distance_weights:  ('helpful', 0.5555555555555556)
vote_prob:  ('helpful', 0.3333333333333333)
vote_distance_weights:  ('kindness', 0.5)
vote_prob:  ('kindness', 0.3333333333333333)
vote_distance_weights:  ('helpless', 0.3333333333333333)
vote_prob:  ('helpless', 0.3333333333333333)
vote_distance_weights:  ('barefoot', 0.4333333333333333)
vote_prob:  ('barefoot', 0.3333333333333333)
vote_distance_weights:  ('liberal', 0.4)
vote_prob:  ('liberal', 0.3333333333333333)
 
 
 
 
 
 
 
 
 
 Using sklearn for kNN neighbors  is a package of the  sklearn , which provides functionalities for nearest neighbor classifiers both for unsupervised and supervised learning. 
 The classes in sklearn.neighbors can handle both Numpy arrays and scipy.sparse matrices as input. For dense matrices, a large number of possible distance metrics are supported. For sparse matrices, arbitrary Minkowski metrics are supported for searches. 
 scikit-learn  implements two different nearest neighbors classifiers: 
 
 KNeighborsClassifier 
 is based on the k nearest neighbors of a sample, which has to be classified. The number 'k' is an integer value specified by the user. This is the most frequently used classifiers of both algorithms. 
 RadiusNeighborsClassifier 
 is based on the number of neighbors within a fixed radius r for each sample which has to be classified. 'r' is float value specified by the user. This classifier is less often used. 
 There is no general way to define an optimal value for 'k'. This value depends on the data. As a general rule we can say that increasing 'k' reduces the noise but on the other hand makes the boundaries less distinct. 
 The decision based on the nearest neighbors can be reached either uniform weights, the class assigned to a query sample is calculated by a simple majority vote of the k-nearest neighbors. This does not take into account that the neighbors closer to the sample should contribute more than the ones further away. The weighting can be controlled by the  weights  keyword: 
 weights = 'uniform'  assigns uniform weights to each neighbor. This is also the default value. 
 weights = 'distance' assigns weights proportional to the inverse of the distance from the query sample. 
 It is also possible to supply a user-defined function to compute the distance. 
 Parameters 
 
 n_neighbors 
 int, optional (default = 5) 
      Number of neighbors to use by default for meth:'kneighbors' queries. 
 weights 
 str or callable, optional (default = 'uniform')  weight function used in prediction.  Possible values:
 
 'uniform' : uniform weights.  All points in each neighborhood are weighted equally. 
 'distance' : weight points by the inverse of their distance. in this case, closer neighbors of a query point will have a greater influence than neighbors which are further away.
     
 [callable] : a user-defined function which accepts an array of distances, and returns an array of the same shape containing the weights. 
 
 
 algorithm 
 optional Algorithm used to compute the nearest neighbors:
 
 'ball_tree' will use :class:'BallTree'
 'kd_tree' will use :class:'KDTree'
 'brute' will use a brute-force search.
 'auto' will attempt to decide the most appropriate algorithm based on the values passed to :meth:'fit' method.
 Note: fitting on sparse input will override the setting of this parameter, using brute force.
     
 
 leaf_size 
 int, optional (default = 30) 
Leaf size passed to BallTree or KDTree.  This can affect the
speed of the construction and query, as well as the memory
required to store the tree.  The optimal value depends on the
nature of the problem. 
 p 
 integer, optional (default = 2) 
Power parameter for the Minkowski metric. When p = 1, this is
equivalent to using manhattan_distance (l1), and euclidean_distance (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used. 
 metric 
 string or callable, default 'minkowski' 
the distance metric to use for the tree.  The default metric is
 minkowski, and with p=2 is equivalent to the standard Euclidean  metric. See the documentation of the DistanceMetric class for a list of available metrics. 
 metric_params 
 dict, optional (default = None) 
Additional keyword arguments for the metric function. 
 n_jobs 
 int, optional (default = 1) 
The number of parallel jobs to run for neighbors search.
If '-1', then the number of jobs is set to the number of CPU cores. Doesn't affect :meth:'fit' method. 
 Example with kNN We will use the k-nearest neighbor classifier 'KNeighborsClassifier' from 'sklearn.neighbors' on the Iris data set: 
 
 
 
 
 
 
 
 
 # Create and fit a nearest-neighbor classifier 
 from   sklearn.neighbors   import   KNeighborsClassifier 
 knn   =   KNeighborsClassifier () 
 knn . fit ( learnset_data ,   learnset_labels )  
 KNeighborsClassifier ( algorithm = 'auto' ,  
                      leaf_size = 30 ,  
                      metric = 'minkowski' , 
                      metric_params = None ,  
                      n_jobs = 1 ,  
                      n_neighbors = 5 ,  
                      p = 2 , 
                      weights = 'uniform' ) 

 print ( ""Predictions form the classifier:"" ) 
 print ( knn . predict ( testset_data )) 
 print ( ""Target values:"" ) 
 print ( testset_labels ) 
 
 
 
 
 
 
 
 
 
 Predictions form the classifier:
[1 2 1 1 2 2 0 1 1 0 1 2]
Target values:
[1 2 1 1 2 2 0 1 2 0 1 2]
 
 
 
 
 
 
 
 
 
 
 
 learnset_data [: 5 ],   learnset_labels [: 5 ] 
 
 
 
 
 
 
 
 Output:: 
 
 (array([[6.1, 2.8, 4.7, 1.2],
        [5.7, 3.8, 1.7, 0.3],
        [7.7, 2.6, 6.9, 2.3],
        [6. , 2.9, 4.5, 1.5],
        [6.8, 2.8, 4.8, 1.4]]), array([1, 0, 2, 1, 1])) 
 
 
 
 
 
 
 
 
 We can see that the sample with the index 8 is again not recognized properly. 
 
 
 
 Previous Chapter:  Machine Learning Terminology 
 Next Chapter:  Neural Networks from Scratch in Python 
 
   © 2011 - 2019, Bernd Klein,
Bodenseo; 
Design by Denise Mitchinson adapted for python-course.eu by Bernd Klein "," k-nearest-neighbor from Scratch,None,None,None,None,None,None,None,None,None,None,None,None,Another Example for Nearest Neighbor Classification,kNN in Linguistics,None,None,Using sklearn for kNN,None,", https://www.python-course.eu/http://www.python-kurs.eu/stellengesuch/Stellenanzeige.pdfhttps://www.python-course.eu/http://www.python-course.eu/levenshtein_distance.php
2,Neural Networks from Scratch in Python,https://www.python-course.eu/neural_networks.php,"Machine Learning with Python: Neural Networks from Scratch in Python 
 
 
 
 - remove in and out prompt from ipython notebook 
%%HTML

div.prompt {display:none}

 - 
 
 
 
 
 Python Machine Learning Tutorial 
 
  Begin Top Menu  
 
 Home Python 2 Tutorial Python 3 Tutorial Advanced Topics Numerical Programming Machine Learning Tkinter Tutorial Contact 
 
  End Top Menu  
 Machine Learning 
 
 
 Machine Learning Terminology k-nearest Neighbor Classifier Neural Networks from Scratch in Python Neural Network in Python using Numpy Backpropagation in Neural Networks Confusion Matrix Training and Testing with MNIST Dropout Neural Networks Neural Networks with Scikit Machine Learning with Scikit and Python Introduction Naive Bayes Classifier Naive Bayes Classifier with Scikit Introduction into Text Classification using Naive Bayes Python Implementation of Text Classification Decision Trees Regression Trees Random Forests Boosting Algorithm Principal Component Analysis Linear Discriminant Analysis Expectation Maximization and Gaussian Mixture Model Introduction into TensorFlow 
 
 
 
 Help Needed 

This website is free of annoying ads. We want to keep it like this. You can help with your donation:
 
 
 
 
 
 
 
 
 The need for donations 
 
 
 
 
 Quotes 
 ""Neural computing is the study of cellular networks that have a natural property for storing experimental knowledge. Such systems bear a resemblance to the brain in the sense that knowledge is acquired through training rather than programming and is retained due to changes in node functions. The knowledge takes the form of stable states or cycles of states in the operation of the et. A central property of such nets is to recall these states or cycles in response to the presentation of cues."" 
 
(Aleksander & Morton, 1989,  ""Neural computing architectures: the design of brain-like machines."", p.2 as cited in: M.A. Lovell et al. (1997) Developments in petrophysics. p.169
 
 
 
 
""Cognitive neuroscience is entering an exciting era in which new technologies and ideas are making it possible to study the neural basis of cognition, perception, memory and emotion at the level of networks of interacting neurons, the level at which we believe many of the important operations of the brain take place. We know a considerable amount about how individual neurons work and how two cells can communicate with each other but the way in which entire networks of hundreds and thousands of neurons cooperate, interact with each other, and are orchestrated to create our ideas and concepts is an underexplored area of neuroscience. ""
 
(John O'Keefe, from his speech at the Nobel Banquet, 10 December 2014)
 
 
 
 
This website is created by: 
Bernd Klein,  Python Training Courses 
 
On site trainings in Europe, Canada and the US.
 
 
 
  Dieses Tag dort einfügen, wo die +1-Schaltfläche dargestellt werden soll  
 
 
 Help Needed 

This website is free of annoying ads. We want to keep it like this. You can help with your donation:
 
 
 
 
 
 
 
 
 
 The need for donations 
 
 Job Applications 
 
 Python Lecturer 
 bodenseo is looking for a new trainer and software developper. You need to live in Germany and know German. Interested? Find out  more !
 Python Programmer 
We are looking for a qualified Python programmer to further improve our website. This is a work from home job, wherever you live in the world! 
If you think that you are the right person or if you have further questions, please do not hesitate to  contact us .
 
 
 
 Bernd Klein on Facebook 
 
 
 
Search this website:
 
 
 
 Classroom Training Courses 
 
This website contains a free and extensive online tutorial by Bernd Klein, using
material from his classroom Python training courses Python classes 
 
 © kabliczech - Fotolia.com Quote of the Day: ""Some programming languages manage to absorb change, but withstand progress. ""  (Alan Perlis)

   Help Needed 
 
 
 
 
 
 The need for donations Data Protection Declaration Data Protection Declaration 
 Previous Chapter:  k-nearest Neighbor Classifier 
 Next Chapter:  Neural Network in Python using Numpy 
 
 
 
 
 Neural Networks Introduction 
 
 
 
 
 
 
 
 
 
 
 
 
 
 When we say ""Neural Networks"", we mean artificial Neural Networks (ANN). The idea of ANN is based on biological neural networks like the brain. 
 The basic structure of a neural network is the neuron. 
A neuron in biology consists of three major parts: the soma (cell body), the dendrites, and the axon. 
 The dendrites branch of from the soma in a tree-like way and getting thinner with every branch.  They receive signals (impulses) from other neurons at synapses. The axon - there is always only one -  also leaves the soma and usually tend to extend for longer distances than the dentrites. The axon is used for sending the output of the neuron to other neurons or better to the synapsis of other neurons. 
 The following image by  Quasar Jarosz , courtesy of Wikipedia, illustrates this: 
 
 
 
 
 
 
 
 
 
 
 
 
 
 Even though the above image is already an abstraction for a biologist, we can further abstract it: 
 
 
 
 
 
 
 
 
 
 
 
 
 
 A perceptron of artificial neural networks is simulating a biological neuron. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 It is amazingly simple, what is going on inside the body of a perceptron or neuron. The input signals get multiplied by weight values, i.e. each input has its corresponding weight. This way the input can be adjusted individually for every $x_i$. We can see  all the inputs as an input vector and the corresponding weights as the weights vector. 
 When a signal comes in, it gets multiplied by a weight value that is assigned to this particular input. That is, if a neuron has three inputs, then it has three weights that can be adjusted individually. The weights usually get adjusted during the learn phase. 
After this the modified input signals are summed up. It is also possible to add additionally a so-called bias b to this sum. The bias is a value which can also be adjusted during the learn phase. 
 Finally, the actual output has to be determined. For this purpose an activation or step function Φ is applied to weighted sum of the input values. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 The simplest form of an activation function is a binary function. If the result of the summation is greater than some threshold s, the result of $\Phi$ will be 1, otherwise 0. 
$$
\Phi(x) = \left\{ \begin{array}{rl}
 1 &\mbox{ wx + b > s} \\
 0 &\mbox{ otherwise}
       \end{array} \right.
$$ 
 A Simple Neural Network The following image shows the general building principle of a simple artificial neural network: 
 
 
 
 
 
 
 
 
 
 
 
 
 
 We will write a very simple Neural Network implementing the logical ""And"" and ""Or"" functions. 
 Let's start with the ""And"" function. It is defined for two inputs: 
 
 
 Input1 
 Input2 
 Output 
 
 
 
 
 0 
 0 
 0 
 
 
 0 
 1 
 0 
 
 
 1 
 0 
 0 
 
 
 1 
 1 
 1 
 
 
 
 
 
 
 
 
 
 Line Separation You could imagine that you have two attributes describing am eddible object like a fruit for example: ""sweetness"" and ""sourness"" 
 We could describe this by points in a two-dimensional space. The x axis for the sweetness and the y axis for the sourness. Imagine now that we have two fruits as points in this space, i.e.  an orange at position (3.5, 1.8) and a lemon at (1.1, 3.9). 
 We could define dividing lines to define the points which are more lemon-like and which are more orange-like. The following program calculates and renders a bunch of lines. The red ones are completely unusable for this purpose, because they are not separating the classes. Yet, it is obvious that even the green ones are not all useful. 
 
 
 
 
 
 
 
 
 import   numpy   as   np 
 import   matplotlib.pyplot   as   plt  


 def   create_distance_function ( a ,   b ,   c ): 
     """""" 0 = ax + by + c """""" 
     def   distance ( x ,   y ): 
         """""" returns tuple (d, pos) 
             d is the distance 
             If pos == -1 point is below the line,  
             0 on the line and +1 if above the line 
         """""" 
         nom   =   a   *   x   +   b   *   y   +   c 
         if   nom   ==   0 : 
             pos   =   0 
         elif   ( nom  0   and   b > 0 ): 
             pos   =   - 1 
         else : 
             pos   =   1 
         return   ( np . absolute ( nom )   /   np . sqrt (   a   **   2   +   b   **   2 ),   pos ) 
     return   distance 
    

 points   =   [   ( 3.5 ,   1.8 ),   ( 1.1 ,   3.9 )   ] 

 fig ,   ax   =   plt . subplots () 
 ax . set_xlabel ( ""sweetness"" ) 
 ax . set_ylabel ( ""sourness"" ) 
 ax . set_xlim ([ - 1 ,   6 ]) 
 ax . set_ylim ([ - 1 ,   8 ]) 
 X   =   np . arange ( - 0.5 ,   5 ,   0.1 ) 


 colors   =   [ ""r"" ,   """" ]   # for the samples 

 size   =   10 
 for   ( index ,   ( x ,   y ))   in   enumerate ( points ): 
     if   index ==   0 : 
         ax . plot ( x ,   y ,   ""o"" ,  
                 color = ""darkorange"" ,  
                 markersize = size ) 
     else : 
         ax . plot ( x ,   y ,   ""oy"" ,  
                 markersize = size ) 

 step   =   0.05 
 for   x   in   np . arange ( 0 ,   1 + step ,   step ): 
     slope   =   np . tan ( np . arccos ( x )) 
     dist4line1   =   create_distance_function ( slope ,   - 1 ,   0 ) 
     #print(""x: "", x, ""slope: "", slope) 
     Y   =   slope   *   X 
    
     results   =   [] 
     for   point   in   points : 
         results . append ( dist4line1 ( * point )) 
     #print(slope, results) 
     if   ( results [ 0 ][ 1 ]   !=   results [ 1 ][ 1 ]): 
         ax . plot ( X ,   Y ,   ""g-"" ) 
     else : 
         ax . plot ( X ,   Y ,   ""r-"" ) 
        

 plt . show () 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 In the following program, we train a neural network to classify two clusters in a 2-dimensional space. We show this in the following diagram with the two classes class1 and class2. We will create those points randomly with the help of a line, the points of class2 will be above the line and the points of class1 will be below the line. 
 
 
 
 
 
 
 
 
 import   numpy   as   np 

 class   Perceptron : 
    
     def   __init__ ( self ,   input_length ,   weights = None ): 
         if   weights   is   None : 
             self . weights   =   np . ones ( input_length )   *   0.5 
         else : 
             self . weights   =   weights 
        
     @staticmethod 
     def   unit_step_function ( x ): 
         if   x   >   0.5 : 
             return   1 
         return   0 
        
     def   __call__ ( self ,   in_data ): 
         weighted_input   =   self . weights   *   in_data 
         weighted_sum   =   weighted_input . sum () 
         return   Perceptron . unit_step_function ( weighted_sum ) 
    
 p   =   Perceptron ( 2 ,   np . array ([ 0.5 ,   0.5 ])) 

 data_in   =   np . empty (( 2 ,)) 
 for   in1   in   range ( 2 ): 
     for   in2   in   range ( 2 ): 
         data_in   =   ( in1 ,   in2 ) 
         data_out   =   p ( data_in ) 
         print ( data_in ,   data_out ) 
 
 
 
 
 
 
 
 
 
 (0, 0) 0
(0, 1) 0
(1, 0) 0
(1, 1) 1
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 We will see that the neural network will find a line that separates the two classes. This line should not be mistaken for the line, which we used to create the points. 
 This line is called a  decision boundary . 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 import   numpy   as   np 
 from   collections   import   Counter 

 class   Perceptron : 
    
     def   __init__ ( self ,   input_length ,   weights = None ): 
         if   weights == None : 
             self . weights   =   np . random . random (( input_length ))   *   2   -   1 
         self . learning_rate   =   0.1 
        
     @staticmethod 
     def   unit_step_function ( x ): 
         if   x      line_func ( x ): 
         return   1 
     else : 
         return   0 
  
 points   =   np . random . randint ( 1 ,   100 ,   ( 100 ,   2 )) 
 p   =   Perceptron ( 2 ) 

 def   lin1 ( x ): 
     return    x   +   4 

 for   point   in   points : 
     p . adjust ( above_line ( point ,   lin1 ),  
              p ( point ),  
              point ) 

 evaluation   =   Counter () 
 for   point   in   points : 
     if   p ( point )   ==   above_line ( point ,   lin1 ): 
         evaluation [ ""correct"" ]   +=   1 
     else : 
         evaluation [ ""wrong"" ]   +=   1 

 print ( evaluation . most_common ()) 
 
 
 
 
 
 
 
 
 
 [('correct', 100)]
 
 
 
 
 
 
 
 
 
 The decision boundary of our previous network can be calculated by looking at the following condition 
$$x_1 w_1 + x_2w_2 = 0$$ We can change the equation into 
$$ x_2 = -\frac{w_1}{w_2}x_1$$ When we look at the general form of a straight line $ y = mx + b$, we can easily see that our equation corresponds to the definition of a line and the slope (aka gradient) $m$ is $-\frac{w_1}{w_2}$ and $b$ is equal to 0. 
 Single Layer with Bias As the constant term $b$ determines the point at which a line crosses the y-axis, i.e. the y-intercept, we can see that our network can only calculate lines which pass through the origin, i.e. the point (0, 0). We will need a bias to get other lines as well, i.e. lines which don't go through the origin. A neural network with bias nodes can look like this: 
 
 Now, the linear equation for a perceptron contains a bias: 
$$b + \sum_{i=1}^{n} x_i \cdot w_i = 0$$ We add now some code to print the points and the dividing line according to the previous equation: 
 
 
 
 
 
 
 
 
 # the following line is only needed, 
 # if you use ""ipython notebook"": 
 % matplotlib  inline 

 from   matplotlib   import   pyplot   as   plt 

 cls   =   [[],   []] 
 for   point   in   points : 
     cls [ above_line ( point ,   lin1 )] . append ( tuple ( point )) 


 colours   =   ( ""r"" ,   ""b"" ) 
 for   i   in   range ( 2 ): 
     X ,   Y   =   zip ( * cls [ i ]) 
     plt . scatter ( X ,   Y ,   c = colours [ i ]) 
    
 X   =   np . arange ( - 3 ,   120 ) 
    
 m   =   - p . weights [ 0 ]   /   p . weights [ 1 ] 
 print ( m ) 
 plt . plot ( X ,   m * X ,   label = ""ANN line"" ) 
 plt . plot ( X ,   lin1 ( X ),   label = ""line1"" ) 
 plt . legend () 
 plt . show () 
 
 
 
 
 
 
 
 
 
 1.11082111934
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 We create a new dataset for our next experiments: 
 
 
 
 
 
 
 
 
 from   matplotlib   import   pyplot   as   plt 

 class1   =   [( 3 ,   4 ),   ( 4.2 ,   5.3 ),   ( 4 ,   3 ),   ( 6 ,   5 ),   ( 4 ,   6 ),   ( 3.7 ,   5.8 ), 
           ( 3.2 ,   4.6 ),   ( 5.2 ,   5.9 ),   ( 5 ,   4 ),   ( 7 ,   4 ),   ( 3 ,   7 ),   ( 4.3 ,   4.3 )   ]  
 class2   =   [( - 3 ,   - 4 ),   ( - 2 ,   - 3.5 ),   ( - 1 ,   - 6 ),   ( - 3 ,   - 4.3 ),   ( - 4 ,   - 5.6 ),  
           ( - 3.2 ,   - 4.8 ),   ( - 2.3 ,   - 4.3 ),   ( - 2.7 ,   - 2.6 ),   ( - 1.5 ,   - 3.6 ),  
           ( - 3.6 ,   - 5.6 ),   ( - 4.5 ,   - 4.6 ),   ( - 3.7 ,   - 5.8 )   ] 


 X ,   Y   =   zip ( * class1 ) 
 plt . scatter ( X ,   Y ,   c = ""r"" ) 

 X ,   Y   =   zip ( * class2 ) 
 plt . scatter ( X ,   Y ,   c = ""b"" ) 
 plt . show () 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 from   itertools   import   chain 

 p   =   Perceptron ( 2 ) 

 def   lin1 ( x ): 
     return    x   +   4 

 for   point   in   class1 : 
     p . adjust ( 1 ,  
              p ( point ),  
              point ) 

 for   point   in   class2 : 
     p . adjust ( 0 ,  
              p ( point ),  
              point ) 
    
 evaluation   =   Counter () 
 for   point   in   chain ( class1 ,   class2 ): 
     if   p ( point )   ==   1 : 
         evaluation [ ""correct"" ]   +=   1 
     else : 
         evaluation [ ""wrong"" ]   +=   1 
        
 testpoints   =   [( 3.9 ,   6.9 ),   ( - 2.9 ,   - 5.9 )] 
 for   point   in   testpoints : 
     print ( p ( point )) 
        
 print ( evaluation . most_common ()) 
 
 
 
 
 
 
 
 
 
 1
0
[('correct', 12), ('wrong', 12)]
 
 
 
 
 
 
 
 
 
 
 
 from   matplotlib   import   pyplot   as   plt 

 X ,   Y   =   zip ( * class1 ) 
 plt . scatter ( X ,   Y ,   c = ""r"" ) 

 X ,   Y   =   zip ( * class2 ) 
 plt . scatter ( X ,   Y ,   c = ""b"" ) 

 x   =   np . arange ( - 7 ,   10 ) 
 y   =   5 * x   +   10  

 m   =   - p . weights [ 0 ]   /   p . weights [ 1 ] 
 plt . plot ( x ,   m * x ) 
 plt . show () 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 from   matplotlib   import   pyplot   as   plt 

 class1   =   [( 3 ,   4 ,   3 ),   ( 4.2 ,   5.3 ,   2.5 ),   ( 4 ,   3 ,   3.8 ),  
           ( 6 ,   5 ,   2.7 ),   ( 4 ,   6 ,   2.9 ),   ( 3.7 ,   5.8 ,   4.2 ), 
           ( 3.2 ,   4.6 ,   1.9 ),   ( 5.2 ,   5.9 ,   2.7 ),   ( 5 ,   4 ,   3.5 ),  
           ( 7 ,   4 ,   2.7 ),   ( 3 ,   7 ,   3.1 ),   ( 4.3 ,   4.3 ,   3.8 )   ]  
 class2   =   [( - 3 ,   - 4 ,   7.6 ),   ( - 2 ,   - 3.5 ,   6.9 ),   ( - 1 ,   - 6 ,   8.6 ),  
           ( - 3 ,   - 4.3 ,   7.4 ),   ( - 4 ,   - 5.6 ,   7.9 ),   ( - 3.2 ,   - 4.8 ,   5.3 ), 
           ( - 2.3 ,   - 4.3 ,   8.1 ),   ( - 2.7 ,   - 2.6 ,   7.3 ),   ( - 1.5 ,   - 3.6 ,   7.8 ),  
           ( - 3.6 ,   - 5.6 ,   6.8 ),   ( - 4.5 ,   - 4.6 ,   8.3 ),   ( - 3.7 ,   - 5.8 ,   8.7 )   ] 


 X ,   Y ,   Z   =   zip ( * class1 ) 
 plt . scatter ( X ,   Y ,   Z ,   c = ""r"" ) 

 X ,   Y ,   Z   =   zip ( * class2 ) 
 plt . scatter ( X ,   Y ,   Z ,   c = ""b"" ) 
 plt . show () 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 Linearly Separable and Inseparable Neural Networks If two data clusters (classes) can be separated by a decision boundary in the form of a linear equation 
$$\sum_{i=1}^{n} x_i \cdot w_i = 0$$ they are called linearly separable. 
 Otherwise, i.e. if such a decision boundary does not exist, the two classes are called linearly inseparable. In this case, we cannot use a simple neural network. 
 In the following section, we will introduce the XOR problem for neural networks. It is the simplest example of a non  linearly separable neural network. I can be solved with an additional layer of neurons, which is called a hidden layer. 
 
 
 
 
 
 
 The XOR Problem for Neural Networks The XOR (exclusive or) function is defined by the following truth table: 
 
 
 Input1 
 Input2 
 XOR Output 
 
 
 
 
 0 
 0 
 0 
 
 
 0 
 1 
 1 
 
 
 1 
 0 
 1 
 
 
 1 
 1 
 0 
 
 
 
 This problem can't be solved with a simple neural network. We need to introduce a new type of neural networks, a network with so-called hidden layers. A hidden layer allows the network to reorganize or rearrange the input data. 
 
 We will need only one hidden layer with two neurons. One works like an AND gate and the other one like an OR gate. 
The output will ""fire"", when the OR gate fires and the AND gate doesn't. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 ANN with hidden layers: 
 
 
 
 
 
 
 The task is to find a line which separates the orange points from the blue points. But they can be separated by two lines, e.g. L 1  and L 2  in the following diagram: 
 
 
 
 
 
 
 
 
 
 
 
 
 
 To solve this problem, we need a network of the following kind, i.e with a hidden layer N 1  and N 2 
 
 
 
 
 
 
 
 
 
 
 
 
 
 The neuron N 1  will determine one line, e.g. L 1  and the neuron N 2  will determine the other line L 2 .
N 3  will finally solve our problem: 
 
 
 
 
 
 
 
 
 
 
 
 
 
 Neural Network with Bias Values We will come back now to our initial example with the random points above and below a line. We will rewrite the code using a bias value. 
 First we will create two classes with random points, which are not separable by a line crossing the origin. 
 We will add a bias b to our neural network. This leads us to the following condition 
$$x_1 w_1 + x_2w_2  + b w_3= 0$$ We can change the equation into 
$$ x_2 = -\frac{w_1}{w_2}x_1 -\frac{w_3}{w_2}b$$
 
 
 
 
 
 
 
 
 import   numpy   as   np 
 from   matplotlib   import   pyplot   as   plt 

 npoints   =   50 
 X ,   Y   =   [],   [] 
 # class 0 
 X . append ( np . random . uniform ( low =- 2.5 ,   high = 2.3 ,   size = ( npoints ,))   ) 
 Y . append ( np . random . uniform ( low =- 1.7 ,   high = 2.8 ,   size = ( npoints ,))) 

 # class 1 
 X . append ( np . random . uniform ( low =- 7.2 ,   high =- 4.4 ,   size = ( npoints ,))   ) 
 Y . append ( np . random . uniform ( low = 3 ,   high = 6.5 ,   size = ( npoints ,))) 

 learnset   =   [] 
 for   i   in   range ( 2 ): 
     # adding points of class i to learnset 
     points   =   zip ( X [ i ],   Y [ i ]) 
     for   p   in   points : 
         learnset . append (( p ,   i )) 

 colours   =   [ ""b"" ,   ""r"" ] 
 for   i   in   range ( 2 ): 
     plt . scatter ( X [ i ],   Y [ i ],   c = colours [ i ]) 

                    
    
 
 
 
 
 
 
 
 
 
 
 import   numpy   as   np 
 from   collections   import   Counter 

 class   Perceptron : 
    
     def   __init__ ( self ,   input_length ,   weights = None ): 
         if   weights == None : 
             self . weights   =   np . random . random (( input_length ))   *   2   -   1 
         self . learning_rate   =   0.1 
        
     @staticmethod 
     def   unit_step_function ( x ): 
         if   x   <   0 : 
             return   0 
         return   1 
        
     def   __call__ ( self ,   in_data ): 
         weighted_input   =   self . weights   *   in_data 
         weighted_sum   =   weighted_input . sum () 
         return   Perceptron . unit_step_function ( weighted_sum ) 
    
     def   adjust ( self ,  
                target_result ,  
                calculated_result , 
                in_data ): 
         error   =   target_result   -   calculated_result 
         for   i   in   range ( len ( in_data )): 
             correction   =   error   *   in_data [ i ]   * self . learning_rate 
             self . weights [ i ]   +=   correction  

     
  
 p   =   Perceptron ( 2 ) 


 for   point ,   label   in   learnset : 
     p . adjust ( label ,  
              p ( point ),  
              point ) 

 evaluation   =   Counter () 
 for   point ,   label   in   learnset : 
     if   p ( point )   ==   label : 
         evaluation [ ""correct"" ]   +=   1 
     else : 
         evaluation [ ""wrong"" ]   +=   1 

 print ( evaluation . most_common ()) 


 colours   =   [ ""b"" ,   ""r"" ] 
 for   i   in   range ( 2 ): 
     plt . scatter ( X [ i ],   Y [ i ],   c = colours [ i ]) 

 XR   =   np . arange ( - 8 ,   4 )   
 m   =   - p . weights [ 0 ]   /   p . weights [ 1 ] 
 print ( m ) 
 plt . plot ( XR ,   m * XR ,   label = ""decision boundary"" ) 
 plt . legend () 
 plt . show () 
 
 
 
 
 
 
 
 
 
 [('correct', 77), ('wrong', 23)]
3.10186712936
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 It is not possible to find a solution with one neuron and without a bias node. The reason is that the class of the blue data points spread around the origin. Without bias nodes we get only lines going through the origin as we have mentioned earlier. It is easy to see that no line going through the origin can separate the blue from the red data. 
 The following class uses bias nodes and solves this problem: 
 
 
 
 
 
 
 
 
 import   numpy   as   np 
 from   collections   import   Counter 

 class   Perceptron : 
    
     def   __init__ ( self ,   input_length ,   weights = None ): 
         if   weights == None : 
             # input_length + 1 because bias needs a weight as well 
             self . weights   =   np . random . random (( input_length   +   1 ))   *   2   -   1 
         self . learning_rate   =   0.05 
         self . bias   =   1 
    
     @staticmethod 
     def   sigmoid_function ( x ): 
         res   =   1   /   ( 1   +   np . power ( np . e ,   - x )) 
         return   0   if   res   <   0.5   else   1 
        
     def   __call__ ( self ,   in_data ): 
         weighted_input   =   self . weights [: - 1 ]   *   in_data 
         weighted_sum   =   weighted_input . sum ()   +   self . bias   * self . weights [ - 1 ] 
         return   Perceptron . sigmoid_function ( weighted_sum ) 
    
     def   adjust ( self ,  
                target_result ,  
                calculated_result , 
                in_data ): 
         error   =   target_result   -   calculated_result 
         for   i   in   range ( len ( in_data )): 
             correction   =   error   *   in_data [ i ]    * self . learning_rate 
             #print(""weights: "", self.weights) 
             #print(target_result, calculated_result, in_data, error, correction) 
             self . weights [ i ]   +=   correction  
         # correct the bias: 
         correction   =   error   *   self . bias   *   self . learning_rate 
         self . weights [ - 1 ]   +=   correction  
     
  
 p   =   Perceptron ( 2 ) 

 for   point ,   label   in   learnset : 
     p . adjust ( label ,  
              p ( point ),  
              point ) 

 evaluation   =   Counter () 
 for   point ,   label   in   learnset : 
     if   p ( point )   ==   label : 
         evaluation [ ""correct"" ]   +=   1 
     else : 
         evaluation [ ""wrong"" ]   +=   1 

 print ( evaluation . most_common ()) 


 colours   =   [ ""b"" ,   ""r"" ] 
 for   i   in   range ( 2 ): 
     plt . scatter ( X [ i ],   Y [ i ],   c = colours [ i ]) 

 XR   =   np . arange ( - 8 ,   4 )   
 m   =   - p . weights [ 0 ]   /   p . weights [ 1 ] 

 b   =   - p . weights [ - 1 ] / p . weights [ 1 ] 
 print ( m ,   b ) 
 plt . plot ( XR ,   m * XR   +   b ,   label = ""decision boundary"" ) 
 plt . legend () 
 plt . show () 
 
 
 
 
 
 
 
 
 
 [('correct', 90), ('wrong', 10)]
-5.07932788718 -6.08697420041
 
 
 
 
 
 
 
 
 
 
 
 
 Previous Chapter:  k-nearest Neighbor Classifier 
 Next Chapter:  Neural Network in Python using Numpy 
 
   © 2011 - 2019, Bernd Klein,
Bodenseo; 
Design by Denise Mitchinson adapted for python-course.eu by Bernd Klein "," Introduction,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,Single Layer with Bias,None,Linearly Separable and Inseparable Neural Networks,The XOR Problem for Neural Networks,None,None,None,None,None,None,None,None,Neural Network with Bias Values,None,", https://www.python-course.eu/http://www.python-kurs.eu/stellengesuch/Stellenanzeige.pdf
3,Neural Network in Python using Numpy,https://www.python-course.eu/neural_networks_with_python_numpy.php,"Machine Learning with Python: Neural Network with Python using Numpy 
 
 
 
 - remove in and out prompt from ipython notebook 
%%HTML

div.prompt {display:none}

 - 
 
 
 
 
 Python Machine Learning Tutorial 
 
  Begin Top Menu  
 
 Home Python 2 Tutorial Python 3 Tutorial Advanced Topics Numerical Programming Machine Learning Tkinter Tutorial Contact 
 
  End Top Menu  
 Machine Learning 
 
 
 Machine Learning Terminology k-nearest Neighbor Classifier Neural Networks from Scratch in Python Neural Network in Python using Numpy Backpropagation in Neural Networks Confusion Matrix Training and Testing with MNIST Dropout Neural Networks Neural Networks with Scikit Machine Learning with Scikit and Python Introduction Naive Bayes Classifier Naive Bayes Classifier with Scikit Introduction into Text Classification using Naive Bayes Python Implementation of Text Classification Decision Trees Regression Trees Random Forests Boosting Algorithm Principal Component Analysis Linear Discriminant Analysis Expectation Maximization and Gaussian Mixture Model Introduction into TensorFlow 
 
 
 
 Help Needed 

This website is free of annoying ads. We want to keep it like this. You can help with your donation:
 
 
 
 
 
 
 
 
 The need for donations 
 
 
 
 
 Quotes 
 “Artificial intelligence would be the ultimate version of Google. The ultimate search engine that would understand everything on the web. It would understand exactly what you wanted, and it would give you the right thing. We’re nowhere near doing that now. However, we can get incrementally closer to that, and that is basically what we work on.” 
 
(Larry Wall)
 
 
 
 
“Machine intelligence is the last invention that humanity will ever need to make.”
 
(Nick Bostrom)
 
 
 
 
This website is created and maintained by: 
Bernd Klein,  
 
On site trainings in Europe, Canada and the US.
 
 
 
  Dieses Tag dort einfügen, wo die +1-Schaltfläche dargestellt werden soll  
 
 
 Help Needed 

This website is free of annoying ads. We want to keep it like this. You can help with your donation:
 
 
 
 
 
 
 
 
 
 The need for donations 
 
 Job Applications 
 
 Python Lecturer 
 bodenseo is looking for a new trainer and software developper. You need to live in Germany and know German. Interested? Find out  more !
 Python Programmer 
We are looking for a qualified Python programmer to further improve our website. This is a work from home job, wherever you live in the world! 
If you think that you are the right person or if you have further questions, please do not hesitate to  contact us .
 
 
 
 Bernd Klein on Facebook 
 
 
 
Search this website:
 
 
 
 Classroom Training Courses 
 
This website contains a free and extensive online tutorial by Bernd Klein, using
material from his classroom Python training courses Python classes 
 
 © kabliczech - Fotolia.com Quote of the Day: The real problem is not whether machines think but whether men do.  
(B. F. Skinner)
 
   Help Needed 
 
 
 
 
 
 The need for donations Data Protection Declaration Data Protection Declaration 
 Previous Chapter:  Neural Networks from Scratch in Python 
 Next Chapter:  Backpropagation in Neural Networks 
 
 
 
 
 Neural Network Using Python and Numpy 
 
 
 
 
 
 
 
 Introduction 
 
 We have introduced the basic ideas about neuronal networks in the previous chapter of our tutorial. 
 We pointed out the similarity between neurons and neural networks in biology. We also introduced very small articial neural networks and introduced decision boundaries and the XOR problem. 
 The focus in our previous chapter had not been on efficiency. 
 We will introduce a Neural Network class in Python in this chapter, which will use the powerful and efficient data structures of Numpy. This way, we get a more efficient network than in our previous chapter. When we say ""more efficient"", we do not mean that the artificial neural networks encountered in this chaper of our tutorial are efficient and ready for real life usage. They are still quite slow compared to implementations from sklearn for example. The focus is to implement a very basic neural network and by doing this explaining the basic ideas. We want to demonstrate simple and easy to grasp networks. 
 Ideas like how the signal flow inside of a network works, how to implement weights. how to initialize weight matrices or what activation functions can be used. 
 We will start with a simple neural networks consisting of three layers, i.e. the input layer, a hidden layer and an output layer. 
 A Simple Artificial Neural Network Structure You can see a simple neural network structure in the following diagram. We have an input layer with three nodes $i_1, i_2, i_3$ These nodes get the corresponding input values $x_1, x_2, x_3$. The middle or hidden layer has four nodes $h_1, h_2, h_3, h_4$. The input of this layer stems from the input layer. We will discuss the mechanism soon. Finally, our output layer consists of the two nodes $o_1, o_2$ 
 We have to note that some would call this a two layer network, because they don't count the inputs as a layer. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 The input layer consists of the nodes $i_1$, $i_2$ and $i_3$. In principle the input is a one-dimensional vector, like 
(2, 4, 11). A one-dimensional vector is represented in numpy like this: 
 
 
 
 
 
 
 
 
 import   numpy   as   np 

 input_vector   =   np . array ([ 2 ,   4 ,   11 ]) 
 print ( input_vector ) 
 
 
 
 
 
 
 
 
 
 [ 2  4 11]
 
 
 
 
 
 
 
 
 
 In the algorithm, which we will write later, we will have to transpose it into a column vector, i.e. a two-dimensional array with just one column: 
 
 
 
 
 
 
 
 
 import   numpy   as   np 

 input_vector   =   np . array ([ 2 ,   4 ,   11 ]) 
 input_vector   =   np . array ( input_vector ,   ndmin = 2 ) . T 
 print ( input_vector ,   input_vector . shape ) 
 
 
 
 
 
 
 
 
 
 [[ 2]
 [ 4]
 [11]] (3, 1)
 
 
 
 
 
 
 
 
 
 Weights and Matrices Each of the arrows in our network diagram has an associated weight value. We will only look at the arrows between the input and the output layer now. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 The value $x_1$ going into the node $i_1$ will be distributed according to the values of the weights. In the following diagram we have added some example values. Using these values, the input values ($Ih_1, Ih_2, Ih_3, Ih_4$ into the nodes ($h_1, h_2, h_3, h_4$) of the hidden layer  can be calculated like this: 
 $Ih_1 = 0.81 * 0.5 + 0.12 * 1 + 0.92 * 0.8 $ 
 $Ih_2 = 0.33 * 0.5 + 0.44 * 1 + 0.72 * 0.8 $ 
 $Ih_3 = 0.29 * 0.5 + 0.22 * 1 + 0.53 * 0.8 $ 
 $Ih_4 = 0.37 * 0.5 + 0.12 * 1 + 0.27 * 0.8 $ 
 Those familiar with matrices and matrix multiplication will see where it is boiling down to. We will redraw our network and denote the weights with $w_{ij}$: 
 
 
 
 
 
 
 
 
 
 
 
 
 
 In order to efficiently execute all the necessary calaculations, we will arrange the weights into a weight matrix. The weights in our diagram above build an array, which we will call 'weights_in_hidden' in our Neural Network class. The name should indicate that the weights are connecting the input and the hidden nodes, i.e. they are between the input and the hidden layer. We will also abbreviate the name as 'wih'. The weight matrix between the hidden and the output layer will be denoted as ""who"".: 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 Now that we have defined our weight matrices, we have to take the next step. We have to multiply the matrix wih the input vector. Btw. this is exactly what we have manually done in our previous example. 
 
 
 
 
 
 
$$\left(\begin{array}{cc} y_1\\y_2\\y_3\\y_4\end{array}\right)=\left(\begin{array}{cc} w_{11} & w_{12} & w_{13}\\w_{21} & w_{22} & w_{23}\\w_{31} & w_{32} & w_{33}\\w_{41} &w_{42}& w_{43}\end{array}\right)\left(\begin{array}{cc} x_1\\x_2\\x_3\end{array}\right)=\left(\begin{array}{cc} w_{11} \cdot x_1 + w_{12} \cdot x_2 + w_{13} \cdot x_3\\w_{21} \cdot x_1 + w_{22} \cdot x_2 + w_{23} \cdot x_3\\w_{31} \cdot x_1 + w_{32} \cdot x_2 + w_{33}\cdot x_3\\w_{41} \cdot x_1 + w_{42} \cdot x_2 + w_{43} \cdot x_3\end{array}\right)$$
 
 
 
 
 
 
 We have a similar situation for the 'who' matrix between hidden and output layer. So the output $z_1$ and $z_2$ from the nodes $o_1$ and $o_2$ can also be calculated with matrix multiplications: 
 
 
 
 
 
 
$$ \left(\begin{array}{cc} z_1\\z_2\end{array}\right)=\left(\begin{array}{cc} wh_{11} & wh_{12} & wh_{13} & wh_{14}\\wh_{21} & wh_{22} & wh_{23} & wh_{24}\end{array}\right)\left(\begin{array}{cc} y_1\\y_2\\y_3\\y_4\end{array}\right)=\left(\begin{array}{cc} wh_{11} \cdot y_1 + wh_{12} \cdot y_2 + wh_{13} \cdot y_3 + wh_{14} \cdot y_4\\wh_{21} \cdot y_1 + wh_{22} \cdot y_2 + wh_{23} \cdot y_3 + wh_{24} \cdot y_4\end{array}\right)$$ 
 
 
 
 
 
 
 You might have noticed that something is missing in our previous calculations. We showed in our introductory chapter  Neural Networks from Scratch in Python  that we have to apply an activation or step function $\Phi$ on each of these sums. 
 The following picture depicts the whole flow of calculation, i.e. the matrix multiplication and the succeeding multiplication. 
The matrix multiplication between the matrix wih and the matrix of the values of the input nodes $x_1, x_2, x_3$ calculates the output which will be passed to the activation function. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 The final output $y_1, y_2, y_3, y_4$ is the input of the weight matrix who: 
 
 
 
 
 
 
 Even though treatment is completely analogue, we will also have a detailled look at what is going on between our hidden layer and the output layer: 
 
 
 
 
 
 
 
 
 
 
 
 
 
 Initializing the weight matrices One of the important choices which have to be made before training a neural network consists in initializing the weight matrices. We don't know anything about the possible weight, when we start. So, we could start with arbitrary values? 
 As we have seen the input to all the nodes except the input nodes is calculated by applying the activation function to the following sum: 
$$y_j = \sum_{i=1}^{n} w_{ji} \cdot x_i$$ (with n being the number of nodes in the previous layer and $y_j$ is the input to a node of the next layer) 
 We can easily see that it would not be a good idea to set all the weight values to 0, because in this case the result of this  summation will always be zero. This means that our network will be incapable of learning. This is the worst choice, but initializing a weight matrix to ones is also a bad choice. 
 The values for the weight matrices should be chosen randomly and not arbitrarily. By choosing a random normal distribution we have broken possible symmetric situations, which are bad for the learning process. 
 There are various ways to initialize the weight matrices randomly. 
The first one we will introduce is the unity function from numpy.random. It creates samples which are uniformly distributed over the half-open interval [low, high), which means that low is included and  high is excluded.  Each value within the given interval is equally likely to be drawn by 'uniform'. 
 
 
 
 
 
 
 
 
 import   numpy   as   np 

 number_of_samples   =   1200 
 low   =   - 1 
 high   =   0 
 s   =   np . random . uniform ( low ,   high ,   number_of_samples ) 

 # all values of s are within the half open interval [-1, 0) : 

 print ( np . all ( s   >=   - 1 )   and   np . all ( s   = 0 and p is 
a float in the interval [0,1]. (n may be input as a float, but it is 
truncated to an integer in use) 
 
 
 
 
 
 
 
 
 s   =   np . random . binomial ( 100 ,   0.5 ,   1200 ) 
 plt . hist ( s ) 
 plt . show () 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 We like to create random numbers with a normal distribution, but the numbers have to be bounded. This is not the case with np.random.normal(), because it doesn't offer any bound parameter. 
 We can use truncnorm from scipy.stats for this purpose. 
 The standard form of this distribution is a standard normal truncated to the range [a, b] — notice that a and b are defined over the domain of the standard normal. To convert clip values for a specific mean and standard deviation, use: 
 a, b = (myclip_a - my_mean) / my_std, (myclip_b - my_mean) / my_std 
 
 
 
 
 
 
 
 
 from   scipy.stats   import   truncnorm 

 s   =   truncnorm ( a =- 2 / 3. ,   b = 2 / 3. ,   scale = 1 ,   loc = 0 ) . rvs ( size = 1000 ) 

 plt . hist ( s ) 
 plt . show () 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 The function 'truncnorm' is difficult to use.  To make life easier, we define a function 'truncated_normal' in the following to fascilitate this task: 
 
 
 
 
 
 
 
 
 def   truncated_normal ( mean = 0 ,   sd = 1 ,   low = 0 ,   upp = 10 ): 
     return   truncnorm ( 
         ( low   -   mean )   /   sd ,   ( upp   -   mean )   /   sd ,   loc = mean ,   scale = sd ) 

 X   =   truncated_normal ( mean = 0 ,   sd = 0.4 ,   low =- 0.5 ,   upp = 0.5 ) 
 s   =   X . rvs ( 10000 ) 

 plt . hist ( s ) 
 plt . show () 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 Further examples: 
 
 
 
 
 
 
 
 
 X1   =   truncated_normal ( mean = 2 ,   sd = 1 ,   low = 1 ,   upp = 10 ) 
 X2   =   truncated_normal ( mean = 5.5 ,   sd = 1 ,   low = 1 ,   upp = 10 ) 
 X3   =   truncated_normal ( mean = 8 ,   sd = 1 ,   low = 1 ,   upp = 10 ) 

 import   matplotlib.pyplot   as   plt 
 fig ,   ax   =   plt . subplots ( 3 ,   sharex = True ) 
 ax [ 0 ] . hist ( X1 . rvs ( 10000 ),   normed = True ) 
 ax [ 1 ] . hist ( X2 . rvs ( 10000 ),   normed = True ) 
 ax [ 2 ] . hist ( X3 . rvs ( 10000 ),   normed = True ) 
 plt . show () 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 We will create the link weights matrix now. 'truncated_normal' is ideal for this purpose. 
It is a good idea to choose random values from within the interval 
$$(-\frac{1}{\sqrt{n}}, \frac{1}{\sqrt{n}})$$ where n denotes the number of input nodes. 
 So we can create our ""wih"" matrix with: 
 
 
 
 
 
 
 
 
 no_of_input_nodes   =   3 
 no_of_hidden_nodes   =   4 
 rad   =   1   /   np . sqrt ( no_of_input_nodes ) 

 X   =   truncated_normal ( mean = 2 ,   sd = 1 ,   low =- rad ,   upp = rad ) 
 wih   =   X . rvs (( no_of_hidden_nodes ,   no_of_input_nodes )) 
 wih 
 
 
 
 
 
 
 
 Output:: 
 
 array([[-0.356241  ,  0.46875865,  0.41897957],
       [ 0.43267439, -0.10009341,  0.35524547],
       [ 0.45234311,  0.39339294,  0.365379  ],
       [ 0.49457071, -0.44498887,  0.47409918]]) 
 
 
 
 
 
 
 
 
 Similarly, we can now define the ""who"" weight matrix: 
 
 
 
 
 
 
 
 
 no_of_hidden_nodes   =   4 
 no_of_output_nodes   =   2 
 rad   =   1   /   np . sqrt ( no_of_hidden_nodes )    # this is the input in this layer! 

 X   =   truncated_normal ( mean = 2 ,   sd = 1 ,   low =- rad ,   upp = rad ) 
 who   =   X . rvs (( no_of_output_nodes ,   no_of_hidden_nodes )) 
 who 
 
 
 
 
 
 
 
 Output:: 
 
 array([[ 0.03743593,  0.34516431,  0.11852342, -0.10899819],
       [ 0.11039838,  0.41685055, -0.39363526,  0.07941089]]) 
 
 
 
 
 
 
 
 
 A Neural Network Class 
 
 
 
 
 
 
 We are ready now to start with the implementation of our neural network in Python. We will need to define the train and run method later. Instead of defining the weight matrices within the __init__ method of our Python class, we define them in a sparate method for reasons of clarity: 
 
 
 
 
 
 
 
 
 import   numpy   as   np 

 class   NeuralNetwork : 
    
     def   __init__ ( self ,  
                  no_of_in_nodes ,  
                  no_of_out_nodes ,  
                  no_of_hidden_nodes , 
                  learning_rate ): 
         self . no_of_in_nodes   =   no_of_in_nodes 
         self . no_of_out_nodes   =   no_of_out_nodes  
         self . no_of_hidden_nodes   =   no_of_hidden_nodes 
         self . learning_rate   =   learning_rate   
         self . create_weight_matrices () 


        
     def   create_weight_matrices ( self ): 

         rad   =   1   /   np . sqrt ( self . no_of_in_nodes ) 
         X   =   truncated_normal ( mean = 0 ,   sd = 1 ,   low =- rad ,   upp = rad ) 
         self . weights_in_hidden   =   X . rvs (( self . no_of_hidden_nodes ,  
                                        self . no_of_in_nodes )) 

         rad   =   1   /   np . sqrt ( self . no_of_hidden_nodes ) 
         X   =   truncated_normal ( mean = 0 ,   sd = 1 ,   low =- rad ,   upp = rad ) 
         self . weights_hidden_out   =   X . rvs (( self . no_of_out_nodes ,  
                                         self . no_of_hidden_nodes )) 
             
    
     def   train ( self ): 
         pass 
    
     def   run ( self ): 
         pass 
    

    
 if   __name__   ==   ""__main__"" : 
     simple_network   =   NeuralNetwork ( no_of_in_nodes   =   3 ,  
                                    no_of_out_nodes   =   2 ,  
                                    no_of_hidden_nodes   =   4 , 
                                    learning_rate   =   0.1 ) 
     print ( simple_network . weights_in_hidden ) 
     print ( simple_network . weights_hidden_out ) 
 
 
 
 
 
 
 
 
 
 [[ 0.10607641 -0.05716482  0.55752363]
 [ 0.33701589  0.05461437  0.5521666 ]
 [ 0.11990863 -0.29320233 -0.43600856]
 [-0.18218775 -0.20794852 -0.39419628]]
[[  4.82634085e-04  -4.97611184e-01  -3.25708215e-01  -2.61086173e-01]
 [ -2.04995922e-01  -7.08439635e-02   2.66347839e-01   4.87601670e-01]]
 
 
 
 
 
 
 
 
 
 Activation Functions, Sigmoid and ReLU Running our neural network on some input means that we will have a matrix multiplications of the weight vectors and the inputs. We have to apply an activation function on the output values. There are lots of different activation functions used in neural networks. The sigmoid function belongs to the most often used activation functions. 
 It is defined as 
$$\sigma(x) = \frac{1}{1+e^{-x}}$$ 
 Let us have a look at the graph of the sigmoid function. We use matplotlib to plot the sigmoid function: 
 
 
 
 
 
 
 
 
 import   numpy   as   np 
 import   matplotlib.pyplot   as   plt 
 def   sigma ( x ): 
     return   1   /   ( 1   +   np . exp ( - x )) 

 X   =   np . linspace ( - 5 ,   5 ,   100 ) 


 plt . plot ( X ,   sigma ( X ), 'b' ) 
 plt . xlabel ( 'X Axis' ) 
 plt . ylabel ( 'Y Axis' ) 
 plt . title ( 'Sigmoid Function' ) 

 plt . grid () 

 plt . text ( 4 ,   0.8 ,   r '$\sigma(x)=\frac {1} {1+e^{-x}}$' ,   fontsize = 16 ) 


 plt . show () 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 Instead of defining the sigmoid function ourselves, we can use the expit function from scipy.special, which is an implementation of the sigmoid function. It can be applied on various data classes like int, float, list, numpy,ndarray and so on. The result is an ndarray of the same shape as the input data x. 
 
 
 
 
 
 
 
 
 from   scipy.special   import   expit 
 print ( expit ( 3.4 )) 
 print ( expit ([ 3 ,   4 ,   1 ])) 
 print ( expit ( np . array ([ 0.8 ,   2.3 ,   8 ]))) 
 
 
 
 
 
 
 
 
 
 0.967704535302
[ 0.95257413  0.98201379  0.73105858]
[ 0.68997448  0.90887704  0.99966465]
 
 
 
 
 
 
 
 
 
 Adding a run Method We can use this as the activation function of our neural network. As you most probably know, we can directly assign a new name, when we import the function: 
 
 
 
 
 
 
 
 
 from   scipy.special   import   expit   as   activation_function 
 
 
 
 
 
 
 
 
 
 
 import   numpy   as   np 
 from   scipy.special   import   expit   as   activation_function 
 from   scipy.stats   import   truncnorm 

 def   truncated_normal ( mean = 0 ,   sd = 1 ,   low = 0 ,   upp = 10 ): 
     return   truncnorm ( 
         ( low   -   mean )   /   sd ,   ( upp   -   mean )   /   sd ,   loc = mean ,   scale = sd ) 


 class   NeuralNetwork : 
           
     def   __init__ ( self ,  
                  no_of_in_nodes ,  
                  no_of_out_nodes ,  
                  no_of_hidden_nodes , 
                  learning_rate ): 
         self . no_of_in_nodes   =   no_of_in_nodes 
         self . no_of_out_nodes   =   no_of_out_nodes 
         self . no_of_hidden_nodes   =   no_of_hidden_nodes 
         self . learning_rate   =   learning_rate  
         self . create_weight_matrices () 
        
     def   create_weight_matrices ( self ): 
         """""" A method to initialize the weight matrices of the neural network"""""" 
         rad   =   1   /   np . sqrt ( self . no_of_in_nodes ) 
         X   =   truncated_normal ( mean = 0 ,   sd = 1 ,   low =- rad ,   upp = rad ) 
         self . weights_in_hidden   =   X . rvs (( self . no_of_hidden_nodes ,  
                                        self . no_of_in_nodes )) 
         rad   =   1   /   np . sqrt ( self . no_of_hidden_nodes ) 
         X   =   truncated_normal ( mean = 0 ,   sd = 1 ,   low =- rad ,   upp = rad ) 
         self . weights_hidden_out   =   X . rvs (( self . no_of_out_nodes ,  
                                         self . no_of_hidden_nodes )) 
    
    
     def   train ( self ,   input_vector ,   target_vector ): 
         pass 
            
    
     def   run ( self ,   input_vector ): 
         """""" 
         running the network with an input vector input_vector.  
         input_vector can be tuple, list or ndarray 
         """""" 
        
         # turning the input vector into a column vector 
         input_vector   =   np . array ( input_vector ,   ndmin = 2 ) . T 

         output_vector   =   np . dot ( self . weights_in_hidden ,   input_vector ) 
         output_vector   =   activation_function ( output_vector ) 
        
         output_vector   =   np . dot ( self . weights_hidden_out ,   output_vector ) 
         output_vector   =   activation_function ( output_vector ) 
    
         return   output_vector 
            
 
 
 
 
 
 
 
 
 There is still a train method missing. We can instantiate and run this network, but the results will not make sense. They are based on the random weight matrices: 
 
 
 
 
 
 
 
 
 simple_network   =   NeuralNetwork ( no_of_in_nodes = 2 ,  
                                no_of_out_nodes = 2 ,  
                                no_of_hidden_nodes = 10 , 
                                learning_rate = 0.6 ) 

 simple_network . run ([( 3 ,   4 )]) 
 
 
 
 
 
 
 
 Output:: 
 
 array([[ 0.66413143],
       [ 0.45385657]]) 
 
 
 
 
 
 
 
 
 We can also define our own sigmoid function with the decorator vectorize from numpy: 
 
 
 
 
 
 
 
 
 @np . vectorize 
 def   sigmoid ( x ): 
     return   1   /   ( 1   +   np . e   **   - x ) 

 #sigmoid = np.vectorize(sigmoid) 
 sigmoid ([ 3 ,   4 ,   5 ]) 
 
 
 
 
 
 
 
 Output:: 
 
 array([ 0.95257413,  0.98201379,  0.99330715]) 
 
 
 
 
 
 
 
 
 We add training support in our next class definition, i.e. we define the method 'train': 
 
 
 
 
 
 
 
 
 import   numpy   as   np 

 @np . vectorize 
 def   sigmoid ( x ): 
     return   1   /   ( 1   +   np . e   **   - x ) 
 activation_function   =   sigmoid 

 from   scipy.stats   import   truncnorm 

 def   truncated_normal ( mean = 0 ,   sd = 1 ,   low = 0 ,   upp = 10 ): 
     return   truncnorm ( 
         ( low   -   mean )   /   sd ,   ( upp   -   mean )   /   sd ,   loc = mean ,   scale = sd ) 


 class   NeuralNetwork : 
    
     def   __init__ ( self ,  
                  no_of_in_nodes ,  
                  no_of_out_nodes ,  
                  no_of_hidden_nodes , 
                  learning_rate ): 
         self . no_of_in_nodes   =   no_of_in_nodes 
         self . no_of_out_nodes   =   no_of_out_nodes 
         self . no_of_hidden_nodes   =   no_of_hidden_nodes 
         self . learning_rate   =   learning_rate  
         self . create_weight_matrices () 
        
     def   create_weight_matrices ( self ): 
         """""" A method to initialize the weight matrices of the neural network"""""" 
         rad   =   1   /   np . sqrt ( self . no_of_in_nodes ) 
         X   =   truncated_normal ( mean = 0 ,   sd = 1 ,   low =- rad ,   upp = rad ) 
         self . weights_in_hidden   =   X . rvs (( self . no_of_hidden_nodes ,  
                                        self . no_of_in_nodes )) 
         rad   =   1   /   np . sqrt ( self . no_of_hidden_nodes ) 
         X   =   truncated_normal ( mean = 0 ,   sd = 1 ,   low =- rad ,   upp = rad ) 
         self . weights_hidden_out   =   X . rvs (( self . no_of_out_nodes ,  
                                         self . no_of_hidden_nodes )) 
        
    
     def   train ( self ,   input_vector ,   target_vector ): 
         # input_vector and target_vector can be tuple, list or ndarray 
        
         input_vector   =   np . array ( input_vector ,   ndmin = 2 ) . T 
         target_vector   =   np . array ( target_vector ,   ndmin = 2 ) . T 

        
         output_vector1   =   np . dot ( stelf . weights_in_hidden ,   input_vector ) 
         output_vector_hidden   =   activation_function ( output_vector1 ) 
        
         output_vector2   =   np . dot ( self . weights_hidden_out ,   output_vector_hidden ) 
         output_vector_network   =   activation_function ( output_vector2 ) 
        
         output_errors   =   target_vector   -   output_vector_network 
         # update the weights: 
         tmp   =   output_errors   *   output_vector_network   *   ( 1.0   -   output_vector_network )      
         tmp   =   self . learning_rate    *   np . dot ( tmp ,   output_vector_hidden . T ) 
         self . weights_hidden_out   +=   tmp 


         # calculate hidden errors: 
         hidden_errors   =   np . dot ( self . weights_hidden_out . T ,   output_errors ) 
         # update the weights: 
         tmp   =   hidden_errors   *   output_vector_hidden   *   ( 1.0   -   output_vector_hidden ) 
         self . weights_in_hidden   +=   self . learning_rate   *   np . dot ( tmp ,   input_vector . T ) 
           
    
     def   run ( self ,   input_vector ): 
         # input_vector can be tuple, list or ndarray 
         input_vector   =   np . array ( input_vector ,   ndmin = 2 ) . T 

         output_vector   =   np . dot ( self . weights_in_hidden ,   input_vector ) 
         output_vector   =   activation_function ( output_vector ) 
        
         output_vector   =   np . dot ( self . weights_hidden_out ,   output_vector ) 
         output_vector   =   activation_function ( output_vector ) 
    
         return   output_vector 
            
 
 
 
 
 
 
 
 
 We will test our network with the same example, we created in the chapter [Neural Networks from Scratch] (neural_networks.php): 
 
 
 
 
 
 
 
 
 import   numpy   as   np 
 from   matplotlib   import   pyplot   as   plt 

 data1   =   [(( 3 ,   4 ),   ( 0.99 ,   0.01 )),   (( 4.2 ,   5.3 ),   ( 0.99 ,   0.01 )),  
          (( 4 ,   3 ),   ( 0.99 ,   0.01 )),   (( 6 ,   5 ),   ( 0.99 ,   0.01 )),  
          (( 4 ,   6 ),   ( 0.99 ,   0.01 )),   (( 3.7 ,   5.8 ),   ( 0.99 ,   0.01 )),  
          (( 3.2 ,   4.6 ),   ( 0.99 ,   0.01 )),   (( 5.2 ,   5.9 ),   ( 0.99 ,   0.01 )),  
          (( 5 ,   4 ),   ( 0.99 ,   0.01 )),   (( 7 ,   4 ),   ( 0.99 ,   0.01 )),  
          (( 3 ,   7 ),   ( 0.99 ,   0.01 )),   (( 4.3 ,   4.3 ),   ( 0.99 ,   0.01 ))] 

 data2   =   [(( - 3 ,   - 4 ),   ( 0.01 ,   0.99 )),   (( - 2 ,   - 3.5 ),   ( 0.01 ,   0.99 )),  
          (( - 1 ,   - 6 ),   ( 0.01 ,   0.99 )),   (( - 3 ,   - 4.3 ),   ( 0.01 ,   0.99 )),  
          (( - 4 ,   - 5.6 ),   ( 0.01 ,   0.99 )),   (( - 3.2 ,   - 4.8 ),   ( 0.01 ,   0.99 )),  
          (( - 2.3 ,   - 4.3 ),   ( 0.01 ,   0.99 )),   (( - 2.7 ,   - 2.6 ),   ( 0.01 ,   0.99 )),  
          (( - 1.5 ,   - 3.6 ),   ( 0.01 ,   0.99 )),   (( - 3.6 ,   - 5.6 ),   ( 0.01 ,   0.99 )),  
          (( - 4.5 ,   - 4.6 ),   ( 0.01 ,   0.99 )),   (( - 3.7 ,   - 5.8 ),   ( 0.01 ,   0.99 ))] 



 data   =   data1   +   data2 
 np . random . shuffle ( data ) 

 points1 ,   labels1   =   zip ( * data1 ) 
 X ,   Y   =   zip ( * points1 ) 
 plt . scatter ( X ,   Y ,   c = ""r"" ) 

 points2 ,   labels2   =   zip ( * data2 ) 
 X ,   Y   =   zip ( * points2 ) 
 plt . scatter ( X ,   Y ,   c = ""b"" ) 
 plt . show () 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 simple_network   =   NeuralNetwork ( no_of_in_nodes = 2 ,  
                                no_of_out_nodes = 2 ,  
                                no_of_hidden_nodes = 2 , 
                                learning_rate = 0.6 ) 
    
 size_of_learn_sample   =   int ( len ( data ) * 0.9 ) 
 learn_data   =   data [: size_of_learn_sample ] 
 test_data   =   data [ - size_of_learn_sample :] 
 print () 


 for   i   in   range ( size_of_learn_sample ): 
     point ,   label   =   learn_data [ i ][ 0 ],   learn_data [ i ][ 1 ] 
     simple_network . train ( point ,   label ) 
    
 for   i   in   range ( size_of_learn_sample ): 
     point ,   label   =   learn_data [ i ][ 0 ],   learn_data [ i ][ 1 ] 
     cls1 ,   cls2   = simple_network . run ( point ) 
     print ( point ,   cls1 ,   cls2 ,   end = "": "" ) 
     if   cls1   >   cls2 : 
         if   label   ==   ( 0.99 ,   0.01 ): 
             print ( ""class1 correct"" ,   label ) 
         else : 
             print ( ""class2 incorrect"" ,   label ) 
     else : 
         if   label   ==   ( 0.01 ,   0.99 ): 
             print ( ""class1 correct"" ,   label ) 
         else : 
             print ( ""class2 incorrect"" ,   label ) 
 
 
 
 
 
 
 
 
 
 
(4.2, 5.3) [ 0.69567493] [ 0.36574485]: class1 correct (0.99, 0.01)
(4, 6) [ 0.69599417] [ 0.3655189]: class1 correct (0.99, 0.01)
(4.3, 4.3) [ 0.69465373] [ 0.36646922]: class1 correct (0.99, 0.01)
(3.2, 4.6) [ 0.69434421] [ 0.36667755]: class1 correct (0.99, 0.01)
(3, 7) [ 0.69614915] [ 0.36540844]: class1 correct (0.99, 0.01)
(4, 3) [ 0.69015391] [ 0.36965891]: class1 correct (0.99, 0.01)
(5.2, 5.9) [ 0.69614659] [ 0.36541353]: class1 correct (0.99, 0.01)
(-2.3, -4.3) [ 0.2887322] [ 0.63701291]: class1 correct (0.01, 0.99)
(-3.6, -5.6) [ 0.28571677] [ 0.63918581]: class1 correct (0.01, 0.99)
(3, 4) [ 0.69265701] [ 0.36786409]: class1 correct (0.99, 0.01)
(6, 5) [ 0.69593054] [ 0.365569]: class1 correct (0.99, 0.01)
(-1.5, -3.6) [ 0.29421745] [ 0.6330841]: class1 correct (0.01, 0.99)
(-3.7, -5.8) [ 0.2855751] [ 0.63928833]: class1 correct (0.01, 0.99)
(-2, -3.5) [ 0.29319957] [ 0.63379548]: class1 correct (0.01, 0.99)
(3.7, 5.8) [ 0.69583411] [ 0.36563081]: class1 correct (0.99, 0.01)
(5, 4) [ 0.69461572] [ 0.36650241]: class1 correct (0.99, 0.01)
(-2.7, -2.6) [ 0.29847545] [ 0.62995199]: class1 correct (0.01, 0.99)
(7, 4) [ 0.69548262] [ 0.36589335]: class1 correct (0.99, 0.01)
(-3.2, -4.8) [ 0.2866943] [ 0.63847813]: class1 correct (0.01, 0.99)
(-3, -4.3) [ 0.28781573] [ 0.63766572]: class1 correct (0.01, 0.99)
(-3, -4) [ 0.28863857] [ 0.63706791]: class1 correct (0.01, 0.99)
 
 
 
 
 
 
 
 
 
 Something to be done in a future release: We will define at a later point also different activation functions like the ReLU: 
 
 
 
 
 
 
 
 
 # alternative activation function 
 def   ReLU ( x ): 
     return   np . maximum ( 0.0 ,   x ) 

 # derivation of relu 
 def   ReLU_derivation ( x ): 
     if   x   <=   0 : 
         return   0 
     else : 
         return   1 
 
 
 
 
 
 
 
 
 
 
 import   numpy   as   np 
 import   matplotlib.pyplot   as   plt 

 X   =   np . linspace ( - 5 ,   5 ,   100 ) 
 plt . plot ( X ,   ReLU ( X ), 'b' ) 
 plt . xlabel ( 'X Axis' ) 
 plt . ylabel ( 'Y Axis' ) 
 plt . title ( 'ReLU Function' ) 
 plt . grid () 
 plt . text ( 3 ,   0.8 ,   r '$ReLU(x)=max(0.0, x)$' ,   fontsize = 16 ) 
 plt . show () 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 Neural Network with Bias Nodes A bias node is a node that is always returning the same output. In other words: It is a node which is not depending on some input and it does not have any input. The value of a bias node is often set to one, but it can be other values as well. Except 0 which doesn't make sense. If a neural network does not have a bias node in a given layer, it will not be able to produce output in the next layer that differs from 0 when the feature values are 0. Generally speaking, we can say that bias nodes are used to increase the flexibility of the network to fit the data. Usually, there will be not more than one bias node per layer. The only exception is the output layer, because it makes no sense to add a bias node to this layer. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 We can see from this diagram that our weight matrix will have one more column and the bias value is added to the input vector: 
 
 
 
 
 
 
 
 
 
 
 
 
 
 Again, the situation for the weight matrix between the hidden and the outputlayer is similar: 
 
 
 
 
 
 
 
 
 
 
 
 
 
 The same is true for the corresponding matrix: 
 
 
 
 
 
 
 
 
 
 
 
 
 
 The following is a complete Python class implementing our network with bias nodes: 
 
 
 
 
 
 
 
 
 import   numpy   as   np 

 @np . vectorize 
 def   sigmoid ( x ): 
     return   1   /   ( 1   +   np . e   **   - x ) 
 activation_function   =   sigmoid 

 from   scipy.stats   import   truncnorm 

 def   truncated_normal ( mean = 0 ,   sd = 1 ,   low = 0 ,   upp = 10 ): 
     return   truncnorm ( 
         ( low   -   mean )   /   sd ,   ( upp   -   mean )   /   sd ,   loc = mean ,   scale = sd ) 


 class   NeuralNetwork : 
        
    
     def   __init__ ( self ,  
                  no_of_in_nodes ,  
                  no_of_out_nodes ,  
                  no_of_hidden_nodes , 
                  learning_rate , 
                  bias = None 
                 ):   

         self . no_of_in_nodes   =   no_of_in_nodes 
         self . no_of_out_nodes   =   no_of_out_nodes 
        
         self . no_of_hidden_nodes   =   no_of_hidden_nodes 
            
         self . learning_rate   =   learning_rate  
         self . bias   =   bias 
         self . create_weight_matrices () 
    
        
    
     def   create_weight_matrices ( self ): 
         """""" A method to initialize the weight matrices of the neural  
         network with optional bias nodes"""""" 
        
         bias_node   =   1   if   self . bias   else   0 
        
         rad   =   1   /   np . sqrt ( self . no_of_in_nodes   +   bias_node ) 
         X   =   truncated_normal ( mean = 0 ,   sd = 1 ,   low =- rad ,   upp = rad ) 
         self . weights_in_hidden   =   X . rvs (( self . no_of_hidden_nodes ,  
                                        self . no_of_in_nodes   +   bias_node )) 

         rad   =   1   /   np . sqrt ( self . no_of_hidden_nodes   +   bias_node ) 
         X   =   truncated_normal ( mean = 0 ,   sd = 1 ,   low =- rad ,   upp = rad ) 
         self . weights_hidden_out   =   X . rvs (( self . no_of_out_nodes ,  
                                         self . no_of_hidden_nodes   +   bias_node )) 
        
        
        
     def   train ( self ,   input_vector ,   target_vector ): 
         # input_vector and target_vector can be tuple, list or ndarray 
        
         bias_node   =   1   if   self . bias   else   0 
         if   self . bias : 
             # adding bias node to the end of the inpuy_vector 
             input_vector   =   np . concatenate (   ( input_vector ,   [ self . bias ])   ) 
                                    
            
         input_vector   =   np . array ( input_vector ,   ndmin = 2 ) . T 
         target_vector   =   np . array ( target_vector ,   ndmin = 2 ) . T 

        
         output_vector1   =   np . dot ( self . weights_in_hidden ,   input_vector ) 
         output_vector_hidden   =   activation_function ( output_vector1 ) 
        
         if   self . bias : 
             output_vector_hidden   =   np . concatenate (   ( output_vector_hidden ,   [[ self . bias ]])   ) 
        
        
         output_vector2   =   np . dot ( self . weights_hidden_out ,   output_vector_hidden ) 
         output_vector_network   =   activation_function ( output_vector2 ) 
        
         output_errors   =   target_vector   -   output_vector_network 
         # update the weights: 
         tmp   =   output_errors   *   output_vector_network   *   ( 1.0   -   output_vector_network )      
         tmp   =   self . learning_rate    *   np . dot ( tmp ,   output_vector_hidden . T ) 
         self . weights_hidden_out   +=   tmp 


         # calculate hidden errors: 
         hidden_errors   =   np . dot ( self . weights_hidden_out . T ,   output_errors ) 
         # update the weights: 
         tmp   =   hidden_errors   *   output_vector_hidden   *   ( 1.0   -   output_vector_hidden ) 
         if   self . bias : 
             x   =   np . dot ( tmp ,   input_vector . T )[: - 1 ,:]       # ???? last element cut off, ??? 
         else : 
             x   =   np . dot ( tmp ,   input_vector . T ) 
         self . weights_in_hidden   +=   self . learning_rate   *   x 
        
       
    
     def   run ( self ,   input_vector ): 
         # input_vector can be tuple, list or ndarray 
        
         if   self . bias : 
             # adding bias node to the end of the inpuy_vector 
             input_vector   =   np . concatenate (   ( input_vector ,   [ 1 ])   ) 
         input_vector   =   np . array ( input_vector ,   ndmin = 2 ) . T 

         output_vector   =   np . dot ( self . weights_in_hidden ,   input_vector ) 
         output_vector   =   activation_function ( output_vector ) 
        
         if   self . bias : 
             output_vector   =   np . concatenate (   ( output_vector ,   [[ 1 ]])   ) 
            

         output_vector   =   np . dot ( self . weights_hidden_out ,   output_vector ) 
         output_vector   =   activation_function ( output_vector ) 
    
         return   output_vector 
            
    

    
 
 
 
 
 
 
 
 
 
 
 class1   =   [( 3 ,   4 ),   ( 4.2 ,   5.3 ),   ( 4 ,   3 ),   ( 6 ,   5 ),   ( 4 ,   6 ),   ( 3.7 ,   5.8 ), 
           ( 3.2 ,   4.6 ),   ( 5.2 ,   5.9 ),   ( 5 ,   4 ),   ( 7 ,   4 ),   ( 3 ,   7 ),   ( 4.3 ,   4.3 )   ]  
 class2   =   [( - 3 ,   - 4 ),   ( - 2 ,   - 3.5 ),   ( - 1 ,   - 6 ),   ( - 3 ,   - 4.3 ),   ( - 4 ,   - 5.6 ),  
           ( - 3.2 ,   - 4.8 ),   ( - 2.3 ,   - 4.3 ),   ( - 2.7 ,   - 2.6 ),   ( - 1.5 ,   - 3.6 ),  
           ( - 3.6 ,   - 5.6 ),   ( - 4.5 ,   - 4.6 ),   ( - 3.7 ,   - 5.8 )   ] 

 labeled_data   =   [] 
 for   el   in   class1 : 
     labeled_data . append (   [ el ,   [ 1 ,   0 ]]) 
 for   el   in   class2 : 
     labeled_data . append ([ el ,   [ 0 ,   1 ]]) 
  

 np . random . shuffle ( labeled_data ) 
 print ( labeled_data [: 10 ]) 

 data ,   labels   =   zip ( * labeled_data ) 
 labels   =   np . array ( labels ) 
 data   =   np . array ( data ) 
 
 
 
 
 
 
 
 
 
 [[(-1, -6), [0, 1]], [(-2.3, -4.3), [0, 1]], [(-3, -4), [0, 1]], [(-2, -3.5), [0, 1]], [(3.2, 4.6), [1, 0]], [(-3.7, -5.8), [0, 1]], [(4, 3), [1, 0]], [(4, 6), [1, 0]], [(3.7, 5.8), [1, 0]], [(5.2, 5.9), [1, 0]]]
 
 
 
 
 
 
 
 
 
 
 
 simple_network   =   NeuralNetwork ( no_of_in_nodes = 2 ,  
                                no_of_out_nodes = 2 ,  
                                no_of_hidden_nodes = 10 , 
                                learning_rate = 0.1 , 
                                bias = None ) 
    
 for   _   in   range ( 20 ): 
     for   i   in   range ( len ( data )): 
         simple_network . train ( data [ i ],   labels [ i ]) 
 for   i   in   range ( len ( data )): 
     print ( labels [ i ]) 
     print ( simple_network . run ( data [ i ])) 
 
 
 
 
 
 
 
 
 
 [0 1]
[[ 0.06857234]
 [ 0.93333256]]
[0 1]
[[ 0.0694426 ]
 [ 0.93263667]]
[0 1]
[[ 0.06890567]
 [ 0.93314354]]
[0 1]
[[ 0.07398586]
 [ 0.92826171]]
[1 0]
[[ 0.91353761]
 [ 0.08620027]]
[0 1]
[[ 0.06598966]
 [ 0.93595685]]
[1 0]
[[ 0.90963169]
 [ 0.09022392]]
[1 0]
[[ 0.9155282 ]
 [ 0.08423438]]
[1 0]
[[ 0.91531178]
 [ 0.08444738]]
[1 0]
[[ 0.91575254]
 [ 0.08401871]]
[1 0]
[[ 0.91164767]
 [ 0.08807266]]
[0 1]
[[ 0.06818507]
 [ 0.93384242]]
[0 1]
[[ 0.07609557]
 [ 0.92620649]]
[0 1]
[[ 0.06651258]
 [ 0.93543384]]
[1 0]
[[ 0.91411049]
 [ 0.08570024]]
[1 0]
[[ 0.91409934]
 [ 0.08567811]]
[0 1]
[[ 0.06711438]
 [ 0.93487441]]
[1 0]
[[ 0.91517701]
 [ 0.08458689]]
[1 0]
[[ 0.91550873]
 [ 0.08427926]]
[1 0]
[[ 0.91562321]
 [ 0.08414424]]
[0 1]
[[ 0.06613625]
 [ 0.93581576]]
[0 1]
[[ 0.0659944]
 [ 0.9359505]]
[0 1]
[[ 0.07744433]
 [ 0.92481335]]
[1 0]
[[ 0.91498511]
 [ 0.08485322]]
 
 
 
 
 
 
 
 
 In [ ]: 
 
 
  
 
 
 
 
 
 Previous Chapter:  Neural Networks from Scratch in Python 
 Next Chapter:  Backpropagation in Neural Networks 
 
   © 2011 - 2019, Bernd Klein,
Bodenseo; 
Design by Denise Mitchinson adapted for python-course.eu by Bernd Klein "," None,Introduction,None,None,None,Weights and Matrices,None,None,None,None,None,None,None,None,None,None,None,None,None,None,Initializing the weight matrices,None,None,None,None,None,None,None,A Neural Network Class,None,Activation Functions, Sigmoid and ReLU,None,Adding a run Method,None,None,None,None,None,Neural Network with Bias Nodes,None,None,None,None,None,None,None,None,", https://www.python-course.eu/http://www.python-kurs.eu/stellengesuch/Stellenanzeige.pdf
4,Backpropagation in Neural Networks,https://www.python-course.eu/neural_networks_backpropagation.php,"Machine Learning with Python: Backpropagation in Neural Network 
 
 
 
 - remove in and out prompt from ipython notebook 
%%HTML

div.prompt {display:none}

 - 
 
 
 
 
 Python Machine Learning Tutorial 
 
  Begin Top Menu  
 
 Home Python 2 Tutorial Python 3 Tutorial Advanced Topics Numerical Programming Machine Learning Tkinter Tutorial Contact 
 
  End Top Menu  
 Machine Learning 
 
 
 Machine Learning Terminology k-nearest Neighbor Classifier Neural Networks from Scratch in Python Neural Network in Python using Numpy Backpropagation in Neural Networks Confusion Matrix Training and Testing with MNIST Dropout Neural Networks Neural Networks with Scikit Machine Learning with Scikit and Python Introduction Naive Bayes Classifier Naive Bayes Classifier with Scikit Introduction into Text Classification using Naive Bayes Python Implementation of Text Classification Decision Trees Regression Trees Random Forests Boosting Algorithm Principal Component Analysis Linear Discriminant Analysis Expectation Maximization and Gaussian Mixture Model Introduction into TensorFlow 
 
 
 
 Help Needed 

This website is free of annoying ads. We want to keep it like this. You can help with your donation:
 
 
 
 
 
 
 
 
 The need for donations 
 
 
 
 
 Quotes 
 ""Neural computing is the study of cellular networks that have a natural property for storing experimental knowledge. Such systems bear a resemblance to the brain in the sense that knowledge is acquired through training rather than programming and is retained due to changes in node functions. The knowledge takes the form of stable states or cycles of states in the operation of the et. A central property of such nets is to recall these states or cycles in response to the presentation of cues."" 
 
(Aleksander & Morton, 1989,  ""Neural computing architectures: the design of brain-like machines."", p.2 as cited in: M.A. Lovell et al. (1997) Developments in petrophysics. p.169
 
 
 
 
""Cognitive neuroscience is entering an exciting era in which new technologies and ideas are making it possible to study the neural basis of cognition, perception, memory and emotion at the level of networks of interacting neurons, the level at which we believe many of the important operations of the brain take place. We know a considerable amount about how individual neurons work and how two cells can communicate with each other but the way in which entire networks of hundreds and thousands of neurons cooperate, interact with each other, and are orchestrated to create our ideas and concepts is an underexplored area of neuroscience. ""
 
(John O'Keefe, from his speech at the Nobel Banquet, 10 December 2014)
 
 
 
 
This website is created by: 
Bernd Klein,  Python Training Courses 
 
On site trainings in Europe, Canada and the US.
 
 
 
  Dieses Tag dort einfügen, wo die +1-Schaltfläche dargestellt werden soll  
 
 
 Help Needed 

This website is free of annoying ads. We want to keep it like this. You can help with your donation:
 
 
 
 
 
 
 
 
 
 The need for donations 
 
 Job Applications 
 
 Python Lecturer 
 bodenseo is looking for a new trainer and software developper. You need to live in Germany and know German. Interested? Find out  more !
 Python Programmer 
We are looking for a qualified Python programmer to further improve our website. This is a work from home job, wherever you live in the world! 
If you think that you are the right person or if you have further questions, please do not hesitate to  contact us .
 
 
 
 Bernd Klein on Facebook 
 
 
 
Search this website:
 
 
 
 Classroom Training Courses 
 
This website contains a free and extensive online tutorial by Bernd Klein, using
material from his classroom Python training courses Python classes 
 
 © kabliczech - Fotolia.com Quote of the Day: ""Space is big. You just won't believe how vastly, hugely, mind-bogglingly big it is. I mean, you may think it's a long way down the road to the chemist's, but that's just peanuts to space.""  (Douglas Adams, The Hitchhiker's Guide to the Galaxy)
   Help Needed 
 
 
 
 
 
 The need for donations Data Protection Declaration Data Protection Declaration 
 Previous Chapter:  Neural Network in Python using Numpy 
 Next Chapter:  Confusion Matrix 
 
 
 
 
 Backpropagation in Neural Networks 
 Introduction 
 We have already written Neural Networks in Python in the previous chapters of our tutorial. We could train these networks, but we didn't explain the mechanism used for training. We used backpropagation without saying so. Backpropagation is a commonly used method for training artificial neural networks, especially deep neural networks. Backpropagation is needed to calculate the gradient, which we need to adapt the weights of the weight matrices. The weight of the neuron (nodes) of our network are adjusted by calculating the gradient of the loss function. For this purpose a gradient descent optimization algorithm is used. It is also called backward propagation of errors. 
 Quite often people are frightened away by the mathematics used in it. 
We try to explain it in simple terms. 
 Explaining gradient descent starts in many articles or tutorials with mountains. Imagine you are put on a mountain, not necessarily the top, by a helicopter at night or heavy fog. Let's further imagine that this mountain is on an island and you want to reach sea level. You have to go down, but you hardly see anything, maybe just a few metres. Your task is to find your way down, but you cannot see the path.   You can use the method of gradient descent. This means that you are examining the steepness at your current position. You will proceed in the direction with the steepest descent. You take only a few steps and then you stop again to reorientate yourself. This means you are applying again the previously described procedure, i.e. you are looking for the steepest descend. 
 This procedure is depicted in the following diagram in a two-dimensional space. 
 
 Going on like this you will arrive at a position, where there is no further descend. 
 Each directions goes upwards. You may have reached the deepest level - the global minimum -,  but you might as well be stuck in a basin.
If you start at the position on the right side of our image, everything works out fine, but from the leftside, you will be stuck in a local minimum. If you imagine now, - not very realistic - you are dropped many time at random places on this island, you will find ways downwards to sea level. This is what we actually do, when we train a neural network. 
 
 
 
 
 
 
 
 Backpropagation in Detail Now, we have to go into the details, i.e. the mathematics. 
 We will start with the simpler case. We look at a linear network. Linear neural networks are networks where the output signal is created by summing up all the weighted input signals. No activation function will be applied to this sum, which is the reason for the linearity. 
 The will use the following simple network. 
 
 We have labels, i.e. target or desired values $t_i$ for each output value $o_i$. Principially, the error is the difference between the target and the actual output: 
$$e_i = t_i - o_i$$ We will later use a squared error function, because it has better characteristics for the algorithm: 
$$e_i = \frac{1}{2}  ( t_i - o_i ) ^ 2   $$ 
 We will have a look at the output value $o_1$, which is depending on the values $w_{11}$, $w_{21}$, $w_{31}$ and $w_{41}$. Let's assume the calculated value ($o_1$) is 0.92 and the desired value ($t_1$) is 1. In this case the error is 
$$e_1 = t_1 - o_1 = 1 - 0.92 = 0.08$$ Depending on this error, we have to change the weights from the incoming values accordingly. We have four weights, so we could spread the error evenly. Yet, it makes more sense to to do it proportionally, according to the weight values. This means that we can calculate the fraction of the error $e_1$ in $w_{11}$ as: 
$$e_1 \cdot \frac{w_{11}}{\sum_{i=1}^{4} w_{i1}}$$ This means in our example: 
$$0.08 \cdot \frac{0.6}{0.6 + 0.4 + 0.1 + 0.2} = 0.037$$ The total error in our weight matrix between the hidden and the output layer - we called it in our previous chapter 'who' -  looks like this 
$$
e_{who} = 
\begin{bmatrix}
    \frac{w_{11}}{\sum_{i=1}^{4} w_{i1}} & \frac{w_{12}}{\sum_{i=1}^{4} w_{i1}}  \\
    \frac{w_{21}}{\sum_{i=1}^{4} w_{i1}} & \frac{w_{22}}{\sum_{i=1}^{4} w_{i1}}  \\
    \frac{w_{31}}{\sum_{i=1}^{4} w_{i1}} & \frac{w_{32}}{\sum_{i=1}^{4} w_{i1}}  \\
        \frac{w_{41}}{\sum_{i=1}^{4} w_{i1}} & \frac{w_{22}}{\sum_{i=1}^{4} w_{i1}}  \\
\end{bmatrix}
\cdot
\begin{bmatrix}
    e_1 \\
    e_2
\end{bmatrix}
$$ You can see that the denominator in the left matrix is always the same. It is a scaling factor. We can drop it so that the calculation gets a lot simpler: 
$$
e_{who} = 
\begin{bmatrix}
    w_{11} & w_{12}  \\
    w_{21} & w_{22}  \\
    w_{31} & w_{32}  \\
    w_{41} & w_{22}  \\
\end{bmatrix}
\cdot
\begin{bmatrix}
    e_1 \\
    e_2
\end{bmatrix}
$$ If you compare the matrix on the right side with the 'who' matrix of our chapter  Neuronal Network Using Python and Numpy , you will notice that it is the transpose of 'who'. 
$$e_{who} = who.T \cdot e$$ So, this has been the easy part for linear neural networks. 
 
 
 
 
 
 
 We want to calculate the error in a network with an activation function, i.e. a non-linear network. The derivation of the error function describes the slope. As we mentioned in the beginning of the this chapter, we want to descend. The derivation describes how the error $E$ changes as the weight $w_{ij}$ changes: 
$$\frac{\partial E}{\partial w_{ij}}$$ The error function E over all the output nodes $o_j$ ($j = 1, ... n$) where $n$ is the number of output nodes is: 
$$E = \sum_{j=1}^{n} \frac{1}{2} (t_j - o_j)^2$$ Now, we can insert this in our derivation: 
$$\frac{\partial E}{\partial w_{ij}} = \frac{\partial}{\partial w_{ij}} \frac{1}{2} \sum_{j=1}^{n} (t_j - o_j)^2$$ If you have a look at our example network, you will see that an output node $o_j$ only depends on the input signals created with the weights $w_{ij}$ with $i = 1, \ldots m$ and $m$ the number of hidden nodes. 
 This means that we can calculate the error for every output node independently of each other and we get rid of the sum. This is the error for a node j for example: 
$$\frac{\partial E}{\partial w_{ij}} = \frac{\partial}{\partial w_{ij}} \frac{1}{2} (t_j - o_j)^2$$ The value $t_j$ is a constant, because it is not depending on any input signals or weights. We can apply the chain rule for the differentiation of the previous term to simplify things: 
$$\frac{\partial E}{\partial w_{ij}} = \frac{\partial E}{\partial o_{j}} \cdot \frac{\partial o_j}{\partial w_{ij}}$$ In the previous chapter of our tutorial, we used the sigmoid function as the activation function: 
$$\sigma(x) = \frac{1}{1+e^{-x}}$$ The output node $o_j$ is calculated by applying the sigmoid function to the sum of the weighted input signals. This means that we can further simplify our differentiation term by replacing $o_j$ by this function: 
$$\frac{\partial E}{\partial w_{ij}} = (t_j - o_j) \cdot \frac{\partial }{\partial w_{ij}} \sigma(\sum_{i=1}^{m} w_{ij}h_i)$$ where $m$ is the number of hidden nodes. 
 The sigmoid function is easy to differentiate: 
$$\frac{\partial \sigma(x)}{\partial x} = \sigma(x) \cdot (1 - \sigma(x))$$ The complete differentiation looks like this now: 
$$\frac{\partial E}{\partial w_{ij}} = (t_j - o_j) \cdot  \sigma(\sum_{i=1}^{m} w_{ij}h_i) \cdot (1 -  \sigma(\sum_{i=1}^{m} w_{ij}h_i)) \frac{\partial }{\partial w_{ij}} \sum_{i=1}^{m} w_{ij}h_i $$ The last part has to be differentiated with respect to $w_{ij}$. This means that all the summands disappear and only $o_j$ is left: 
$$\frac{\partial E}{\partial w_{ij}} = (t_j - o_j) \cdot  \sigma(\sum_{i=1}^{m} w_{ij}h_i) \cdot (1 -  \sigma(\sum_{i=1}^{m} w_{ij}h_i)) \cdot o_j $$ This is what we had used in our method 'train' of our NeuralNetwork class in the previous chapter. 
 
 
 
 
 
 In [ ]: 
 
 
  
 
 
 
 
 
 Previous Chapter:  Neural Network in Python using Numpy 
 Next Chapter:  Confusion Matrix 
 
   © 2011 - 2019, Bernd Klein,
Bodenseo; 
Design by Denise Mitchinson adapted for python-course.eu by Bernd Klein "," Introduction,Backpropagation in Detail,None,", https://www.python-course.eu/http://www.python-kurs.eu/stellengesuch/Stellenanzeige.pdf
5,Confusion Matrix,https://www.python-course.eu/confusion_matrix.php,"Machine Learning with Python: Confusion Matrix in Machine Learning with Python 
 
 
 
 - remove in and out prompt from ipython notebook 
%%HTML

div.prompt {display:none}

 - 
 
 
 
 
 Python Machine Learning Tutorial 
 
  Begin Top Menu  
 
 Home Python 2 Tutorial Python 3 Tutorial Advanced Topics Numerical Programming Machine Learning Tkinter Tutorial Contact 
 
  End Top Menu  
 Machine Learning 
 
 
 Machine Learning Terminology k-nearest Neighbor Classifier Neural Networks from Scratch in Python Neural Network in Python using Numpy Backpropagation in Neural Networks Confusion Matrix Training and Testing with MNIST Dropout Neural Networks Neural Networks with Scikit Machine Learning with Scikit and Python Introduction Naive Bayes Classifier Naive Bayes Classifier with Scikit Introduction into Text Classification using Naive Bayes Python Implementation of Text Classification Decision Trees Regression Trees Random Forests Boosting Algorithm Principal Component Analysis Linear Discriminant Analysis Expectation Maximization and Gaussian Mixture Model Introduction into TensorFlow 
 
 
 
 Help Needed 

This website is free of annoying ads. We want to keep it like this. You can help with your donation:
 
 
 
 
 
 
 
 
 The need for donations 
 
 
 
 
 Quotes 
 ""The reason science really matters runs deeper still. Science is a way of life. Science is a perspective. Science is the process that takes us from confusion to understanding in a manner that’s precise, predictive and reliable — a transformation, for those lucky enough to experience it, that is empowering and emotional."" 
 
(Brian Green, New York Times, June 1, 2008)
 
 
 
 
Trinity: 
I know why you're here, Neo. I know what you've been doing... why you hardly sleep, why you live alone, and why night after night, you sit by your computer. You're looking for him. I know because I was once looking for the same thing. And when he found me, he told me I wasn't really looking for him. I was looking for an answer. It's the question, Neo. It's the question that drives us. It's the question that brought you here. You know the question, just as I did.
 
Neo: 
What is the Matrix?
 
Trinity: 
The answer is out there, Neo, and it's looking for you, and it will find you if you want it to. 
(Excerpt from the film ""Matrix"")
 
 
 
 
This website is created and maintained by: 
Bernd Klein,  
 
 
 
 
  Dieses Tag dort einfügen, wo die +1-Schaltfläche dargestellt werden soll  
 
 
 Help Needed 

This website is free of annoying ads. We want to keep it like this. You can help with your donation:
 
 
 
 
 
 
 
 
 
 The need for donations 
 
 Job Applications 
 
 Python Lecturer 
 bodenseo is looking for a new trainer and software developper. You need to live in Germany and know German. Interested? Find out  more !
 Python Programmer 
We are looking for a qualified Python programmer to further improve our website. This is a work from home job, wherever you live in the world! 
If you think that you are the right person or if you have further questions, please do not hesitate to  contact us .
 
 
 
 Bernd Klein on Facebook 
 
 
 
Search this website:
 
 
 
 Classroom Training Courses 
 
This website contains a free and extensive online tutorial by Bernd Klein, using
material from his classroom Python training courses Python classes 
 
 © kabliczech - Fotolia.com Quote of the Day: Man is the best computer we can put aboard a spacecraft...and the only one that can be mass produced with unskilled labor.  (Wernher von Braun)
 
   Help Needed 
 
 
 
 
 
 The need for donations Data Protection Declaration Data Protection Declaration 
 Previous Chapter:  Backpropagation in Neural Networks 
 Next Chapter:  Training and Testing with MNIST 
 
 
 
 
 Confusion Matrix 
 In the previous chapters of our Machine Learning tutorial ( Neural Networks with Python and Numpy  and  Neural Networks from Scratch   ) we implemented various algorithms, but we didn't properly measure the quality of the output. The main reason was that we used very simple and small datasets to learn and test. In the chapter  Neural Network: Testing with MNIST , we will work with large datasets and ten classes, so we need proper evaluations tools. We will introduce in this chapter the concepts of the confusion matrix: 
 A  confusion matrix   is a matrix (table) that can be used to measure the performance of an machine learning algorithm, usually a supervised learning one. Each row of the confusion matrix represents the instances of an actual class and each column represents the instances of a predicted class. This is the way we keep it in this chapter of our tutorial, but it can be the other way around as well, i.e. rows for predicted classes and columns for actual classes.
The name confusion matrix reflects the fact that it makes it easy for us to see what kind of confusions occur in our classification algorithms. For example the algorithms should have predicted a sample as $c_i$ because the actual class is $c_i$, but the algorithm came out with $c_j$. In this case of mislabelling the element $cm[i, j]$ will be incremented by one, when the confusion matrix is constructed. 
 We will define methods to calculate the confusion matrix, precision and recall in the following class. 
 
 2-class Case In a 2-class case, i.e. ""negative"" and ""positive"", the confusion matrix may look like this: 
 
 
 
 
 predicted 
 
 
 actual 
 
 negative 
 positive 
 
 
 negative 
 11 
 0 
 
 
 positive 
 1 
 12 
 
 
 
 The fields of the matrix mean the following: 
 
 
 
 predicted 
 
 
 actual 
 
 negative 
 positive 
 
 
 negative 
 TN True positive 
 FP False Positive 
 
 
 positive 
 FN False negative 
 TP True positive 
 
 
 
 We can define now some important performance measures used in machine learning: 
 Accuracy : 
$$AC = \frac {TN + TP}{TN + FP + FN + TP}$$ The accuracy is not always an adequate performance measure. Let us assume we have 1000 samples. 995 of these are negative and 5 are positive cases. Let us further assume we have a classifier, which classifies whatever it will be presented as negative. The accuracy will be a surprising 99.5%, even though the classifier could not recognize any positive samples. 
 Recall  aka. True Positive Rate: 
$$recall = \frac {TP}{FN + TP}$$ True Negative Rate : 
$$TNR = \frac {FP}{TN + FP}$$ Precision : 
$$precision: \frac {TP}{FP + TP} $$ 
 Multi-class Case To measure the results of machine learning algorithms, the previous confusion matrix will not be sufficient. We will need a generalization for the multi-class case. 
 Let us assume that we have a sample of 25 animals, e.g. 7 cats, 8 dogs, and 10 snakes, most probably Python snakes. 
The confusion matrix of our recognition algorithm may look like the following table: 
 
 
 
 
 predicted 
 
 
 actual 
 
 dog 
 cat 
 snake 
 
 
 dog 
 6 
 2 
 0 
 
 
 cat 
 1 
 6 
 0 
 
 
 snake 
 1 
 1 
 8 
 
 In this confusion matrix, the system correctly predicted six of the eight actual dogs, but in two cases it took a dog for a cat. The seven acutal cats were correctly recognized in six cases but in one case a cat was taken to be a dog.  Usually, it is hard to take a snake for a dog or a cat, but this is what happened to our classifier in two cases. Yet, eight out of ten snakes had been correctly recognized. (Most probably this machine learning algorithm was not written in a Python program, because Python should properly recognize its own species :-) ) 
 You can see that all correct predictions are located in the diagonal of the table, so prediction errors can be easily found in the table, as they will be represented by values outside the diagonal. 
 We can generalize this to the multi-class case. To do this we summarize over the rows and columns of the confusion matrix. Given that the matrix is oriented as above, i.e., that a given row of the matrix corresponds to specific value for the ""truth"", we have: 
$$Precision_i = \frac{M_{ii}}{\sum_j M_{ji}}$$$$Recall_i = \frac{M_{ii}}{\sum_j M_{ij}}$$ This means, precision is the fraction of cases where the algorithm correctly predicted class i out of all instances where the algorithm predicted i (correctly and incorrectly). 
recall on the other hand is the fraction of cases where the algorithm correctly predicted i out of all of the cases which are labelled as i. 
 Let us apply this to our example: 
 The precision for our animals can be calculated as 
$$precision_{dogs} = 6 / (6 + 1 + 1) = 3/4 = 0.75$$$$precision_{cats} = 6 / (2 + 6 + 1) = 6/9 = 0.67$$$$precision_{snakes} = 8 / (0 + 0 + 8) = 1$$ The recall is calculated like this: 
$$recall_{dogs} = 6 / (6 + 2 + 0) = 3/4 = 0.75$$$$recall_{cats} = 6 / (1 + 6 + 0) = 6/7 = 0.86$$$$recall_{snakes} = 8 / (1 + 1 + 8) = 4/5 = 0.8$$
 
 
 
 
 
 
 Example We are ready now to code this into Python. The following code shows a confusion matrix for a multi-class machine learning problem with ten labels, so for example an algorithms for recognizing the ten digits from handwritten characters. 
 If you are not familiar with Numpy and Numpy arrays, we recommend our tutorial on  Numpy . 
 
 
 
 
 
 
 
 
 import   numpy   as   np 

 cm   =   np . array ( 
 [[ 5825 ,      1 ,     49 ,     23 ,      7 ,     46 ,     30 ,     12 ,     21 ,     26 ], 
  [     1 ,   6654 ,     48 ,     25 ,     10 ,     32 ,     19 ,     62 ,    111 ,     10 ], 
  [     2 ,     20 ,   5561 ,     69 ,     13 ,     10 ,      2 ,     45 ,     18 ,      2 ], 
  [     6 ,     26 ,     99 ,   5786 ,      5 ,    111 ,      1 ,     41 ,    110 ,     79 ], 
  [     4 ,     10 ,     43 ,      6 ,   5533 ,     32 ,     11 ,     53 ,     34 ,     79 ], 
  [     3 ,      1 ,      2 ,     56 ,      0 ,   4954 ,     23 ,      0 ,     12 ,      5 ], 
  [    31 ,      4 ,     42 ,     22 ,     45 ,    103 ,   5806 ,      3 ,     34 ,      3 ], 
  [     0 ,      4 ,     30 ,     29 ,      5 ,      6 ,      0 ,   5817 ,      2 ,     28 ], 
  [    35 ,      6 ,     63 ,     58 ,      8 ,     59 ,     26 ,     13 ,   5394 ,     24 ], 
  [    16 ,     16 ,     21 ,     57 ,    216 ,     68 ,      0 ,    219 ,    115 ,   5693 ]]) 
 
 
 
 
 
 
 
 
 The functions 'precision' and 'recall' calculate values for a label, whereas the function 'precision_macro_average' the precision for the whole classification problem calculates. 
 
 
 
 
 
 
 
 
 def   precision ( label ,   confusion_matrix ): 
     col   =   confusion_matrix [:,   label ] 
     return   confusion_matrix [ label ,   label ]   /   col . sum () 
    
 def   recall ( label ,   confusion_matrix ): 
     row   =   confusion_matrix [ label ,   :] 
     return   confusion_matrix [ label ,   label ]   /   row . sum () 

 def   precision_macro_average ( confusion_matrix ): 
     rows ,   columns   =   confusion_matrix . shape 
     sum_of_precisions   =   0 
     for   label   in   range ( rows ): 
         sum_of_precisions   +=   precision ( label ,   confusion_matrix ) 
     return   sum_of_precisions   /   rows 

 def   recall_macro_average ( confusion_matrix ): 
     rows ,   columns   =   confusion_matrix . shape 
     sum_of_recalls   =   0 
     for   label   in   range ( columns ): 
         sum_of_recalls   +=   recall ( label ,   confusion_matrix ) 
     return   sum_of_recalls   /   columns 
 
 
 
 
 
 
 
 
 
 
 print ( ""label precision recall"" ) 
 for   label   in   range ( 10 ): 
     print ( f "" {label:5d}  {precision(label, cm):9.3f} {recall(label, cm):6.3f}"" ) 
 
 
 
 
 
 
 
 
 
 label precision recall
    0     0.983  0.964
    1     0.987  0.954
    2     0.933  0.968
    3     0.944  0.924
    4     0.947  0.953
    5     0.914  0.980
    6     0.981  0.953
    7     0.928  0.982
    8     0.922  0.949
    9     0.957  0.887
 
 
 
 
 
 
 
 
 
 
 
 print ( ""precision total:"" ,   precision_macro_average ( cm )) 

 print ( ""recall total:"" ,   recall_macro_average ( cm )) 
 
 
 
 
 
 
 
 
 
 precision total: 0.949688556405
recall total: 0.951453154788
 
 
 
 
 
 
 
 
 
 
 
 def   accuracy ( confusion_matrix ): 
     diagonal_sum   =   confusion_matrix . trace () 
     sum_of_all_elements   =   confusion_matrix . sum () 
     return   diagonal_sum   /   sum_of_all_elements  
 
 
 
 
 
 
 
 
 
 
 accuracy ( cm ) 
 
 
 
 
 
 
 
 Output:: 
 
 0.95038333333333336 
 
 
 
 
 
 Previous Chapter:  Backpropagation in Neural Networks 
 Next Chapter:  Training and Testing with MNIST 
 
   © 2011 - 2019, Bernd Klein,
Bodenseo; 
Design by Denise Mitchinson adapted for python-course.eu by Bernd Klein "," None,Example,None,", https://www.python-course.eu/http://www.python-kurs.eu/stellengesuch/Stellenanzeige.pdf
6,Training and Testing with MNIST,https://www.python-course.eu/neural_network_mnist.php,"Machine Learning with Python: Training and Testing the Neural Network with MNIST data set 
 
 
 
 - remove in and out prompt from ipython notebook 
%%HTML

div.prompt {display:none}

 - 
 
 
 
 
 Python Machine Learning Tutorial 
 
  Begin Top Menu  
 
 Home Python 2 Tutorial Python 3 Tutorial Advanced Topics Numerical Programming Machine Learning Tkinter Tutorial Contact 
 
  End Top Menu  
 Machine Learning 
 
 
 Machine Learning Terminology k-nearest Neighbor Classifier Neural Networks from Scratch in Python Neural Network in Python using Numpy Backpropagation in Neural Networks Confusion Matrix Training and Testing with MNIST Dropout Neural Networks Neural Networks with Scikit Machine Learning with Scikit and Python Introduction Naive Bayes Classifier Naive Bayes Classifier with Scikit Introduction into Text Classification using Naive Bayes Python Implementation of Text Classification Decision Trees Regression Trees Random Forests Boosting Algorithm Principal Component Analysis Linear Discriminant Analysis Expectation Maximization and Gaussian Mixture Model Introduction into TensorFlow 
 
 
 
 Help Needed 

This website is free of annoying ads. We want to keep it like this. You can help with your donation:
 
 
 
 
 
 
 
 
 The need for donations 
 
 
 
 
 Quotes 
 “Artificial intelligence would be the ultimate version of Google. The ultimate search engine that would understand everything on the web. It would understand exactly what you wanted, and it would give you the right thing. We’re nowhere near doing that now. However, we can get incrementally closer to that, and that is basically what we work on.” 
 
(Larry Wall)
 
 
 
 
“Machine intelligence is the last invention that humanity will ever need to make.”
 
(Nick Bostrom)
 
 
 
 
This website is created and maintained by: 
Bernd Klein,  
 
On site trainings in Europe, Canada and the US.
 
 
 
  Dieses Tag dort einfügen, wo die +1-Schaltfläche dargestellt werden soll  
 
 
 Help Needed 

This website is free of annoying ads. We want to keep it like this. You can help with your donation:
 
 
 
 
 
 
 
 
 
 The need for donations 
 
 Job Applications 
 
 Python Lecturer 
 bodenseo is looking for a new trainer and software developper. You need to live in Germany and know German. Interested? Find out  more !
 Python Programmer 
We are looking for a qualified Python programmer to further improve our website. This is a work from home job, wherever you live in the world! 
If you think that you are the right person or if you have further questions, please do not hesitate to  contact us .
 
 
 
 Bernd Klein on Facebook 
 
 
 
Search this website:
 
 
 
 Classroom Training Courses 
 
This website contains a free and extensive online tutorial by Bernd Klein, using
material from his classroom Python training courses Python classes 
 
 © kabliczech - Fotolia.com Quote of the Day: ""Computer science is no more about computers than astronomy is about telescopes.""
(Edsger Dijkstra)
   Help Needed 
 
 
 
 
 
 The need for donations Data Protection Declaration Data Protection Declaration 
 Previous Chapter:  Confusion Matrix 
 Next Chapter:  Dropout Neural Networks 
 
 
 
 
 Neural Network 
 Using  MNIST 
 
The  MNIST database   (Modified National Institute of Standards and Technology database)  of handwritten digits consists of a training set of 60,000 examples, and a test set of 10,000 examples. It is a subset of a larger set available from NIST.  Additionally, the black and white images from NIST were size-normalized and centered to fit into a 28x28 pixel bounding box and anti-aliased, which introduced grayscale levels. 
 This database is well liked for training and testing in the field of machine learning and image processing. It is a remixed subset of the original NIST datasets. 
One half of the 60,000 training images consist of images from NIST's testing dataset and the other half from Nist's training set. The 10,000 images from the testing set  are similarly assembled. 
 The MNIST dataset is used by researchers to test and compare their research results with others. The lowest error rates in literature are as low as 0.21 percent. 1 
 
 Reading the MNIST data set The images from the data set have the size 28 x 28. They are saved in the csv data files  mnist_train.csv  and 
  mnist_test.csv . 
 Every line of these files consists of an image, i.e. 785 numbers between 0 and 255. 
 The first number of each line is the label, i.e. the digit which is depicted in the image. The following 784 numbers are the pixels of the 28 x 28 image. 
 
 
 
 
 
 
 
 
 % matplotlib  inline
 import   numpy   as   np 
 import   matplotlib.pyplot   as   plt 

 image_size   =   28   # width and length 
 no_of_different_labels   =   10   #  i.e. 0, 1, 2, 3, ..., 9 
 image_pixels   =   image_size   *   image_size 
 data_path   =   ""data/mnist/"" 
 train_data   =   np . loadtxt ( data_path   +   ""mnist_train.csv"" ,  
                         delimiter = "","" ) 
 test_data   =   np . loadtxt ( data_path   +   ""mnist_test.csv"" ,  
                        delimiter = "","" )  
 test_data [: 10 ] 
 
 
 
 
 
 
 
 Output:: 
 
 array([[7., 0., 0., ..., 0., 0., 0.],
       [2., 0., 0., ..., 0., 0., 0.],
       [1., 0., 0., ..., 0., 0., 0.],
       ...,
       [9., 0., 0., ..., 0., 0., 0.],
       [5., 0., 0., ..., 0., 0., 0.],
       [9., 0., 0., ..., 0., 0., 0.]]) 
 
 
 
 
 
 
 
 
 
 
 test_data [ test_data == 255 ] 
 test_data . shape 
 
 
 
 
 
 
 
 Output:: 
 
 (10000, 785) 
 
 
 
 
 
 
 
 
 The images of the MNIST dataset are greyscale and the pixels range between 0 and 255 including both bounding values. We will map these values into an interval from 
[0.01, 1] by multiplying each pixel by 0.99 / 255 and adding 0.01 to the result.
This way, we avoid 0 values as inputs, which are capable of preventing weight updates, as we we seen in the introductory chapter. 
 
 
 
 
 
 
 
 
 fac   =   0.99   /   255 
 train_imgs   =   np . asfarray ( train_data [:,   1 :])   *   fac   +   0.01 
 test_imgs   =   np . asfarray ( test_data [:,   1 :])   *   fac   +   0.01 

 train_labels   =   np . asfarray ( train_data [:,   : 1 ]) 
 test_labels   =   np . asfarray ( test_data [:,   : 1 ]) 
 
 
 
 
 
 
 
 
 We need the labels in our calculations in a one-hot representation. We have 10 digits from 0 to 9, i.e. lr = np.arange(10). 
 Turning a label into one-hot representation can be achieved with the command:
(lr==label).astype(np.int) 
 We demonstrate this in the following: 
 
 
 
 
 
 
 
 
 import   numpy   as   np 

 lr   =   np . arange ( 10 ) 

 for   label   in   range ( 10 ): 
     one_hot   =   ( lr == label ) . astype ( np . int ) 
     print ( ""label: "" ,   label ,   "" in one-hot representation: "" ,   one_hot ) 
 
 
 
 
 
 
 
 
 
 label:  0  in one-hot representation:  [1 0 0 0 0 0 0 0 0 0]
label:  1  in one-hot representation:  [0 1 0 0 0 0 0 0 0 0]
label:  2  in one-hot representation:  [0 0 1 0 0 0 0 0 0 0]
label:  3  in one-hot representation:  [0 0 0 1 0 0 0 0 0 0]
label:  4  in one-hot representation:  [0 0 0 0 1 0 0 0 0 0]
label:  5  in one-hot representation:  [0 0 0 0 0 1 0 0 0 0]
label:  6  in one-hot representation:  [0 0 0 0 0 0 1 0 0 0]
label:  7  in one-hot representation:  [0 0 0 0 0 0 0 1 0 0]
label:  8  in one-hot representation:  [0 0 0 0 0 0 0 0 1 0]
label:  9  in one-hot representation:  [0 0 0 0 0 0 0 0 0 1]
 
 
 
 
 
 
 
 
 
 We are ready now to turn our labelled images into one-hot representations. Instead of zeroes and one, we create 0.01 and 0.99, which will be better for our calculations: 
 
 
 
 
 
 
 
 
 lr   =   np . arange ( no_of_different_labels ) 

 # transform labels into one hot representation 
 train_labels_one_hot   =   ( lr == train_labels ) . astype ( np . float ) 
 test_labels_one_hot   =   ( lr == test_labels ) . astype ( np . float ) 

 # we don't want zeroes and ones in the labels neither: 
 train_labels_one_hot [ train_labels_one_hot == 0 ]   =   0.01 
 train_labels_one_hot [ train_labels_one_hot == 1 ]   =   0.99 
 test_labels_one_hot [ test_labels_one_hot == 0 ]   =   0.01 
 test_labels_one_hot [ test_labels_one_hot == 1 ]   =   0.99 
 
 
 
 
 
 
 
 
 Before we start using the MNIST data sets with our neural network, we will have a look at some images: 
 
 
 
 
 
 
 
 
 for   i   in   range ( 10 ): 
     img   =   train_imgs [ i ] . reshape (( 28 , 28 )) 
     plt . imshow ( img ,   cmap = ""Greys"" ) 
     plt . show () 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 Dumping the Data for Faster Reload You may have noticed that it is quite slow to read in the data from the csv files. 
 We will save the data in binary format with the dump function from the pickle module: 
 
 
 
 
 
 
 
 
 import   pickle 

 with   open ( ""data/mnist/pickled_mnist.pkl"" ,   ""bw"" )   as   fh : 
     data   =   ( train_imgs ,  
             test_imgs ,  
             train_labels , 
             test_labels , 
             train_labels_one_hot , 
             test_labels_one_hot ) 
     pickle . dump ( data ,   fh ) 
    
 
 
 
 
 
 
 
 
 We are able now to read in the data by using pickle.load. This is a lot faster than using loadtxt on the csv files: 
 
 
 
 
 
 
 
 
 import   pickle 

 with   open ( ""data/mnist/pickled_mnist.pkl"" ,   ""br"" )   as   fh : 
     data   =   pickle . load ( fh ) 

 train_imgs   =   data [ 0 ] 
 test_imgs   =   data [ 1 ] 
 train_labels   =   data [ 2 ] 
 test_labels   =   data [ 3 ] 
 train_labels_one_hot   =   data [ 4 ] 
 test_labels_one_hot   =   data [ 5 ] 

 image_size   =   28   # width and length 
 no_of_different_labels   =   10   #  i.e. 0, 1, 2, 3, ..., 9 
 image_pixels   =   image_size   *   image_size 
 
 
 
 
 
 
 
 
 
 Classifying the Data We will use the following neuronal network class for our first classification: 
 
 
 
 
 
 
 
 
 import   numpy   as   np 

 @np . vectorize 
 def   sigmoid ( x ): 
     return   1   /   ( 1   +   np . e   **   - x ) 
 activation_function   =   sigmoid 

 from   scipy.stats   import   truncnorm 

 def   truncated_normal ( mean = 0 ,   sd = 1 ,   low = 0 ,   upp = 10 ): 
     return   truncnorm (( low   -   mean )   /   sd ,  
                      ( upp   -   mean )   /   sd ,  
                      loc = mean ,  
                      scale = sd ) 


 class   NeuralNetwork : 
    
     def   __init__ ( self ,  
                  no_of_in_nodes ,  
                  no_of_out_nodes ,  
                  no_of_hidden_nodes , 
                  learning_rate ): 
         self . no_of_in_nodes   =   no_of_in_nodes 
         self . no_of_out_nodes   =   no_of_out_nodes 
         self . no_of_hidden_nodes   =   no_of_hidden_nodes 
         self . learning_rate   =   learning_rate  
         self . create_weight_matrices () 
        
     def   create_weight_matrices ( self ): 
         """"""  
         A method to initialize the weight  
         matrices of the neural network 
         """""" 
         rad   =   1   /   np . sqrt ( self . no_of_in_nodes ) 
         X   =   truncated_normal ( mean = 0 ,  
                              sd = 1 ,  
                              low =- rad ,  
                              upp = rad ) 
         self . wih   =   X . rvs (( self . no_of_hidden_nodes ,  
                                        self . no_of_in_nodes )) 
         rad   =   1   /   np . sqrt ( self . no_of_hidden_nodes ) 
         X   =   truncated_normal ( mean = 0 ,   sd = 1 ,   low =- rad ,   upp = rad ) 
         self . who   =   X . rvs (( self . no_of_out_nodes ,  
                                          self . no_of_hidden_nodes )) 
        
    
     def   train ( self ,   input_vector ,   target_vector ): 
         """""" 
         input_vector and target_vector can  
         be tuple, list or ndarray 
         """""" 
        
         input_vector   =   np . array ( input_vector ,   ndmin = 2 ) . T 
         target_vector   =   np . array ( target_vector ,   ndmin = 2 ) . T 
        
         output_vector1   =   np . dot ( self . wih ,  
                                 input_vector ) 
         output_hidden   =   activation_function ( output_vector1 ) 
        
         output_vector2   =   np . dot ( self . who ,  
                                 output_hidden ) 
         output_network   =   activation_function ( output_vector2 ) 
        
         output_errors   =   target_vector   -   output_network 
         # update the weights: 
         tmp   =   output_errors   *   output_network  \
               *   ( 1.0   -   output_network )      
         tmp   =   self . learning_rate    *   np . dot ( tmp ,  
                                            output_hidden . T ) 
         self . who   +=   tmp 


         # calculate hidden errors: 
         hidden_errors   =   np . dot ( self . who . T ,  
                                output_errors ) 
         # update the weights: 
         tmp   =   hidden_errors   *   output_hidden   *  \
               ( 1.0   -   output_hidden ) 
         self . wih   +=   self . learning_rate  \
                           *   np . dot ( tmp ,   input_vector . T ) 
        

        
    
     def   run ( self ,   input_vector ): 
         # input_vector can be tuple, list or ndarray 
         input_vector   =   np . array ( input_vector ,   ndmin = 2 ) . T 

         output_vector   =   np . dot ( self . wih ,  
                                input_vector ) 
         output_vector   =   activation_function ( output_vector ) 
        
         output_vector   =   np . dot ( self . who ,  
                                output_vector ) 
         output_vector   =   activation_function ( output_vector ) 
    
         return   output_vector 
            
     def   confusion_matrix ( self ,   data_array ,   labels ): 
         cm   =   np . zeros (( 10 ,   10 ),   int ) 
         for   i   in   range ( len ( data_array )): 
             res   =   self . run ( data_array [ i ]) 
             res_max   =   res . argmax () 
             target   =   labels [ i ][ 0 ] 
             cm [ res_max ,   int ( target )]   +=   1 
         return   cm     

     def   precision ( self ,   label ,   confusion_matrix ): 
         col   =   confusion_matrix [:,   label ] 
         return   confusion_matrix [ label ,   label ]   /   col . sum () 
    
     def   recall ( self ,   label ,   confusion_matrix ): 
         row   =   confusion_matrix [ label ,   :] 
         return   confusion_matrix [ label ,   label ]   /   row . sum () 
        
    
     def   evaluate ( self ,   data ,   labels ): 
         corrects ,   wrongs   =   0 ,   0 
         for   i   in   range ( len ( data )): 
             res   =   self . run ( data [ i ]) 
             res_max   =   res . argmax () 
             if   res_max   ==   labels [ i ]: 
                 corrects   +=   1 
             else : 
                 wrongs   +=   1 
         return   corrects ,   wrongs 
            
 
 
 
 
 
 
 
 
 
 
 ANN   =   NeuralNetwork ( no_of_in_nodes   =   image_pixels ,  
                     no_of_out_nodes   =   10 ,  
                     no_of_hidden_nodes   =   100 , 
                     learning_rate   =   0.1 ) 
    
    
 for   i   in   range ( len ( train_imgs )): 
     ANN . train ( train_imgs [ i ],   train_labels_one_hot [ i ]) 
 
 
 
 
 
 
 
 
 
 
 for   i   in   range ( 20 ): 
     res   =   ANN . run ( test_imgs [ i ]) 
     print ( test_labels [ i ],   np . argmax ( res ),   np . max ( res )) 
    
 
 
 
 
 
 
 
 
 
 [7.] 7 0.9860708799942223
[2.] 2 0.9267395215547444
[1.] 1 0.992722703709605
[0.] 0 0.9912467012359228
[4.] 4 0.9663453611837215
[1.] 1 0.989817232710903
[4.] 4 0.9809813141030581
[9.] 9 0.9559155145505563
[5.] 6 0.251161100416336
[9.] 9 0.9715763167861055
[0.] 0 0.9778280648498543
[6.] 6 0.5525239387979288
[9.] 9 0.9948306224839408
[0.] 0 0.9895392427773758
[1.] 1 0.9933049204042839
[5.] 5 0.9401970590548236
[9.] 9 0.9956798141507527
[7.] 7 0.9767053019763295
[3.] 3 0.6472735640210903
[4.] 4 0.9952786141328994
 
 
 
 
 
 
 
 
 
 
 
 corrects ,   wrongs   =   ANN . evaluate ( train_imgs ,   train_labels ) 
 print ( ""accruracy train: "" ,   corrects   /   (   corrects   +   wrongs )) 
 corrects ,   wrongs   =   ANN . evaluate ( test_imgs ,   test_labels ) 
 print ( ""accruracy: test"" ,   corrects   /   (   corrects   +   wrongs )) 

 cm   =   ANN . confusion_matrix ( train_imgs ,   train_labels ) 
 print ( cm ) 

 for   i   in   range ( 10 ): 
     print ( ""digit: "" ,   i ,   ""precision: "" ,   ANN . precision ( i ,   cm ),   ""recall: "" ,   ANN . recall ( i ,   cm )) 
 
 
 
 
 
 
 
 
 
 accruracy train:  0.9459666666666666
accruracy: test 0.9437
[[5808    0   45   13   14   36   37    7   17   17]
 [   1 6611   62   21   17   34   20   56   97    9]
 [   0   19 5446   32    5   10    4   49    6    5]
 [  11   42  144 5870    3  206    2   42  162   74]
 [   8   13   57    5 5490   36   17   44   24   57]
 [   5    5    6   32    0 4896   33    1   16   13]
 [  25    3   45   20   50   71 5765    6   30    2]
 [   1    7   37   27    2    4    0 5784    2   22]
 [  46   14   92   39    6   62   40   14 5355   17]
 [  18   28   24   72  255   66    0  262  142 5733]]
digit:  0 precision:  0.9805841634306939 recall:  0.968968968968969
digit:  1 precision:  0.980569563927618 recall:  0.954243648960739
digit:  2 precision:  0.914065122524337 recall:  0.9766857962697274
digit:  3 precision:  0.9574294568585875 recall:  0.8953630262355095
digit:  4 precision:  0.9397466621020198 recall:  0.9546165884194053
digit:  5 precision:  0.9031543995572773 recall:  0.9778310365488316
digit:  6 precision:  0.9741466711726935 recall:  0.9581186637859398
digit:  7 precision:  0.9232242617717478 recall:  0.9826707441386341
digit:  8 precision:  0.9152281661254487 recall:  0.941952506596306
digit:  9 precision:  0.9636913767019667 recall:  0.8686363636363637
 
 
 
 
 
 
 
 
 
 Multiple Runs We can repeat the training multiple times. Each run is called an ""epoch"". 
 
 
 
 
 
 
 
 
 epochs   =   3 

 NN   =   NeuralNetwork ( no_of_in_nodes   =   image_pixels ,  
                    no_of_out_nodes   =   10 ,  
                    no_of_hidden_nodes   =   100 , 
                    learning_rate   =   0.1 ) 


 for   epoch   in   range ( epochs ):   
     print ( ""epoch: "" ,   epoch ) 
     for   i   in   range ( len ( train_imgs )): 
         NN . train ( train_imgs [ i ],  
                  train_labels_one_hot [ i ]) 
  
     corrects ,   wrongs   =   NN . evaluate ( train_imgs ,   train_labels ) 
     print ( ""accruracy train: "" ,   corrects   /   (   corrects   +   wrongs )) 
     corrects ,   wrongs   =   NN . evaluate ( test_imgs ,   test_labels ) 
     print ( ""accruracy: test"" ,   corrects   /   (   corrects   +   wrongs )) 
 
 
 
 
 
 
 
 
 
 epoch:  0
accruracy train:  0.9481333333333334
accruracy: test 0.9481
epoch:  1
accruracy train:  0.9619666666666666
accruracy: test 0.9577
epoch:  2
accruracy train:  0.96355
accruracy: test 0.9575
 
 
 
 
 
 
 
 
 
 We want to do the multiple training of the training set inside of our network. To this purpose we rewrite the method train and add a method train_single. train_single is more or less what we called 'train' before. Whereas the new 'train' method is doing the epoch counting. For testing purposes, we save the weight matrices after each epoch in 
the list intermediate_weights. This list is returned as the output of train: 
 
 
 
 
 
 
 
 
 import   numpy   as   np 

 @np . vectorize 
 def   sigmoid ( x ): 
     return   1   /   ( 1   +   np . e   **   - x ) 
 activation_function   =   sigmoid 

 from   scipy.stats   import   truncnorm 

 def   truncated_normal ( mean = 0 ,   sd = 1 ,   low = 0 ,   upp = 10 ): 
     return   truncnorm (( low   -   mean )   /   sd ,  
                      ( upp   -   mean )   /   sd ,  
                      loc = mean ,  
                      scale = sd ) 


 class   NeuralNetwork : 
    
     def   __init__ ( self ,  
                  no_of_in_nodes ,  
                  no_of_out_nodes ,  
                  no_of_hidden_nodes , 
                  learning_rate ): 
         self . no_of_in_nodes   =   no_of_in_nodes 
         self . no_of_out_nodes   =   no_of_out_nodes 
         self . no_of_hidden_nodes   =   no_of_hidden_nodes 
         self . learning_rate   =   learning_rate  
         self . create_weight_matrices () 
        
     def   create_weight_matrices ( self ): 
         """""" A method to initialize the weight matrices of the neural network"""""" 
         rad   =   1   /   np . sqrt ( self . no_of_in_nodes ) 
         X   =   truncated_normal ( mean = 0 ,  
                              sd = 1 ,  
                              low =- rad ,  
                              upp = rad ) 
         self . wih   =   X . rvs (( self . no_of_hidden_nodes ,  
                                        self . no_of_in_nodes )) 
         rad   =   1   /   np . sqrt ( self . no_of_hidden_nodes ) 
         X   =   truncated_normal ( mean = 0 ,  
                              sd = 1 ,  
                              low =- rad ,  
                              upp = rad ) 
         self . who   =   X . rvs (( self . no_of_out_nodes ,  
                                         self . no_of_hidden_nodes )) 
        
    
     def   train_single ( self ,   input_vector ,   target_vector ): 
         """""" 
         input_vector and target_vector can be tuple,  
         list or ndarray 
         """""" 
        
         output_vectors   =   [] 
         input_vector   =   np . array ( input_vector ,   ndmin = 2 ) . T 
         target_vector   =   np . array ( target_vector ,   ndmin = 2 ) . T 

        
         output_vector1   =   np . dot ( self . wih ,  
                                 input_vector ) 
         output_hidden   =   activation_function ( output_vector1 ) 
        
         output_vector2   =   np . dot ( self . who ,  
                                 output_hidden ) 
         output_network   =   activation_function ( output_vector2 ) 
        
         output_errors   =   target_vector   -   output_network 
         # update the weights: 
         tmp   =   output_errors   *   output_network   *  \
               ( 1.0   -   output_network )      
         tmp   =   self . learning_rate    *   np . dot ( tmp ,  
                                            output_hidden . T ) 
         self . who   +=   tmp 


         # calculate hidden errors: 
         hidden_errors   =   np . dot ( self . who . T ,  
                                output_errors ) 
         # update the weights: 
         tmp   =   hidden_errors   *   output_hidden   *   ( 1.0   -   output_hidden ) 
         self . wih   +=   self . learning_rate   *   np . dot ( tmp ,   input_vector . T ) 
        

     def   train ( self ,   data_array ,  
               labels_one_hot_array , 
               epochs = 1 , 
               intermediate_results = False ): 
         intermediate_weights   =   [] 
         for   epoch   in   range ( epochs ):   
             print ( ""*"" ,   end = """" ) 
             for   i   in   range ( len ( data_array )): 
                 self . train_single ( data_array [ i ],  
                                   labels_one_hot_array [ i ]) 
             if   intermediate_results : 
                 intermediate_weights . append (( self . wih . copy (),  
                                              self . who . copy ())) 
         return   intermediate_weights         
            
     def   confusion_matrix ( self ,   data_array ,   labels ): 
         cm   =   {} 
         for   i   in   range ( len ( data_array )): 
             res   =   self . run ( data_array [ i ]) 
             res_max   =   res . argmax () 
             target   =   labels [ i ][ 0 ] 
             if   ( target ,   res_max )   in   cm : 
                 cm [( target ,   res_max )]   +=   1 
             else : 
                 cm [( target ,   res_max )]   =   1 
         return   cm 
        
    
     def   run ( self ,   input_vector ): 
         """""" input_vector can be tuple, list or ndarray """""" 
        
         input_vector   =   np . array ( input_vector ,   ndmin = 2 ) . T 

         output_vector   =   np . dot ( self . wih ,  
                                input_vector ) 
         output_vector   =   activation_function ( output_vector ) 
        
         output_vector   =   np . dot ( self . who ,  
                                output_vector ) 
         output_vector   =   activation_function ( output_vector ) 
    
         return   output_vector 
    
     def   evaluate ( self ,   data ,   labels ): 
         corrects ,   wrongs   =   0 ,   0 
         for   i   in   range ( len ( data )): 
             res   =   self . run ( data [ i ]) 
             res_max   =   res . argmax () 
             if   res_max   ==   labels [ i ]: 
                 corrects   +=   1 
             else : 
                 wrongs   +=   1 
         return   corrects ,   wrongs 
            

    
 
 
 
 
 
 
 
 
 
 
 epochs   =   10 

 ANN   =   NeuralNetwork ( no_of_in_nodes   =   image_pixels ,  
                                no_of_out_nodes   =   10 ,  
                                no_of_hidden_nodes   =   100 , 
                                learning_rate   =   0.15 ) 
    
    
 
 weights   =   ANN . train ( train_imgs ,  
                     train_labels_one_hot ,  
                     epochs = epochs ,  
                     intermediate_results = True ) 
        
 
 
 
 
 
 
 
 
 
 ********** 
 
 
 
 
 
 
 
 
 
 
 cm   =   ANN . confusion_matrix ( train_imgs ,   train_labels ) 
        
 print ( ANN . run ( train_imgs [ i ])) 
 
 
 
 
 
 
 
 
 
 [[4.00902378e-03]
 [1.21174658e-03]
 [3.53102424e-03]
 [2.62065106e-03]
 [2.81580124e-04]
 [1.34748207e-02]
 [3.53419006e-04]
 [6.95493256e-04]
 [9.85274442e-01]
 [5.51759120e-04]]
 
 
 
 
 
 
 
 
 
 
 
 cm   =   list ( cm . items ()) 
 print ( sorted ( cm )) 
 
 
 
 
 
 
 
 
 
 [((0.0, 0), 5851), ((0.0, 1), 1), ((0.0, 2), 6), ((0.0, 4), 10), ((0.0, 5), 4), ((0.0, 6), 17), ((0.0, 7), 6), ((0.0, 8), 19), ((0.0, 9), 9), ((1.0, 0), 2), ((1.0, 1), 6694), ((1.0, 2), 8), ((1.0, 3), 5), ((1.0, 4), 11), ((1.0, 5), 3), ((1.0, 6), 1), ((1.0, 7), 7), ((1.0, 8), 5), ((1.0, 9), 6), ((2.0, 0), 33), ((2.0, 1), 56), ((2.0, 2), 5757), ((2.0, 3), 10), ((2.0, 4), 12), ((2.0, 5), 7), ((2.0, 6), 10), ((2.0, 7), 39), ((2.0, 8), 22), ((2.0, 9), 12), ((3.0, 0), 17), ((3.0, 1), 36), ((3.0, 2), 33), ((3.0, 3), 5819), ((3.0, 4), 9), ((3.0, 5), 73), ((3.0, 6), 7), ((3.0, 7), 34), ((3.0, 8), 60), ((3.0, 9), 43), ((4.0, 0), 11), ((4.0, 1), 20), ((4.0, 2), 5), ((4.0, 4), 5685), ((4.0, 5), 2), ((4.0, 6), 20), ((4.0, 7), 1), ((4.0, 8), 7), ((4.0, 9), 91), ((5.0, 0), 15), ((5.0, 1), 9), ((5.0, 2), 2), ((5.0, 3), 15), ((5.0, 4), 7), ((5.0, 5), 5318), ((5.0, 6), 26), ((5.0, 7), 2), ((5.0, 8), 13), ((5.0, 9), 14), ((6.0, 0), 29), ((6.0, 1), 17), ((6.0, 2), 3), ((6.0, 4), 9), ((6.0, 5), 39), ((6.0, 6), 5802), ((6.0, 7), 3), ((6.0, 8), 11), ((6.0, 9), 5), ((7.0, 0), 35), ((7.0, 1), 35), ((7.0, 2), 24), ((7.0, 3), 11), ((7.0, 4), 35), ((7.0, 5), 6), ((7.0, 6), 1), ((7.0, 7), 5962), ((7.0, 8), 13), ((7.0, 9), 143), ((8.0, 0), 19), ((8.0, 1), 88), ((8.0, 2), 10), ((8.0, 3), 30), ((8.0, 4), 31), ((8.0, 5), 42), ((8.0, 6), 16), ((8.0, 7), 5), ((8.0, 8), 5556), ((8.0, 9), 54), ((9.0, 0), 23), ((9.0, 1), 25), ((9.0, 2), 1), ((9.0, 3), 50), ((9.0, 4), 58), ((9.0, 5), 19), ((9.0, 6), 2), ((9.0, 7), 15), ((9.0, 8), 25), ((9.0, 9), 5731)]
 
 
 
 
 
 
 
 
 
 
 
 for   i   in   range ( epochs ):   
     print ( ""epoch: "" ,   i ) 
     ANN . wih   =   weights [ i ][ 0 ] 
     ANN . who   =   weights [ i ][ 1 ] 
   
     corrects ,   wrongs   =   ANN . evaluate ( train_imgs ,   train_labels ) 
     print ( ""accruracy train: "" ,   corrects   /   (   corrects   +   wrongs )) 
     corrects ,   wrongs   =   ANN . evaluate ( test_imgs ,   test_labels ) 
     print ( ""accruracy: test"" ,   corrects   /   (   corrects   +   wrongs )) 
 
 
 
 
 
 
 
 
 
 epoch:  0
accruracy train:  0.9463166666666667
accruracy: test 0.9426
epoch:  1
accruracy train:  0.9607
accruracy: test 0.956
epoch:  2
accruracy train:  0.9657666666666667
accruracy: test 0.9588
epoch:  3
accruracy train:  0.9712
accruracy: test 0.9639
epoch:  4
accruracy train:  0.9684
accruracy: test 0.9599
epoch:  5
accruracy train:  0.9729666666666666
accruracy: test 0.9634
epoch:  6
accruracy train:  0.97265
accruracy: test 0.9614
epoch:  7
accruracy train:  0.96965
accruracy: test 0.9579
epoch:  8
accruracy train:  0.96855
accruracy: test 0.9585
epoch:  9
accruracy train:  0.9695833333333334
accruracy: test 0.9594
 
 
 
 
 
 
 
 
 
 
 With Bias Nodes 
 
 
 
 
 
 
 
 
 import   numpy   as   np 

 @np . vectorize 
 def   sigmoid ( x ): 
     return   1   /   ( 1   +   np . e   **   - x ) 
 activation_function   =   sigmoid 

 from   scipy.stats   import   truncnorm 

 def   truncated_normal ( mean = 0 ,   sd = 1 ,   low = 0 ,   upp = 10 ): 
     return   truncnorm (( low   -   mean )   /   sd ,  
                      ( upp   -   mean )   /   sd ,  
                      loc = mean ,  
                      scale = sd ) 


 class   NeuralNetwork : 
        
    
     def   __init__ ( self ,  
                  no_of_in_nodes ,  
                  no_of_out_nodes ,  
                  no_of_hidden_nodes , 
                  learning_rate , 
                  bias = None 
                 ):   

         self . no_of_in_nodes   =   no_of_in_nodes 
         self . no_of_out_nodes   =   no_of_out_nodes       
         self . no_of_hidden_nodes   =   no_of_hidden_nodes      
         self . learning_rate   =   learning_rate  
         self . bias   =   bias 
         self . create_weight_matrices () 
    
        
    
     def   create_weight_matrices ( self ): 
         """"""  
         A method to initialize the weight  
         matrices of the neural network with  
         optional bias nodes 
         """""" 
        
         bias_node   =   1   if   self . bias   else   0 
        
         rad   =   1   /   np . sqrt ( self . no_of_in_nodes   +   bias_node ) 
         X   =   truncated_normal ( mean = 0 ,  
                              sd = 1 ,  
                              low =- rad ,  
                              upp = rad ) 
         self . wih   =   X . rvs (( self . no_of_hidden_nodes ,  
                           self . no_of_in_nodes   +   bias_node )) 

         rad   =   1   /   np . sqrt ( self . no_of_hidden_nodes   +   bias_node ) 
         X   =   truncated_normal ( mean = 0 ,   sd = 1 ,   low =- rad ,   upp = rad ) 
         self . who   =   X . rvs (( self . no_of_out_nodes ,  
                           self . no_of_hidden_nodes   +   bias_node )) 
        
        
        
     def   train ( self ,   input_vector ,   target_vector ): 
         """"""  
         input_vector and target_vector can  
         be tuple, list or ndarray 
         """""" 
        
         bias_node   =   1   if   self . bias   else   0 
         if   self . bias : 
             # adding bias node to the end of the inpuy_vector 
             input_vector   =   np . concatenate (( input_vector ,  
                                            [ self . bias ])   ) 
                                    
            
         input_vector   =   np . array ( input_vector ,   ndmin = 2 ) . T 
         target_vector   =   np . array ( target_vector ,   ndmin = 2 ) . T 

        
         output_vector1   =   np . dot ( self . wih ,  
                                 input_vector ) 
         output_hidden   =   activation_function ( output_vector1 ) 
        
         if   self . bias : 
             output_hidden   =   np . concatenate (( output_hidden ,  
                                             [[ self . bias ]])   ) 
        
        
         output_vector2   =   np . dot ( self . who ,  
                                 output_hidden ) 
         output_network   =   activation_function ( output_vector2 ) 
        
         output_errors   =   target_vector   -   output_network 
         # update the weights: 
         tmp   =   output_errors   *   output_network   *   ( 1.0   -   output_network )      
         tmp   =   self . learning_rate    *   np . dot ( tmp ,   output_hidden . T ) 
         self . who   +=   tmp 


         # calculate hidden errors: 
         hidden_errors   =   np . dot ( self . who . T ,  
                                output_errors ) 
         # update the weights: 
         tmp   =   hidden_errors   *   output_hidden   *   ( 1.0   -   output_hidden ) 
         if   self . bias : 
             x   =   np . dot ( tmp ,   input_vector . T )[: - 1 ,:]      
         else : 
             x   =   np . dot ( tmp ,   input_vector . T ) 
         self . wih   +=   self . learning_rate   *   x 
        
       
    
     def   run ( self ,   input_vector ): 
         """""" 
         input_vector can be tuple, list or ndarray 
         """""" 
        
         if   self . bias : 
             # adding bias node to the end of the inpuy_vector 
             input_vector   =   np . concatenate (( input_vector ,   [ 1 ])   ) 
         input_vector   =   np . array ( input_vector ,   ndmin = 2 ) . T 

         output_vector   =   np . dot ( self . wih ,  
                                input_vector ) 
         output_vector   =   activation_function ( output_vector ) 
        
         if   self . bias : 
             output_vector   =   np . concatenate (   ( output_vector ,  
                                              [[ 1 ]])   ) 
            

         output_vector   =   np . dot ( self . who ,  
                                output_vector ) 
         output_vector   =   activation_function ( output_vector ) 
         return   output_vector 
    
     def   evaluate ( self ,   data ,   labels ): 
         corrects ,   wrongs   =   0 ,   0 
         for   i   in   range ( len ( data )): 
             res   =   self . run ( data [ i ]) 
             res_max   =   res . argmax () 
             if   res_max   ==   labels [ i ]: 
                 corrects   +=   1 
             else : 
                 wrongs   +=   1 
         return   corrects ,   wrongs 
    
 
 
 
 
 
 
 
 
 
 
 ANN   =   NeuralNetwork ( no_of_in_nodes = image_pixels ,  
                     no_of_out_nodes = 10 ,  
                     no_of_hidden_nodes = 200 , 
                     learning_rate = 0.1 , 
                     bias = None ) 
    
    
 for   i   in   range ( len ( train_imgs )): 
     ANN . train ( train_imgs [ i ],   train_labels_one_hot [ i ]) 
 for   i   in   range ( 20 ): 
     res   =   ANN . run ( test_imgs [ i ]) 
     print ( test_labels [ i ],   np . argmax ( res ),   np . max ( res )) 
 
 
 
 
 
 
 
 
 
 [7.] 7 0.9919548855346075
[2.] 2 0.9126166313171279
[1.] 1 0.9950208553219682
[0.] 0 0.9749351235230623
[4.] 4 0.9571763854857767
[1.] 1 0.9935538746697467
[4.] 4 0.9837991934187194
[9.] 9 0.9880928849631352
[5.] 6 0.48522777972199804
[9.] 9 0.9869804655091072
[0.] 0 0.9724003174889927
[6.] 6 0.8546492950379682
[9.] 9 0.9948361350336243
[0.] 0 0.9879652442706465
[1.] 1 0.993662379896922
[5.] 5 0.9388307192428593
[9.] 9 0.9932742444002292
[7.] 7 0.9823754932151263
[3.] 3 0.3342016770005162
[4.] 4 0.9921731312320509
 
 
 
 
 
 
 
 
 
 
 
 corrects ,   wrongs   =   ANN . evaluate ( train_imgs ,   train_labels ) 
 print ( ""accruracy train: "" ,   corrects   /   (   corrects   +   wrongs )) 
 corrects ,   wrongs   =   ANN . evaluate ( test_imgs ,   test_labels ) 
 print ( ""accruracy: test"" ,   corrects   /   (   corrects   +   wrongs )) 
 
 
 
 
 
 
 
 
 
 accruracy train:  0.95035
accruracy: test 0.9488
 
 
 
 
 
 
 
 
 
 
 Version with Bias and Epochs: 
 
 
 
 
 
 
 
 
 import   numpy   as   np 

 @np . vectorize 
 def   sigmoid ( x ): 
     return   1   /   ( 1   +   np . e   **   - x ) 
 activation_function   =   sigmoid 

 from   scipy.stats   import   truncnorm 

 def   truncated_normal ( mean = 0 ,   sd = 1 ,   low = 0 ,   upp = 10 ): 
     return   truncnorm (( low   -   mean )   /   sd , 
                      ( upp   -   mean )   /   sd , 
                      loc = mean , 
                      scale = sd ) 


 class   NeuralNetwork : 
 
     def   __init__ ( self ,  
                  no_of_in_nodes ,  
                  no_of_out_nodes ,  
                  no_of_hidden_nodes , 
                  learning_rate , 
                  bias = None 
                 ):   

         self . no_of_in_nodes   =   no_of_in_nodes 
         self . no_of_out_nodes   =   no_of_out_nodes 
        
         self . no_of_hidden_nodes   =   no_of_hidden_nodes 
            
         self . learning_rate   =   learning_rate  
         self . bias   =   bias 
         self . create_weight_matrices () 
    
        
    
     def   create_weight_matrices ( self ): 
         """"""  
         A method to initialize the weight matrices  
         of the neural network with optional  
         bias nodes"""""" 
        
         bias_node   =   1   if   self . bias   else   0 
        
         rad   =   1   /   np . sqrt ( self . no_of_in_nodes   +   bias_node ) 
         X   =   truncated_normal ( mean = 0 ,   sd = 1 ,   low =- rad ,   upp = rad ) 
         self . wih   =   X . rvs (( self . no_of_hidden_nodes ,  
                           self . no_of_in_nodes   +   bias_node )) 

         rad   =   1   /   np . sqrt ( self . no_of_hidden_nodes   +   bias_node ) 
         X   =   truncated_normal ( mean = 0 ,  
                              sd = 1 ,  
                              low =- rad ,  
                              upp = rad ) 
         self . who   =   X . rvs (( self . no_of_out_nodes ,  
                           self . no_of_hidden_nodes   +   bias_node )) 
        
 
     def   train_single ( self ,   input_vector ,   target_vector ): 
         """""" 
         input_vector and target_vector can be tuple,  
         list or ndarray 
         """""" 

         bias_node   =   1   if   self . bias   else   0 
         if   self . bias : 
             # adding bias node to the end of the inpuy_vector 
             input_vector   =   np . concatenate (   ( input_vector ,  
                                             [ self . bias ])   ) 
        
         output_vectors   =   [] 
         input_vector   =   np . array ( input_vector ,   ndmin = 2 ) . T 
         target_vector   =   np . array ( target_vector ,   ndmin = 2 ) . T 

        
         output_vector1   =   np . dot ( self . wih ,  
                                 input_vector ) 
         output_hidden   =   activation_function ( output_vector1 ) 
        
         if   self . bias : 
             output_hidden   =   np . concatenate (( output_hidden ,  
                                             [[ self . bias ]])   ) 

        
         output_vector2   =   np . dot ( self . who ,  
                                 output_hidden ) 
         output_network   =   activation_function ( output_vector2 ) 
        
         output_errors   =   target_vector   -   output_network 
         # update the weights: 
         tmp   =   output_errors   *   output_network   *   ( 1.0   -   output_network )           
         tmp   =   self . learning_rate    *   np . dot ( tmp ,  
                                            output_hidden . T )  
         self . who   +=   tmp 

        
         # calculate hidden errors: 
         hidden_errors   =   np . dot ( self . who . T ,  
                                output_errors ) 
         # update the weights: 
         tmp   =   hidden_errors   *   output_hidden   *   ( 1.0   -   output_hidden ) 
         if   self . bias : 
             x   =   np . dot ( tmp ,   input_vector . T )[: - 1 ,:]  
         else : 
             x   =   np . dot ( tmp ,   input_vector . T ) 
         self . wih   +=   self . learning_rate   *   x 
        

     def   train ( self ,   data_array ,  
               labels_one_hot_array , 
               epochs = 1 , 
               intermediate_results = False ): 
         intermediate_weights   =   [] 
         for   epoch   in   range ( epochs ):   
             for   i   in   range ( len ( data_array )): 
                 self . train_single ( data_array [ i ],  
                                   labels_one_hot_array [ i ]) 
             if   intermediate_results : 
                 intermediate_weights . append (( self . wih . copy (),  
                                              self . who . copy ())) 
         return   intermediate_weights       
        

        
    
     def   run ( self ,   input_vector ): 
         # input_vector can be tuple, list or ndarray 
        
         if   self . bias : 
             # adding bias node to the end of the inpuy_vector 
             input_vector   =   np . concatenate (   ( input_vector ,  
                                             [ self . bias ])   ) 
         input_vector   =   np . array ( input_vector ,   ndmin = 2 ) . T 

         output_vector   =   np . dot ( self . wih ,  
                                input_vector ) 
         output_vector   =   activation_function ( output_vector ) 
        
         if   self . bias : 
             output_vector   =   np . concatenate (   ( output_vector ,  
                                              [[ self . bias ]])   ) 
            

         output_vector   =   np . dot ( self . who ,  
                                output_vector ) 
         output_vector   =   activation_function ( output_vector ) 
    
         return   output_vector 
    
    
     def   evaluate ( self ,   data ,   labels ): 
         corrects ,   wrongs   =   0 ,   0 
         for   i   in   range ( len ( data )): 
             res   =   self . run ( data [ i ]) 
             res_max   =   res . argmax () 
             if   res_max   ==   labels [ i ]: 
                 corrects   +=   1 
             else : 
                 wrongs   +=   1 
         return   corrects ,   wrongs 
            
    
 
 
 
 
 
 
 
 
 
 
 epochs   =   12 

 network   =   NeuralNetwork ( no_of_in_nodes = image_pixels ,  
                         no_of_out_nodes = 10 ,  
                         no_of_hidden_nodes = 100 , 
                         learning_rate = 0.1 , 
                         bias = None ) 

 weights   =   network . train ( train_imgs ,  
                         train_labels_one_hot ,  
                         epochs = epochs ,  
                         intermediate_results = True )  
 for   epoch   in   range ( epochs ):   
     print ( ""epoch: "" ,   epoch ) 
     network . wih   =   weights [ epoch ][ 0 ] 
     network . who   =   weights [ epoch ][ 1 ] 
     corrects ,   wrongs   =   network . evaluate ( train_imgs ,  
                                         train_labels ) 
     print ( ""accruracy train: "" ,   corrects   /   (   corrects   +   wrongs ))                    
     corrects ,   wrongs   =   network . evaluate ( test_imgs ,  
                                         test_labels ) 
     print ( ""accruracy test: "" ,   corrects   /   (   corrects   +   wrongs ))  
    
 
 
 
 
 
 
 
 
 
 epoch:  0
accruracy train:  0.94145
accruracy test:  0.9408
epoch:  1
accruracy train:  0.9601833333333334
accruracy test:  0.9562
epoch:  2
accruracy train:  0.9647833333333333
accruracy test:  0.9581
epoch:  3
accruracy train:  0.9664166666666667
accruracy test:  0.9576
epoch:  4
accruracy train:  0.9717833333333333
accruracy test:  0.9606
epoch:  5
accruracy train:  0.9738333333333333
accruracy test:  0.964
epoch:  6
accruracy train:  0.97435
accruracy test:  0.9626
epoch:  7
accruracy train:  0.9760666666666666
accruracy test:  0.9638
epoch:  8
accruracy train:  0.9771666666666666
accruracy test:  0.9639
epoch:  9
accruracy train:  0.9767333333333333
accruracy test:  0.9599
epoch:  10
accruracy train:  0.9754166666666667
accruracy test:  0.9615
epoch:  11
accruracy train:  0.9752666666666666
accruracy test:  0.9603
 
 
 
 
 
 
 
 
 
 
 
 epochs   =   12 


 with   open ( ""nist_tests.csv"" ,   ""w"" )   as   fh_out :   
     for   hidden_nodes   in   [ 20 ,   50 ,   100 ,   120 ,   150 ]: 
         for   learning_rate   in   [ 0.01 ,   0.05 ,   0.1 ,   0.2 ]: 
             for   bias   in   [ None ,   0.5 ]: 
                 network   =   NeuralNetwork ( no_of_in_nodes = image_pixels ,  
                                        no_of_out_nodes = 10 ,  
                                        no_of_hidden_nodes = hidden_nodes , 
                                        learning_rate = learning_rate , 
                                        bias = bias ) 
                 weights   =   network . train ( train_imgs ,  
                                        train_labels_one_hot ,  
                                        epochs = epochs ,  
                                        intermediate_results = True )  
                 for   epoch   in   range ( epochs ):   
                     print ( ""*"" ,   end = """" ) 
                     network . wih   =   weights [ epoch ][ 0 ] 
                     network . who   =   weights [ epoch ][ 1 ] 
                     train_corrects ,   train_wrongs   =   network . evaluate ( train_imgs ,  
                                                                     train_labels ) 
                    
                     test_corrects ,   test_wrongs   =   network . evaluate ( test_imgs ,  
                                                                   test_labels ) 
                     outstr   =   str ( hidden_nodes )   +   "" ""   +   str ( learning_rate )   +   "" ""   +   str ( bias )  
                     outstr   +=   "" ""   +   str ( epoch )   +   "" "" 
                     outstr   +=   str ( train_corrects   /   ( train_corrects   +   train_wrongs ))   +   "" "" 
                     outstr   +=   str ( train_wrongs   /   ( train_corrects   +   train_wrongs ))   +   "" "" 
                     outstr   +=   str ( test_corrects   /   ( test_corrects   +   test_wrongs ))   +   "" "" 
                     outstr   +=   str ( test_wrongs   /   ( test_corrects   +   test_wrongs ))  
                    
                     fh_out . write ( outstr   +   "" \n ""   ) 
                     fh_out . flush () 
 
 
 
 
 
 
 
 
 
 ************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************ 
 
 
 
 
 
 
 
 
 The file  nist_tests_20_50_100_120_150.csv  contains the results from a run of the previous program. 
 
 
 
 
 
 
 Networks with multiple hidden layers We will write a new neural network class, in which we can define an arbitrary number of hidden layers. The code is also improved, because the weight matrices are now build inside of a loop instead redundant code: 
 
 
 
 
 
 
 
 
 import   numpy   as   np 
 from   scipy.special   import   expit   as   activation_function 
 from   scipy.stats   import   truncnorm 

 def   truncated_normal ( mean = 0 ,   sd = 1 ,   low = 0 ,   upp = 10 ): 
     return   truncnorm (( low   -   mean )   /   sd ,  
                      ( upp   -   mean )   /   sd ,  
                      loc = mean ,  
                      scale = sd ) 


 class   NeuralNetwork : 
        
    
     def   __init__ ( self ,  
                  network_structure ,   # ie. [input_nodes, hidden1_nodes, ... , hidden_n_nodes, output_nodes] 
                  learning_rate , 
                  bias = None 
                 ):   

         self . structure   =   network_structure 
         self . learning_rate   =   learning_rate  
         self . bias   =   bias 
         self . create_weight_matrices () 
    
    
     def   create_weight_matrices ( self ): 
        
         bias_node   =   1   if   self . bias   else   0 
         self . weights_matrices   =   [] 
        
         layer_index   =   1 
         no_of_layers   =   len ( self . structure ) 
         while   layer_index      0 : 
             out_vector   =   res_vectors [ layer_index ] 
             in_vector   =   res_vectors [ layer_index - 1 ] 

             if   self . bias   and   not   layer_index == ( no_of_layers - 1 ): 
                 out_vector   =   out_vector [: - 1 ,:] . copy () 

             tmp   =   output_errors   *   out_vector   *   ( 1.0   -   out_vector )      
             tmp   =   np . dot ( tmp ,   in_vector . T ) 
            
             #if self.bias: 
             #    tmp = tmp[:-1,:]  
                
             self . weights_matrices [ layer_index - 1 ]   +=   self . learning_rate   *   tmp 
            
             output_errors   =   np . dot ( self . weights_matrices [ layer_index - 1 ] . T ,  
                                    output_errors ) 
             if   self . bias : 
                 output_errors   =   output_errors [: - 1 ,:] 
             layer_index   -=   1 
            
            
               
    
     def   run ( self ,   input_vector ): 
         # input_vector can be tuple, list or ndarray 

         no_of_layers   =   len ( self . structure ) 
         if   self . bias : 
             # adding bias node to the end of the inpuy_vector 
             input_vector   =   np . concatenate (   ( input_vector ,  
                                             [ self . bias ])   ) 
         in_vector   =   np . array ( input_vector ,   ndmin = 2 ) . T 

         layer_index   =   1 
         # The input vectors to the various layers 
         while   layer_index      0 : 
             out_vector   =   res_vectors [ layer_index ] 
             in_vector   =   res_vectors [ layer_index - 1 ] 

             if   self . bias   and   not   layer_index == ( no_of_layers - 1 ): 
                 out_vector   =   out_vector [: - 1 ,:] . copy () 

             tmp   =   output_errors   *   out_vector   *   ( 1.0   -   out_vector )      
             tmp   =   np . dot ( tmp ,   in_vector . T ) 
            
             #if self.bias: 
             #    tmp = tmp[:-1,:]  
                
             self . weights_matrices [ layer_index - 1 ]   +=   self . learning_rate   *   tmp 
            
             output_errors   =   np . dot ( self . weights_matrices [ layer_index - 1 ] . T ,  
                                    output_errors ) 
             if   self . bias : 
                 output_errors   =   output_errors [: - 1 ,:] 
             layer_index   -=   1 
            

       

     def   train ( self ,   data_array ,  
               labels_one_hot_array , 
               epochs = 1 , 
               intermediate_results = False ): 
         intermediate_weights   =   [] 
         for   epoch   in   range ( epochs ):   
             for   i   in   range ( len ( data_array )): 
                 self . train_single ( data_array [ i ],   labels_one_hot_array [ i ]) 
             if   intermediate_results : 
                 intermediate_weights . append (( self . wih . copy (),  
                                              self . who . copy ())) 
         return   intermediate_weights       
        

               
    
     def   run ( self ,   input_vector ): 
         # input_vector can be tuple, list or ndarray 

         no_of_layers   =   len ( self . structure ) 
         if   self . bias : 
             # adding bias node to the end of the inpuy_vector 
             input_vector   =   np . concatenate (   ( input_vector ,   [ self . bias ])   ) 
         in_vector   =   np . array ( input_vector ,   ndmin = 2 ) . T 

         layer_index   =   1 
         # The input vectors to the various layers 
         while   layer_index   <   no_of_layers : 
             x   =   np . dot ( self . weights_matrices [ layer_index - 1 ],  
                        in_vector ) 
             out_vector   =   activation_function ( x ) 
            
             # input vector for next layer 
             in_vector   =   out_vector 
             if   self . bias : 
                 in_vector   =   np . concatenate (   ( in_vector ,  
                                              [[ self . bias ]])   )             
            
             layer_index   +=   1 
  
    
         return   out_vector 
    
     def   evaluate ( self ,   data ,   labels ): 
         corrects ,   wrongs   =   0 ,   0 
         for   i   in   range ( len ( data )): 
             res   =   self . run ( data [ i ]) 
             res_max   =   res . argmax () 
             if   res_max   ==   labels [ i ]: 
                 corrects   +=   1 
             else : 
                 wrongs   +=   1 
         return   corrects ,   wrongs 
    
    
 
 
 
 
 
 
 
 
 
 
 epochs   =   3 

 ANN   =   NeuralNetwork ( network_structure = [ image_pixels ,   80 ,   80 ,   10 ], 
                                learning_rate = 0.01 , 
                                bias = None ) 
    
    
 ANN . train ( train_imgs ,   train_labels_one_hot ,   epochs = epochs ) 
 
 
 
 
 
 
 
 Output:: 
 
 [] 
 
 
 
 
 
 
 
 
 
 
 corrects ,   wrongs   =   ANN . evaluate ( train_imgs ,   train_labels ) 
 print ( ""accruracy train: "" ,   corrects   /   (   corrects   +   wrongs )) 
 corrects ,   wrongs   =   ANN . evaluate ( test_imgs ,   test_labels ) 
 print ( ""accruracy: test"" ,   corrects   /   (   corrects   +   wrongs )) 
 
 
 
 
 
 
 
 
 
 accruracy train:  0.9561833333333334
accruracy: test 0.9537
 
 
 
 
 
 
 
 
 
 Footnotes 
 1  Wan, Li; Matthew Zeiler; Sixin Zhang; Yann LeCun; Rob Fergus (2013). Regularization of Neural Network using DropConnect. International Conference on Machine Learning(ICML). 
 
 
 
 Previous Chapter:  Confusion Matrix 
 Next Chapter:  Dropout Neural Networks 
 
   © 2011 - 2019, Bernd Klein,
Bodenseo; 
Design by Denise Mitchinson adapted for python-course.eu by Bernd Klein "," Using  MNIST,None,None,None,None,Dumping the Data for Faster Reload,None,Classifying the Data,None,None,None,Version with Bias and Epochs:,None,None,None,Footnotes,", https://www.python-course.eu/http://www.python-kurs.eu/stellengesuch/Stellenanzeige.pdfhttps://www.python-course.eu/http://yann.lecun.com/exdb/mnist/
7,Dropout Neural Networks,https://www.python-course.eu/neural_networks_with_dropout.php,"Machine Learning with Python: Dropout Neural Networks in Python 
 
 
 
 - remove in and out prompt from ipython notebook 
%%HTML

div.prompt {display:none}

 - 
 
 
 
 
 Python Machine Learning Tutorial 
 
  Begin Top Menu  
 
 Home Python 2 Tutorial Python 3 Tutorial Advanced Topics Numerical Programming Machine Learning Tkinter Tutorial Contact 
 
  End Top Menu  
 Machine Learning 
 
 
 Machine Learning Terminology k-nearest Neighbor Classifier Neural Networks from Scratch in Python Neural Network in Python using Numpy Backpropagation in Neural Networks Confusion Matrix Training and Testing with MNIST Dropout Neural Networks Neural Networks with Scikit Machine Learning with Scikit and Python Introduction Naive Bayes Classifier Naive Bayes Classifier with Scikit Introduction into Text Classification using Naive Bayes Python Implementation of Text Classification Decision Trees Regression Trees Random Forests Boosting Algorithm Principal Component Analysis Linear Discriminant Analysis Expectation Maximization and Gaussian Mixture Model Introduction into TensorFlow 
 
 
 
 Help Needed 

This website is free of annoying ads. We want to keep it like this. You can help with your donation:
 
 
 
 
 
 
 
 
 The need for donations 
 
 Python 

In Greek mythology, Python is the name of a a huge serpent and sometimes a dragon. Python had been killed by the god Apollo at Delphi. Python was created out of the slime and mud left after the great flood. He was appointed by Gaia (Mother Earth) to guard the oracle of Delphi, known as Pytho.
 
The programming language Python has not been created out of slime and mud but out of the programming language ABC. It has been devised by a Dutch programmer, named Guido van Rossum, in Amsterdam.

 
 Origins of Python 


Guido van Rossum wrote the following about the origins of Python in a foreword for the book  ""Programming Python"" by Mark Lutz in 1996:
 
""Over six years ago, in December 1989, I was looking for a ""hobby"" programming project that would keep me occupied during the week around Christmas. My office (a government-run research lab in Amsterdam) would be closed, but I had a home computer, and not much else on my hands. I decided to write an interpreter for the new scripting language I had been thinking about lately: a descendant of ABC that would appeal to Unix/C hackers. I chose Python as a working title for the project, being in a slightly irreverent mood (and a big fan of Monty Python's Flying Circus).""

 
  Dieses Tag dort einfügen, wo die +1-Schaltfläche dargestellt werden soll  
 
 
 Help Needed 

This website is free of annoying ads. We want to keep it like this. You can help with your donation:
 
 
 
 
 
 
 
 
 
 The need for donations 
 
 Job Applications 
 
 Python Lecturer 
 bodenseo is looking for a new trainer and software developper. You need to live in Germany and know German. Interested? Find out  more !
 Python Programmer 
We are looking for a qualified Python programmer to further improve our website. This is a work from home job, wherever you live in the world! 
If you think that you are the right person or if you have further questions, please do not hesitate to  contact us .
 
 
 
 Bernd Klein on Facebook 
 
 
 
Search this website:
 
 
 
 Classroom Training Courses 
 
This website contains a free and extensive online tutorial by Bernd Klein, using
material from his classroom Python training courses Python classes 
 
 © kabliczech - Fotolia.com Quote of the Day: ""If you use the original World Wide Web program, you never see a URL or have to deal with HTML. That was a surprise to me that people were prepared to painstakingly write HTML.""  (Tim Berners Lee)
   Help Needed 
 
 
 
 
 
 The need for donations Data Protection Declaration Data Protection Declaration 
 Previous Chapter:  Training and Testing with MNIST 
 Next Chapter:  Neural Networks with Scikit 
 
 
 
 
 Dropout Neural Networks Introduction 
 The term ""dropout"" is used for a technique which drops out some nodes of the network. Dropping out can be seen as temporarily deactivating or ignoring neurons of the network. This technique is applied in the training phase  to reduce overfitting effects. Overfitting is an error which occurs when a network is too closely fit to a limited set of input samples. 
 The basic idea behind dropout neural networks is to dropout nodes so that the network can concentrate on other features. Think about it like this. You watch lots of films from your favourite actor. At some point you listen to the radio and here somebody in an interview. You don't recognize your favourite actor, because you have seen only movies and your are a visual type. Now, imagine that you can only listen to the audio tracks of the films. In this case you will have to learn to differentiate the voices of the actresses and actors. So by dropping out the visual part you are forced tp focus on the sound features! 
 This technique has been first proposed in a paper ""Dropout: A Simple Way to Prevent Neural Networks from Overfitting"" by Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever and Ruslan Salakhutdinov in 2014 
 We will implement in our tutorial on machine learning in Python a Python class which is capable of dropout. 
 
 
 
 
 
 
 Modifying the Weight Arrays If we deactivate a node, we have to modify the weight arrays accordingly. To demonstrate how this can be accomplished, we will use a network with three input nodes, four hidden and two output nodes: 
 
 
 
 
 
 
 
 
 
 
 
 
 
 At first, we will have a look at the weight array between the input and the hidden layer. We called this array 'wih' (weights between input and hidden layer). 
 Let's deactivate (drop out) the node $i_2$. We can see in the following diagram what's happening: 
 
 
 
 
 
 
 
 
 
 
 
 
 
 This means that we have to take out every second product of the summation, which means that we have to delete the whole second column of the matrix. The second element from the input vector has to be deleted as well. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 Now we will examine what happens if we take out a hidden node. We take out the first hidden node, i.e. $h_1$. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 In this case, we can remove the complete first line of our weight matrix: 
 
 
 
 
 
 
 
 
 
 
 
 
 
 Taking out a hidden node affects the next weight matrix as well. Let's have a look at what is happening in the network graph: 
 
 
 
 
 
 
 
 
 
 
 
 
 
 It is easy to see that the first column of the who weight matrix has to be removed again: 
 
 
 
 
 
 
 
 
 
 
 
 
 
 So far we have arbitrarily chosen one node to deactivate. The dropout approach means that we randomly choose a certain number of nodes from the input and the hidden layers, which remain active and turn off the other nodes of these layers. After this we can train a part of our learn set with this network. The next step consists in activating all the nodes again and randomly chose other nodes. It is also possible to train the whole training set with the randomly created dropout networks. 
 We present three possible randomly chosen dropout networks in the following three diagrams: 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 Now it is time to think about a possible Python implementation. 
 We will start with the weight matrix between input and hidden layer. We will randomly create a weight matrix for 10 input nodes and 5 hidden nodes. We fill our matrix with random numbers between -10 and 10, which are not proper weight values, but this way we can see better what is going on: 
 
 
 
 
 
 
 
 
 import   numpy   as   np 
 import   random 

 input_nodes   =   10 
 hidden_nodes   =   5 
 output_nodes   =   7 

 wih   =   np . random . randint ( - 10 ,   10 ,   ( hidden_nodes ,   input_nodes )) 
 wih 
 
 
 
 
 
 
 
 Output:: 
 
 array([[ -6,  -8,  -3,  -7,   2,  -9,  -3,  -5,  -6,   4],
       [  5,   3,   7,  -4,   4,   8,  -2,  -4,   7,   7],
       [  9,  -7,   4,   0,   4,   0,  -3,  -6,  -2,   7],
       [ -8,  -9,  -4,  -5,  -9,   8,  -8,  -8,  -2,  -3],
       [  3, -10,   0,  -3,   4,   0,   0,   2,  -7,  -9]]) 
 
 
 
 
 
 
 
 
 We will choose now the active nodes for the input layer. We calculate random indices for the active nodes: 
 
 
 
 
 
 
 
 
 active_input_percentage   =   0.7 
 active_input_nodes   =   int ( input_nodes   *   active_input_percentage ) 
 active_input_indices   =   sorted ( random . sample ( range ( 0 ,   input_nodes ),  
                               active_input_nodes )) 
 active_input_indices 
 
 
 
 
 
 
 
 Output:: 
 
 [0, 1, 2, 5, 7, 8, 9] 
 
 
 
 
 
 
 
 
 We learned above that we have to remove the column $j$, if the node $i_j$ is removed. We can easily accomplish this for all deactived nodes by using the slicing operator with the active nodes: 
 
 
 
 
 
 
 
 
 wih_old   =   wih . copy () 
 wih   =   wih [:,   active_input_indices ] 
 wih 
 
 
 
 
 
 
 
 Output:: 
 
 array([[ -6,  -8,  -3,  -9,  -5,  -6,   4],
       [  5,   3,   7,   8,  -4,   7,   7],
       [  9,  -7,   4,   0,  -6,  -2,   7],
       [ -8,  -9,  -4,   8,  -8,  -2,  -3],
       [  3, -10,   0,   0,   2,  -7,  -9]]) 
 
 
 
 
 
 
 
 
 As we have mentioned before, we will have to modify both the 'wih' and the 'who' matrix: 
 
 
 
 
 
 
 
 
 who   =   np . random . randint ( - 10 ,   10 ,   ( output_nodes ,   hidden_nodes )) 

 print ( who ) 
 active_hidden_percentage   =   0.7 
 active_hidden_nodes   =   int ( hidden_nodes   *   active_hidden_percentage ) 
 active_hidden_indices   =   sorted ( random . sample ( range ( 0 ,   hidden_nodes ),  
                              active_hidden_nodes )) 
 print ( active_hidden_indices ) 

 who_old   =   who . copy () 
 who   =   who [:,   active_hidden_indices ] 
 print ( who ) 
 
 
 
 
 
 
 
 
 
 [[  3   6  -3  -9   4]
 [-10   1   2   5   7]
 [ -8   1  -3   6   3]
 [ -3  -3   6  -5  -3]
 [ -4  -9   8  -3   5]
 [  8   4  -8   2   7]
 [ -2   2   3  -8  -5]]
[0, 2, 3]
[[  3  -3  -9]
 [-10   2   5]
 [ -8  -3   6]
 [ -3   6  -5]
 [ -4   8  -3]
 [  8  -8   2]
 [ -2   3  -8]]
 
 
 
 
 
 
 
 
 
 We have to change wih accordingly: 
 
 
 
 
 
 
 
 
 wih   =   wih [ active_hidden_indices ] 
 wih 
 
 
 
 
 
 
 
 Output:: 
 
 array([[-6, -8, -3, -9, -5, -6,  4],
       [ 9, -7,  4,  0, -6, -2,  7],
       [-8, -9, -4,  8, -8, -2, -3]]) 
 
 
 
 
 
 
 
 
 The following Python code summarizes the sniplets from above: 
 
 
 
 
 
 
 
 
 import   numpy   as   np 
 import   random 

 input_nodes   =   10 
 hidden_nodes   =   5 
 output_nodes   =   7 

 wih   =   np . random . randint ( - 10 ,   10 ,   ( hidden_nodes ,   input_nodes )) 
 print ( ""wih:  \n "" ,   wih ) 
 who   =   np . random . randint ( - 10 ,   10 ,   ( output_nodes ,   hidden_nodes )) 
 print ( ""who: \n "" ,   who ) 

 active_input_percentage   =   0.7 
 active_hidden_percentage   =   0.7 

 active_input_nodes   =   int ( input_nodes   *   active_input_percentage ) 
 active_input_indices   =   sorted ( random . sample ( range ( 0 ,   input_nodes ),  
                               active_input_nodes )) 
 print ( "" \n active input indices: "" ,   active_input_indices ) 
 active_hidden_nodes   =   int ( hidden_nodes   *   active_hidden_percentage ) 
 active_hidden_indices   =   sorted ( random . sample ( range ( 0 ,   hidden_nodes ),  
                              active_hidden_nodes )) 
 print ( ""active hidden indices: "" ,   active_hidden_indices ) 

 wih_old   =   wih . copy () 
 wih   =   wih [:,   active_input_indices ] 
 print ( "" \n wih after deactivating input nodes: \n "" ,   wih ) 
 wih   =   wih [ active_hidden_indices ] 
 print ( "" \n wih after deactivating hidden nodes: \n "" ,   wih ) 


 who_old   =   who . copy () 
 who   =   who [:,   active_hidden_indices ] 
 print ( "" \n wih after deactivating hidden nodes: \n "" ,   who ) 
 
 
 
 
 
 
 
 
 
 wih: 
 [[ -4   9   3   5  -9   5  -3   0   9   1]
 [  4   7  -7   3  -4   7   4  -5   6   2]
 [  5   8   1 -10  -8  -6   7  -4  -6   8]
 [  6  -3   7   4  -7  -4   0   8   9   1]
 [  6  -1   4  -3   5  -5  -5   5   4  -7]]
who:
 [[ -6   2  -2   4   0]
 [ -5  -3   3  -4 -10]
 [  4   6  -7  -7  -1]
 [ -4  -1 -10   0  -8]
 [  8  -2   9  -8  -9]
 [ -6   0  -2   1  -8]
 [  1  -4  -2  -6  -5]]

active input indices:  [1, 3, 4, 5, 7, 8, 9]
active hidden indices:  [0, 1, 2]

wih after deactivating input nodes:
 [[  9   5  -9   5   0   9   1]
 [  7   3  -4   7  -5   6   2]
 [  8 -10  -8  -6  -4  -6   8]
 [ -3   4  -7  -4   8   9   1]
 [ -1  -3   5  -5   5   4  -7]]

wih after deactivating hidden nodes:
 [[  9   5  -9   5   0   9   1]
 [  7   3  -4   7  -5   6   2]
 [  8 -10  -8  -6  -4  -6   8]]

wih after deactivating hidden nodes:
 [[ -6   2  -2]
 [ -5  -3   3]
 [  4   6  -7]
 [ -4  -1 -10]
 [  8  -2   9]
 [ -6   0  -2]
 [  1  -4  -2]]
 
 
 
 
 
 
 
 
 
 
 
 import   numpy   as   np 
 import   random 
 from   scipy.special   import   expit   as   activation_function 
 from   scipy.stats   import   truncnorm 

 def   truncated_normal ( mean = 0 ,   sd = 1 ,   low = 0 ,   upp = 10 ): 
     return   truncnorm ( 
         ( low   -   mean )   /   sd ,   ( upp   -   mean )   /   sd ,   loc = mean ,   scale = sd ) 


 class   NeuralNetwork : 
    
     def   __init__ ( self ,  
                  no_of_in_nodes ,  
                  no_of_out_nodes ,  
                  no_of_hidden_nodes , 
                  learning_rate , 
                  bias = None 
                 ):   

         self . no_of_in_nodes   =   no_of_in_nodes 
         self . no_of_out_nodes   =   no_of_out_nodes        
         self . no_of_hidden_nodes   =   no_of_hidden_nodes           
         self . learning_rate   =   learning_rate  
         self . bias   =   bias 
         self . create_weight_matrices () 
        
     def   create_weight_matrices ( self ): 
         X   =   truncated_normal ( mean = 2 ,   sd = 1 ,   low =- 0.5 ,   upp = 0.5 ) 
        
         bias_node   =   1   if   self . bias   else   0 

         n   =   ( self . no_of_in_nodes   +   bias_node )   *   self . no_of_hidden_nodes 
         X   =   truncated_normal ( mean = 2 ,   sd = 1 ,   low =- 0.5 ,   upp = 0.5 ) 
         self . wih   =   X . rvs ( n ) . reshape (( self . no_of_hidden_nodes ,  
                                                    self . no_of_in_nodes   +   bias_node )) 

         n   =   ( self . no_of_hidden_nodes   +   bias_node )   *   self . no_of_out_nodes 
         X   =   truncated_normal ( mean = 2 ,   sd = 1 ,   low =- 0.5 ,   upp = 0.5 ) 
         self . who   =   X . rvs ( n ) . reshape (( self . no_of_out_nodes ,  
                                                     ( self . no_of_hidden_nodes   +   bias_node ))) 

     def   dropout_weight_matrices ( self , 
                                 active_input_percentage = 0.70 , 
                                 active_hidden_percentage = 0.70 ): 
         # restore wih array, if it had been used for dropout 
         self . wih_orig   =   self . wih . copy () 
         self . no_of_in_nodes_orig   =   self . no_of_in_nodes 
         self . no_of_hidden_nodes_orig   =   self . no_of_hidden_nodes 
         self . who_orig   =   self . who . copy () 
        

         active_input_nodes   =   int ( self . no_of_in_nodes   *   active_input_percentage ) 
         active_input_indices   =   sorted ( random . sample ( range ( 0 ,   self . no_of_in_nodes ),  
                                       active_input_nodes )) 
         active_hidden_nodes   =   int ( self . no_of_hidden_nodes   *   active_hidden_percentage ) 
         active_hidden_indices   =   sorted ( random . sample ( range ( 0 ,   self . no_of_hidden_nodes ),  
                                        active_hidden_nodes )) 
        
         self . wih   =   self . wih [:,   active_input_indices ][ active_hidden_indices ]        
         self . who   =   self . who [:,   active_hidden_indices ] 
        
         self . no_of_hidden_nodes   =   active_hidden_nodes 
         self . no_of_in_nodes   =   active_input_nodes 
         return   active_input_indices ,   active_hidden_indices 
    
     def   weight_matrices_reset ( self ,  
                               active_input_indices ,  
                               active_hidden_indices ): 
        
         """""" 
         self.wih and self.who contain the newly adapted values from the active nodes. 
         We have to reconstruct the original weight matrices by assigning the new values  
         from the active nodes 
         """""" 
 
         temp   =   self . wih_orig . copy ()[:, active_input_indices ] 
         temp [ active_hidden_indices ]   =   self . wih 
         self . wih_orig [:,   active_input_indices ]   =   temp 
         self . wih   =   self . wih_orig . copy () 

         self . who_orig [:,   active_hidden_indices ]   =   self . who 
         self . who   =   self . who_orig . copy () 
         self . no_of_in_nodes   =   self . no_of_in_nodes_orig 
         self . no_of_hidden_nodes   =   self . no_of_hidden_nodes_orig 
 
           
    
     def   train_single ( self ,   input_vector ,   target_vector ): 
         """"""  
         input_vector and target_vector can be tuple, list or ndarray 
         """""" 
 
         if   self . bias : 
             # adding bias node to the end of the input_vector 
             input_vector   =   np . concatenate (   ( input_vector ,   [ self . bias ])   ) 

         input_vector   =   np . array ( input_vector ,   ndmin = 2 ) . T 
         target_vector   =   np . array ( target_vector ,   ndmin = 2 ) . T 

         output_vector1   =   np . dot ( self . wih ,   input_vector ) 
         output_vector_hidden   =   activation_function ( output_vector1 ) 
        
         if   self . bias : 
             output_vector_hidden   =   np . concatenate (   ( output_vector_hidden ,   [[ self . bias ]])   ) 
        
         output_vector2   =   np . dot ( self . who ,   output_vector_hidden ) 
         output_vector_network   =   activation_function ( output_vector2 ) 
        
         output_errors   =   target_vector   -   output_vector_network 
         # update the weights: 
         tmp   =   output_errors   *   output_vector_network   *   ( 1.0   -   output_vector_network )      
         tmp   =   self . learning_rate    *   np . dot ( tmp ,   output_vector_hidden . T ) 
         self . who   +=   tmp 


         # calculate hidden errors: 
         hidden_errors   =   np . dot ( self . who . T ,   output_errors ) 
         # update the weights: 
         tmp   =   hidden_errors   *   output_vector_hidden   *   ( 1.0   -   output_vector_hidden ) 
         if   self . bias : 
             x   =   np . dot ( tmp ,   input_vector . T )[: - 1 ,:]  
         else : 
             x   =   np . dot ( tmp ,   input_vector . T ) 
         self . wih   +=   self . learning_rate   *   x 

            
        
     def   train ( self ,   data_array ,  
               labels_one_hot_array , 
               epochs = 1 , 
               active_input_percentage = 0.70 , 
               active_hidden_percentage = 0.70 , 
               no_of_dropout_tests   =   10 ): 

         partition_length   =   int ( len ( data_array )   /   no_of_dropout_tests ) 
        
         for   epoch   in   range ( epochs ): 
             print ( ""epoch: "" ,   epoch ) 
             for   start   in   range ( 0 ,   len ( data_array ),   partition_length ): 
                 active_in_indices ,   active_hidden_indices   =  \
                            self . dropout_weight_matrices ( active_input_percentage , 
                                                         active_hidden_percentage ) 
                 for   i   in   range ( start ,   start   +   partition_length ): 
                     self . train_single ( data_array [ i ][ active_in_indices ],  
                                      labels_one_hot_array [ i ])  
                    
                 self . weight_matrices_reset ( active_in_indices ,   active_hidden_indices ) 

      

    
     def   confusion_matrix ( self ,   data_array ,   labels ): 
         cm   =   {} 
         for   i   in   range ( len ( data_array )): 
             res   =   self . run ( data_array [ i ]) 
             res_max   =   res . argmax () 
             target   =   labels [ i ][ 0 ] 
             if   ( target ,   res_max )   in   cm : 
                 cm [( target ,   res_max )]   +=   1 
             else : 
                 cm [( target ,   res_max )]   =   1 
         return   cm 
        
    
     def   run ( self ,   input_vector ): 
         # input_vector can be tuple, list or ndarray 
        
         if   self . bias : 
             # adding bias node to the end of the input_vector 
             input_vector   =   np . concatenate (   ( input_vector ,   [ self . bias ])   ) 
         input_vector   =   np . array ( input_vector ,   ndmin = 2 ) . T 

         output_vector   =   np . dot ( self . wih ,   input_vector ) 
         output_vector   =   activation_function ( output_vector ) 
        
         if   self . bias : 
             output_vector   =   np . concatenate (   ( output_vector ,   [[ self . bias ]])   ) 
            

         output_vector   =   np . dot ( self . who ,   output_vector ) 
         output_vector   =   activation_function ( output_vector ) 
    
         return   output_vector 
    
    
     def   evaluate ( self ,   data ,   labels ): 
         corrects ,   wrongs   =   0 ,   0 
         for   i   in   range ( len ( data )): 
             res   =   self . run ( data [ i ]) 
             res_max   =   res . argmax () 
             if   res_max   ==   labels [ i ]: 
                 corrects   +=   1 
             else : 
                 wrongs   +=   1 
         return   corrects ,   wrongs 
 
 
 
 
 
 
 
 
 
 
 import   pickle 

 with   open ( ""data/mnist/pickled_mnist.pkl"" ,   ""br"" )   as   fh : 
     data   =   pickle . load ( fh ) 

 train_imgs   =   data [ 0 ] 
 test_imgs   =   data [ 1 ] 
 train_labels   =   data [ 2 ] 
 test_labels   =   data [ 3 ] 
 train_labels_one_hot   =   data [ 4 ] 
 test_labels_one_hot   =   data [ 5 ] 

 image_size   =   28   # width and length 
 no_of_different_labels   =   10   #  i.e. 0, 1, 2, 3, ..., 9 
 image_pixels   =   image_size   *   image_size 
 
 
 
 
 
 
 
 
 
 
 parts   =   10 
 partition_length   =   int ( len ( train_imgs )   /   parts ) 
 print ( partition_length ) 

 start   =   0 
 for   start   in   range ( 0 ,   len ( train_imgs ),   partition_length ): 
     print ( start ,   start   +   partition_length ) 
 
 
 
 
 
 
 
 
 
 6000
0 6000
6000 12000
12000 18000
18000 24000
24000 30000
30000 36000
36000 42000
42000 48000
48000 54000
54000 60000
 
 
 
 
 
 
 
 
 
 
 
 epochs   =   3 

 simple_network   =   NeuralNetwork ( no_of_in_nodes   =   image_pixels ,  
                                no_of_out_nodes   =   10 ,  
                                no_of_hidden_nodes   =   100 , 
                                learning_rate   =   0.1 ) 
    
    
 
 simple_network . train ( train_imgs ,  
                      train_labels_one_hot ,  
                      active_input_percentage = 1 , 
                      active_hidden_percentage = 1 , 
                      no_of_dropout_tests   =   100 , 
                      epochs = epochs ) 
 
 
 
 
 
 
 
 
 
 epoch:  0
epoch:  1
epoch:  2
 
 
 
 
 
 
 
 
 
 
 
 corrects ,   wrongs   =   simple_network . evaluate ( train_imgs ,   train_labels ) 
 print ( ""accruracy train: "" ,   corrects   /   (   corrects   +   wrongs )) 
 corrects ,   wrongs   =   simple_network . evaluate ( test_imgs ,   test_labels ) 
 print ( ""accruracy: test"" ,   corrects   /   (   corrects   +   wrongs )) 
 
 
 
 
 
 
 
 
 
 accruracy train:  0.9317833333333333
accruracy: test 0.9296
 
 
 
 
 
 
 Previous Chapter:  Training and Testing with MNIST 
 Next Chapter:  Neural Networks with Scikit 
 
   © 2011 - 2019, Bernd Klein,
Bodenseo; 
Design by Denise Mitchinson adapted for python-course.eu by Bernd Klein "," Introduction,Modifying the Weight Arrays,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,None,", https://www.python-course.eu/http://www.python-kurs.eu/stellengesuch/Stellenanzeige.pdf
8,Neural Networks with Scikit,https://www.python-course.eu/neural_networks_with_scikit.php,"Machine Learning with Python: Neural Networks with Scikit 
 
 
 
 - remove in and out prompt from ipython notebook 
%%HTML

div.prompt {display:none}

 - 
 
 
 
 
 Python Machine Learning Tutorial 
 
  Begin Top Menu  
 
 Home Python 2 Tutorial Python 3 Tutorial Advanced Topics Numerical Programming Machine Learning Tkinter Tutorial Contact 
 
  End Top Menu  
 Machine Learning 
 
 
 Machine Learning Terminology k-nearest Neighbor Classifier Neural Networks from Scratch in Python Neural Network in Python using Numpy Backpropagation in Neural Networks Confusion Matrix Training and Testing with MNIST Dropout Neural Networks Neural Networks with Scikit Machine Learning with Scikit and Python Introduction Naive Bayes Classifier Naive Bayes Classifier with Scikit Introduction into Text Classification using Naive Bayes Python Implementation of Text Classification Decision Trees Regression Trees Random Forests Boosting Algorithm Principal Component Analysis Linear Discriminant Analysis Expectation Maximization and Gaussian Mixture Model Introduction into TensorFlow 
 
 
 
 Help Needed 

This website is free of annoying ads. We want to keep it like this. You can help with your donation:
 
 
 
 
 
 
 
 
 The need for donations 
 
 
 
 
 
 
 
This website is created by: 
 Python Training Courses in Toronto, Canada 
 
On site trainings in Europe, Canada and the US.
 
 
 
  Dieses Tag dort einfügen, wo die +1-Schaltfläche dargestellt werden soll  
 
 
 Help Needed 

This website is free of annoying ads. We want to keep it like this. You can help with your donation:
 
 
 
 
 
 
 
 
 
 The need for donations 
 
 Job Applications 
 
 Python Lecturer 
 bodenseo is looking for a new trainer and software developper. You need to live in Germany and know German. Interested? Find out  more !
 Python Programmer 
We are looking for a qualified Python programmer to further improve our website. This is a work from home job, wherever you live in the world! 
If you think that you are the right person or if you have further questions, please do not hesitate to  contact us .
 
 
 
 Bernd Klein on Facebook 
 
 
 
Search this website:
 
 
 
 Classroom Training Courses 
 
This website contains a free and extensive online tutorial by Bernd Klein, using
material from his classroom Python training courses Python classes 
 
 © kabliczech - Fotolia.com Quote of the Day: ""The difference between stupidity and genius is that genius has its limits""  (Albert Einstein)
   Help Needed 
 
 
 
 
 
 The need for donations Data Protection Declaration Data Protection Declaration 
 Previous Chapter:  Dropout Neural Networks 
 Next Chapter:  Machine Learning with Scikit and Python 
 
 
 
 
 Neural Networks with scikit Perceptron Class 
 We will start with the Perceptron class contained in Scikit-Learn. We will use it on the iris dataset, which we had already used in our chapter on  k-nearest neighbor 
 
 
 
 
 
 
 
 
 import   numpy   as   np 
 from   sklearn.datasets   import   load_iris 
 from   sklearn.linear_model   import   Perceptron 

 iris   =   load_iris () 

 print ( iris . data [: 3 ]) 
 print ( iris . data [ 15 : 18 ]) 
 print ( iris . data [ 37 : 40 ]) 


 # we extract only the lengths and widthes of the petals: 
 X   =   iris . data [:,   ( 2 ,   3 )]    
 
 
 
 
 
 
 
 
 
 [[5.1 3.5 1.4 0.2]
 [4.9 3.  1.4 0.2]
 [4.7 3.2 1.3 0.2]]
[[5.7 4.4 1.5 0.4]
 [5.4 3.9 1.3 0.4]
 [5.1 3.5 1.4 0.3]]
[[4.9 3.6 1.4 0.1]
 [4.4 3.  1.3 0.2]
 [5.1 3.4 1.5 0.2]]
 
 
 
 
 
 
 
 
 
 iris.label contains the labels 0, 1 and 2 corresponding three species of Iris flower: 
 
 Iris setosa, 
 Iris virginica and 
 Iris versicolor. 
 
 
 
 
 
 
 
 
 
 print ( iris . target ) 
 
 
 
 
 
 
 
 
 
 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2]
 
 
 
 
 
 
 
 
 
 We turn the three classes into two classes, i.e. 
 
 Iris setosa 
 not Iris setosa (this means Iris virginica or Iris versicolor) 
 
 
 
 
 
 
 
 
 
 y   =   ( iris . target == 0 ) . astype ( np . int8 ) 
 print ( y ) 
 
 
 
 
 
 
 
 
 
 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0]
 
 
 
 
 
 
 
 
 
 We create now a Perceptron and fit the data X and y: 
 
 
 
 
 
 
 
 
 p   =   Perceptron ( random_state = 42 , 
               max_iter = 10 , 
               tol = 0.001 ) 
 p . fit ( X ,   y ) 
 
 
 
 
 
 
 
 Output:: 
 
 Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,
      fit_intercept=True, max_iter=10, n_iter=None, n_iter_no_change=5,
      n_jobs=None, penalty=None, random_state=42, shuffle=True, tol=0.001,
      validation_fraction=0.1, verbose=0, warm_start=False) 
 
 
 
 
 
 
 
 
 Now, we are ready for predictions: 
 
 
 
 
 
 
 
 
 values   =   [[ 1.5 ,   0.1 ],   [ 1.8 ,   0.4 ],   [ 1.3 , 0.2 ]] 

 for   value   in   X : 
     pred   =   p . predict ([ value ]) 
     print ([ pred ]) 
 
 
 
 
 
 
 
 
 
 [array([1], dtype=int8)]
[array([1], dtype=int8)]
[array([1], dtype=int8)]
[array([1], dtype=int8)]
[array([1], dtype=int8)]
[array([1], dtype=int8)]
[array([1], dtype=int8)]
[array([1], dtype=int8)]
[array([1], dtype=int8)]
[array([1], dtype=int8)]
[array([1], dtype=int8)]
[array([1], dtype=int8)]
[array([1], dtype=int8)]
[array([1], dtype=int8)]
[array([1], dtype=int8)]
[array([1], dtype=int8)]
[array([1], dtype=int8)]
[array([1], dtype=int8)]
[array([1], dtype=int8)]
[array([1], dtype=int8)]
[array([1], dtype=int8)]
[array([1], dtype=int8)]
[array([1], dtype=int8)]
[array([1], dtype=int8)]
[array([1], dtype=int8)]
[array([1], dtype=int8)]
[array([1], dtype=int8)]
[array([1], dtype=int8)]
[array([1], dtype=int8)]
[array([1], dtype=int8)]
[array([1], dtype=int8)]
[array([1], dtype=int8)]
[array([1], dtype=int8)]
[array([1], dtype=int8)]
[array([1], dtype=int8)]
[array([1], dtype=int8)]
[array([1], dtype=int8)]
[array([1], dtype=int8)]
[array([1], dtype=int8)]
[array([1], dtype=int8)]
[array([1], dtype=int8)]
[array([1], dtype=int8)]
[array([1], dtype=int8)]
[array([1], dtype=int8)]
[array([1], dtype=int8)]
[array([1], dtype=int8)]
[array([1], dtype=int8)]
[array([1], dtype=int8)]
[array([1], dtype=int8)]
[array([1], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
[array([0], dtype=int8)]
 
 
 
 
 
 ### Multi-layer Perceptron

We will continue with examples using the multilayer perceptron (MLP). 
The multilayer perceptron (MLP) is a feedforward artificial neural network model that maps sets of input data onto a set of appropriate outputs. An MLP consists of multiple layers
and each layer is fully connected to the following one.
The nodes of the layers are neurons using nonlinear activation functions, except for the nodes of the input layer. There can be one or more non-linear hidden layers between the input and the output layer. 

 
 
 
 
 
 from   sklearn.neural_network   import   MLPClassifier 
 X   =   [[ 0. ,   0. ],   [ 0. ,   1. ],   [ 1. ,   0. ],   [ 1. ,   1. ]] 
 y   =   [ 0 ,   0 ,   0 ,   1 ] 
 clf   =   MLPClassifier ( solver = 'lbfgs' ,   alpha = 1e-5 , 
                     hidden_layer_sizes = ( 5 ,   2 ),   random_state = 1 ) 

 print ( clf . fit ( X ,   y ))                          
 
 
 
 
 
 
 
 
 
 MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(5, 2), learning_rate='constant',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,
       random_state=1, shuffle=True, solver='lbfgs', tol=0.0001,
       validation_fraction=0.1, verbose=False, warm_start=False)
 
 
 
 
 
 
 
 
 
 The following diagram depicts the neural network, that we have trained for our classifier clf. We have two input nodes $X_0$ and $X_1$, called the input layer, and one output neuron 'Out'. We have two hidden layers the first one with the neurons $H_{00}$ ... $H_{04}$ and the second hidden layer consisting of $H_{10}$ and $H_{11}$.
Each neuron of the hidden layers and the output neuron possesses a corresponding Bias, i.e. 
$B_{00}$ is the corresponding Bias to the neuron $H_{00}$, $B_{01}$ is the corresponding Bias to the neuron $H_{01}$ and so on. 
 Each neuron of the hidden layers receives the output from every neuron of the previous layers and transforms these values with a weighted linear summation
$$\sum_{i=0}^{n-1}w_ix_i = w_0x_0 + w_1x_1 + ... + w_{n-1}x_{n-1}$$
into an output value, where n is the number of neurons of the layer and $w_i$ corresponds to the i th  component of the weight vector.
The output layer receives the values from the last hidden layer. It also performs a linear summation, but a non-linear activation function 
$$g(\cdot):R \rightarrow R$$
like the hyperbolic tan function will be applied to the summation result. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 The attribute coefs_ contains a list of weight matrices for every layer. The weight matrix at index i holds the weights between the layer i and layer i + 1. 
 
 
 
 
 
 
 
 
 print ( ""weights between input and first hidden layer:"" ) 
 print ( clf . coefs_ [ 0 ]) 
 print ( "" \n weights between first hidden and second hidden layer:"" ) 
 print ( clf . coefs_ [ 1 ]) 
 
 
 
 
 
 
 
 
 
 weights between input and first hidden layer:
[[-0.14203691 -1.18304359 -0.85567518 -4.53250719 -0.60466275]
 [-0.69781111 -3.5850093  -0.26436018 -4.39161248  0.06644423]]

weights between first hidden and second hidden layer:
[[ 0.29179638 -0.14155284]
 [ 4.02666592 -0.61556475]
 [-0.51677234  0.51479708]
 [ 7.37215202 -0.31936965]
 [ 0.32920668  0.64428109]]
 
 
 
 
 
 
 
 
 
 The summation formula of the neuron H 00  is defined by: 
$$\sum_{i=0}^{n-1}w_ix_i = w_0x_0 + w_1x_1 + w_{B_{11}} * B_{11}$$ which can be written as 
$$\sum_{i=0}^{n-1}w_ix_i = w_0x_0 + w_1x_1 + w_{B_{11}}$$ because $B_{11} = 1$. 
 We can get the values for $w_0$ and $w_1$ from clf.coefs_ like this: 
 $w_0 =$ clf.coefs_[0][0][0] and $w_1 =$ clf.coefs_[0][1][0] 
 
 
 
 
 
 
 
 
 print ( ""w0 = "" ,   clf . coefs_ [ 0 ][ 0 ][ 0 ]) 
 print ( ""w1 = "" ,   clf . coefs_ [ 0 ][ 1 ][ 0 ]) 
 
 
 
 
 
 
 
 
 
 w0 =  -0.14203691267827162
w1 =  -0.6978111149778682
 
 
 
 
 
 
 
 
 
 The weight vector of $H_{00}$ can be accessed with 
 
 
 
 
 
 
 
 
 clf . coefs_ [ 0 ][:, 0 ] 
 
 
 
 
 
 
 
 Output:: 
 
 array([-0.14203691, -0.69781111]) 
 
 
 
 
 
 
 
 
 We can generalize the above to access a neuron $H_{ij}$ in the following way: 
 
 
 
 
 
 
 
 
 for   i   in   range ( len ( clf . coefs_ )): 
     number_neurons_in_layer   =   clf . coefs_ [ i ] . shape [ 1 ] 
     for   j   in   range ( number_neurons_in_layer ): 
         weights   =   clf . coefs_ [ i ][:, j ] 
         print ( i ,   j ,   weights ,   end = "", "" ) 
         print () 
     print () 
 
 
 
 
 
 
 
 
 
 0 0 [-0.14203691 -0.69781111], 
0 1 [-1.18304359 -3.5850093 ], 
0 2 [-0.85567518 -0.26436018], 
0 3 [-4.53250719 -4.39161248], 
0 4 [-0.60466275  0.06644423], 

1 0 [ 0.29179638  4.02666592 -0.51677234  7.37215202  0.32920668], 
1 1 [-0.14155284 -0.61556475  0.51479708 -0.31936965  0.64428109], 

2 0 [-4.96774269 -0.86330397], 

 
 
 
 
 
 
 
 
 
 intercepts_ is a list of bias vectors, where the vector at index i represents the bias values added to layer i+1. 
 
 
 
 
 
 
 
 
 print ( ""Bias values for first hidden layer:"" ) 
 print ( clf . intercepts_ [ 0 ]) 
 print ( "" \n Bias values for second hidden layer:"" ) 
 print ( clf . intercepts_ [ 1 ]) 
 
 
 
 
 
 
 
 
 
 Bias values for first hidden layer:
[-0.14962269 -0.59232707 -0.5472481   7.02667699 -0.87510813]

Bias values for second hidden layer:
[-3.61417672 -0.76834882]
 
 
 
 
 
 
 
 
 
 The main reason, why we train a classifier is to predict results for new samples. We can do this with the predict method. The method returns a predicted class for a sample, in our case a  ""0"" or a ""1"" : 
 
 
 
 
 
 
 
 
 result   =   clf . predict ([[ 0 ,   0 ],   [ 0 ,   1 ],  
                       [ 1 ,   0 ],   [ 0 ,   1 ],  
                       [ 1 ,   1 ],   [ 2. ,   2. ], 
                       [ 1.3 ,   1.3 ],   [ 2 ,   4.8 ]]) 
 
 
 
 
 
 
 
 
 Instead of just looking at the class results, we can also use the predict_proba method to get the probability estimates. 
 
 
 
 
 
 
 
 
 prob_results   =   clf . predict_proba ([[ 0 ,   0 ],   [ 0 ,   1 ],  
                                   [ 1 ,   0 ],   [ 0 ,   1 ],  
                                   [ 1 ,   1 ],   [ 2. ,   2. ],  
                                   [ 1.3 ,   1.3 ],   [ 2 ,   4.8 ]]) 
 print ( prob_results ) 
 
 
 
 
 
 
 
 
 
 [[1.00000000e+000 5.25723951e-101]
 [1.00000000e+000 3.71534882e-031]
 [1.00000000e+000 6.47069178e-029]
 [1.00000000e+000 3.71534882e-031]
 [2.07145538e-004 9.99792854e-001]
 [2.07145538e-004 9.99792854e-001]
 [2.07145538e-004 9.99792854e-001]
 [2.07145538e-004 9.99792854e-001]]
 
 
 
 
 
 
 
 
 
 prob_results[i][0] gives us the probability for the class0, i.e. a ""0"" and results[i][1] the probabilty for a ""1"". i corresponds to the i th  sample. 
 Another Example We will populate two clusters (class0 and class1) in a two dimensional space. 
 
 
 
 
 
 
 
 
 import   numpy   as   np 
 from   matplotlib   import   pyplot   as   plt 

 npoints   =   50 
 X ,   Y   =   [],   [] 
 # class 0 
 X . append ( np . random . uniform ( low =- 2.5 ,   high = 2.3 ,   size = ( npoints ,))   ) 
 Y . append ( np . random . uniform ( low =- 1.7 ,   high = 2.8 ,   size = ( npoints ,))) 

 # class 1 
 X . append ( np . random . uniform ( low =- 7.2 ,   high =- 4.4 ,   size = ( npoints ,))   ) 
 Y . append ( np . random . uniform ( low = 3 ,   high = 6.5 ,   size = ( npoints ,))) 

 learnset   =   [] 
 learnlabels   =   [] 
 for   i   in   range ( 2 ): 
     # adding points of class i to learnset 
     points   =   zip ( X [ i ],   Y [ i ]) 
     for   p   in   points : 
         learnset . append ( p ) 
         learnlabels . append ( i ) 

 npoints_test   =   3   *   npoints 
 TestX   =   np . random . uniform ( low =- 7.2 ,   high = 5 ,   size = ( npoints_test ,))  
 TestY   =   np . random . uniform ( low =- 4 ,   high = 9 ,   size = ( npoints_test ,)) 
 testset   =   [] 
 points   =   zip ( TestX ,   TestY ) 
 for   p   in   points : 
     testset . append ( p ) 


 colours   =   [ ""b"" ,   ""r"" ] 
 for   i   in   range ( 2 ): 
     plt . scatter ( X [ i ],   Y [ i ],   c = colours [ i ]) 
 plt . scatter ( TestX ,   TestY ,   c = ""g"" ) 
 plt . show () 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 We will train a MLPClassifier for our two classes: 
 
 
 
 
 
 
 
 
 import   matplotlib.pyplot   as   plt 
 from   sklearn.datasets   import   fetch_mldata 
 from   sklearn.neural_network   import   MLPClassifier 

 mlp   =   MLPClassifier ( hidden_layer_sizes = ( 20 ,   3 ),   max_iter = 150 ,   alpha = 1e-4 , 
                     solver = 'sgd' ,   verbose = 10 ,   tol = 1e-4 ,   random_state = 1 , 
                     learning_rate_init =. 1 ) 

 mlp . fit ( learnset ,   learnlabels ) 
 print ( ""Training set score:  %f ""   %   mlp . score ( learnset ,   learnlabels )) 
 print ( ""Test set score:  %f ""   %   mlp . score ( learnset ,   learnlabels )) 


 mlp . classes_ 
 
 
 
 
 
 
 
 
 
 Iteration 1, loss = 0.50079019
Iteration 2, loss = 0.46400111
Iteration 3, loss = 0.42645559
Iteration 4, loss = 0.38630293
Iteration 5, loss = 0.35703136
Iteration 6, loss = 0.32589219
Iteration 7, loss = 0.29516201
Iteration 8, loss = 0.26677878
Iteration 9, loss = 0.24073422
Iteration 10, loss = 0.21667340
Iteration 11, loss = 0.19438790
Iteration 12, loss = 0.17388987
Iteration 13, loss = 0.15530203
Iteration 14, loss = 0.13868463
Iteration 15, loss = 0.12405113
Iteration 16, loss = 0.11130529
Iteration 17, loss = 0.10011663
Iteration 18, loss = 0.09029552
Iteration 19, loss = 0.08169809
Iteration 20, loss = 0.07417581
Iteration 21, loss = 0.06758791
Iteration 22, loss = 0.06180892
Iteration 23, loss = 0.05673045
Iteration 24, loss = 0.05226030
Iteration 25, loss = 0.04833629
Iteration 26, loss = 0.04487704
Iteration 27, loss = 0.04181651
Iteration 28, loss = 0.03910883
Iteration 29, loss = 0.03669848
Iteration 30, loss = 0.03454754
Iteration 31, loss = 0.03262256
Iteration 32, loss = 0.03089441
Iteration 33, loss = 0.02933799
Iteration 34, loss = 0.02793164
Iteration 35, loss = 0.02665732
Iteration 36, loss = 0.02549950
Iteration 37, loss = 0.02444474
Iteration 38, loss = 0.02348141
Iteration 39, loss = 0.02259936
Iteration 40, loss = 0.02178970
Iteration 41, loss = 0.02104464
Iteration 42, loss = 0.02035728
Iteration 43, loss = 0.01972159
Iteration 44, loss = 0.01913238
Iteration 45, loss = 0.01858504
Iteration 46, loss = 0.01807525
Iteration 47, loss = 0.01759938
Iteration 48, loss = 0.01715424
Iteration 49, loss = 0.01673697
Iteration 50, loss = 0.01634503
Iteration 51, loss = 0.01597614
Iteration 52, loss = 0.01562821
Iteration 53, loss = 0.01529952
Iteration 54, loss = 0.01498845
Iteration 55, loss = 0.01469354
Iteration 56, loss = 0.01441349
Iteration 57, loss = 0.01414710
Iteration 58, loss = 0.01389331
Iteration 59, loss = 0.01365116
Iteration 60, loss = 0.01341977
Iteration 61, loss = 0.01319837
Iteration 62, loss = 0.01298624
Iteration 63, loss = 0.01278273
Iteration 64, loss = 0.01258725
Iteration 65, loss = 0.01239927
Iteration 66, loss = 0.01221832
Iteration 67, loss = 0.01204393
Iteration 68, loss = 0.01187567
Iteration 69, loss = 0.01171318
Iteration 70, loss = 0.01155611
Iteration 71, loss = 0.01140413
Iteration 72, loss = 0.01125697
Iteration 73, loss = 0.01111436
Iteration 74, loss = 0.01097603
Iteration 75, loss = 0.01084176
Iteration 76, loss = 0.01071135
Iteration 77, loss = 0.01058459
Iteration 78, loss = 0.01046130
Iteration 79, loss = 0.01034132
Iteration 80, loss = 0.01022448
Iteration 81, loss = 0.01011065
Iteration 82, loss = 0.00999968
Iteration 83, loss = 0.00989145
Iteration 84, loss = 0.00978583
Iteration 85, loss = 0.00968273
Iteration 86, loss = 0.00958202
Iteration 87, loss = 0.00948363
Iteration 88, loss = 0.00938744
Iteration 89, loss = 0.00929339
Iteration 90, loss = 0.00920138
Iteration 91, loss = 0.00911134
Iteration 92, loss = 0.00902320
Iteration 93, loss = 0.00893689
Iteration 94, loss = 0.00885236
Iteration 95, loss = 0.00876958
Iteration 96, loss = 0.00868844
Iteration 97, loss = 0.00860890
Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
Training set score: 1.000000
Test set score: 1.000000
 
 
 
 
 Output:: 
 
 array([0, 1]) 
 
 
 
 
 
 
 
 
 
 
 predictions   =   clf . predict ( testset ) 
 predictions 
 
 
 
 
 
 
 
 Output:: 
 
 array([1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1,
       1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1,
       1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,
       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0,
       1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0,
       0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1,
       0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0]) 
 
 
 
 
 
 
 
 
 
 
 testset   =   np . array ( testset ) 
 testset [ predictions == 1 ] 


 colours   =   [ '#C0FFFF' ,   ""#FFC8C8"" ] 
 for   i   in   range ( 2 ): 
     plt . scatter ( X [ i ],   Y [ i ],   c = colours [ i ]) 


 colours   =   [ ""b"" ,   ""r"" ] 
 for   i   in   range ( 2 ): 
     cls   =   testset [ predictions == i ] 
     Xt ,   Yt   =   zip ( * cls ) 
     plt . scatter ( Xt ,   Yt ,   marker = ""D"" ,   c = colours [ i ]) 
    
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 MNIST Dataset We have already used the MNIST dataset in the chapter  Testing with MNIST  of our tutorial. You will also find some explanations about this dataset. 
 We want to apply the MLPClassifier on the MNIST data. We can load in the data with pickle: 
 
 
 
 
 
 
 
 
 import   pickle 

 with   open ( ""data/mnist/pickled_mnist.pkl"" ,   ""br"" )   as   fh : 
     data   =   pickle . load ( fh ) 

 train_imgs   =   data [ 0 ] 
 test_imgs   =   data [ 1 ] 
 train_labels   =   data [ 2 ] 
 test_labels   =   data [ 3 ] 
 train_labels_one_hot   =   data [ 4 ] 
 test_labels_one_hot   =   data [ 5 ] 

 image_size   =   28   # width and length 
 no_of_different_labels   =   10   #  i.e. 0, 1, 2, 3, ..., 9 
 image_pixels   =   image_size   *   image_size 
 
 
 
 
 
 
 
 
 
 
 mlp   =   MLPClassifier ( hidden_layer_sizes = ( 100 ,   ),  
                     max_iter = 480 ,   alpha = 1e-4 , 
                     solver = 'sgd' ,   verbose = 10 ,  
                     tol = 1e-4 ,   random_state = 1 , 
                     learning_rate_init =. 1 ) 

 train_labels   =   train_labels . reshape ( train_labels . shape [ 0 ],) 
 print ( train_imgs . shape ,   train_labels . shape ) 

 mlp . fit ( train_imgs ,   train_labels ) 
 print ( ""Training set score:  %f ""   %   mlp . score ( train_imgs ,   train_labels )) 
 print ( ""Test set score:  %f ""   %   mlp . score ( test_imgs ,   test_labels )) 
 help ( mlp . fit ) 
 
 
 
 
 
 
 
 
 
 (60000, 784) (60000,)
Iteration 1, loss = 0.29308647
Iteration 2, loss = 0.12126145
Iteration 3, loss = 0.08665577
Iteration 4, loss = 0.06916886
Iteration 5, loss = 0.05734882
Iteration 6, loss = 0.04697824
Iteration 7, loss = 0.04005900
Iteration 8, loss = 0.03370386
Iteration 9, loss = 0.02848827
Iteration 10, loss = 0.02453574
Iteration 11, loss = 0.02058716
Iteration 12, loss = 0.01649971
Iteration 13, loss = 0.01408953
Iteration 14, loss = 0.01173909
Iteration 15, loss = 0.00925713
Iteration 16, loss = 0.00879338
Iteration 17, loss = 0.00687255
Iteration 18, loss = 0.00578659
Iteration 19, loss = 0.00492355
Iteration 20, loss = 0.00414159
Iteration 21, loss = 0.00358124
Iteration 22, loss = 0.00324285
Iteration 23, loss = 0.00299358
Iteration 24, loss = 0.00268943
Iteration 25, loss = 0.00248878
Iteration 26, loss = 0.00229525
Iteration 27, loss = 0.00218314
Iteration 28, loss = 0.00203129
Iteration 29, loss = 0.00190647
Iteration 30, loss = 0.00180089
Iteration 31, loss = 0.00175467
Iteration 32, loss = 0.00165441
Iteration 33, loss = 0.00159778
Iteration 34, loss = 0.00152206
Iteration 35, loss = 0.00146529
Iteration 36, loss = 0.00143086
Iteration 37, loss = 0.00138042
Iteration 38, loss = 0.00133189
Iteration 39, loss = 0.00128424
Iteration 40, loss = 0.00125897
Iteration 41, loss = 0.00121776
Iteration 42, loss = 0.00118951
Iteration 43, loss = 0.00115738
Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
Training set score: 1.000000
Test set score: 0.980600
Help on method fit in module sklearn.neural_network.multilayer_perceptron:

fit(X, y) method of sklearn.neural_network.multilayer_perceptron.MLPClassifier instance
    Fit the model to data matrix X and target(s) y.
    
    Parameters
    ----------
    X : array-like or sparse matrix, shape (n_samples, n_features)
        The input data.
    
    y : array-like, shape (n_samples,) or (n_samples, n_outputs)
        The target values (class labels in classification, real numbers in
        regression).
    
    Returns
    -------
    self : returns a trained MLP model.

 
 
 
 
 
 
 
 
 
 
 
 fig ,   axes   =   plt . subplots ( 4 ,   4 ) 
 # use global min / max to ensure all weights are shown on the same scale 
 vmin ,   vmax   =   mlp . coefs_ [ 0 ] . min (),   mlp . coefs_ [ 0 ] . max () 
 for   coef ,   ax   in   zip ( mlp . coefs_ [ 0 ] . T ,   axes . ravel ()): 
     ax . matshow ( coef . reshape ( 28 ,   28 ),   cmap = plt . cm . gray ,   vmin =. 5   *   vmin , 
                vmax =. 5   *   vmax ) 
     ax . set_xticks (()) 
     ax . set_yticks (()) 

 plt . show () 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 In [ ]: 
 
 
  
 
 
 
 
 
 
 
 In [ ]: 
 
 
  
 
 
 
 
 
 
 
 In [ ]: 
 
 
  
 
 
 
 
 
 Previous Chapter:  Dropout Neural Networks 
 Next Chapter:  Machine Learning with Scikit and Python 
 
   © 2011 - 2019, Bernd Klein,
Bodenseo; 
Design by Denise Mitchinson adapted for python-course.eu by Bernd Klein "," Perceptron Class,None,None,None,None,None,None,None,None,None,None,None,None,None,Another Example,None,MNIST Dataset,", https://www.python-course.eu/http://www.python-kurs.eu/stellengesuch/Stellenanzeige.pdf
9,Machine Learning with Scikit and Python,https://www.python-course.eu/machine_learning_with_scikit.php,"Machine Learning with Python: Machine Learning with Scikit and Python 
 
 
 
 - remove in and out prompt from ipython notebook 
%%HTML

div.prompt {display:none}

 - 
 
 
 
 
 Python Machine Learning Tutorial 
 
  Begin Top Menu  
 
 Home Python 2 Tutorial Python 3 Tutorial Advanced Topics Numerical Programming Machine Learning Tkinter Tutorial Contact 
 
  End Top Menu  
 Machine Learning 
 
 
 Machine Learning Terminology k-nearest Neighbor Classifier Neural Networks from Scratch in Python Neural Network in Python using Numpy Backpropagation in Neural Networks Confusion Matrix Training and Testing with MNIST Dropout Neural Networks Neural Networks with Scikit Machine Learning with Scikit and Python Introduction Naive Bayes Classifier Naive Bayes Classifier with Scikit Introduction into Text Classification using Naive Bayes Python Implementation of Text Classification Decision Trees Regression Trees Random Forests Boosting Algorithm Principal Component Analysis Linear Discriminant Analysis Expectation Maximization and Gaussian Mixture Model Introduction into TensorFlow 
 
 
 
 Help Needed 

This website is free of annoying ads. We want to keep it like this. You can help with your donation:
 
 
 
 
 
 
 
 
 The need for donations 
 
 
 
 
 
 
 
This website is created by: 
 Python Training Courses in Toronto, Canada 
 
On site trainings in Europe, Canada and the US.
 
 
 
  Dieses Tag dort einfügen, wo die +1-Schaltfläche dargestellt werden soll  
 
 
 Help Needed 

This website is free of annoying ads. We want to keep it like this. You can help with your donation:
 
 
 
 
 
 
 
 
 
 The need for donations 
 
 Job Applications 
 
 Python Lecturer 
 bodenseo is looking for a new trainer and software developper. You need to live in Germany and know German. Interested? Find out  more !
 Python Programmer 
We are looking for a qualified Python programmer to further improve our website. This is a work from home job, wherever you live in the world! 
If you think that you are the right person or if you have further questions, please do not hesitate to  contact us .
 
 
 
 Bernd Klein on Facebook 
 
 
 
Search this website:
 
 
 
 Classroom Training Courses 
 
This website contains a free and extensive online tutorial by Bernd Klein, using
material from his classroom Python training courses Python classes 
 
 © kabliczech - Fotolia.com Quote of the Day: ""To err is human, but to really foul things up you need a computer.""  (Paul R. Ehrlich)
   Help Needed 
 
 
 
 
 
 The need for donations Data Protection Declaration Data Protection Declaration 
 Previous Chapter:  Neural Networks with Scikit 
 Next Chapter:  Introduction Naive Bayes Classifier 
 
 
 
 
 Scikit 
 Scikit-learn is a Python module merging classic machine learning algorithms  with the world of scientific Python packages (NumPy, SciPy, matplotlib). 
 
 
 
 
 
 
 Our Learning Set: ""digits"" 
 
 
 
 
 
 
 
 
 % matplotlib  inline
 
 
 
 
 
 
 
 
 
 
 import   numpy   as   np 
 from   sklearn   import   datasets 
 #iris = datasets.load_iris() 
 digits   =   datasets . load_digits () 
 print ( type ( digits )) 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 The digits dataset is a dictionary-like objects, containing the actual data and some metadata. 
 
 
 
 
 
 
 
 
 print ( digits . data ) 
 
 
 
 
 
 
 
 
 
 [[  0.   0.   5. ...,   0.   0.   0.]
 [  0.   0.   0. ...,  10.   0.   0.]
 [  0.   0.   0. ...,  16.   9.   0.]
 ..., 
 [  0.   0.   1. ...,   6.   0.   0.]
 [  0.   0.   2. ...,  12.   0.   0.]
 [  0.   0.  10. ...,  12.   1.   0.]]
 
 
 
 
 
 
 
 
 
 digits.data contains the features, i.e. images of handwritten images of digits, which can be used for classification. 
 
 
 
 
 
 
 
 
 digits . target 
 
 
 
 
 
 
 
 Output:: 
 
 array([0, 1, 2, ..., 8, 9, 8]) 
 
 
 
 
 
 
 
 
 
 
 len ( digits . data ),   len ( digits . target ) 
 
 
 
 
 
 
 
 Output:: 
 
 (1797, 1797) 
 
 
 
 
 
 
 
 
 digits.target contain the labels, i.e. digits from 0 to 9 for the digits of digits.data.
The data ""digits"" is a 2 D array with the shape (number of samples, number of features). In our case, a sample is an image of shape (8, 8): 
 
 
 
 
 
 
 
 
 print ( digits . target [ 0 ],   digits . data [ 0 ]) 
 print ( digits . images [ 0 ]) 
 
 
 
 
 
 
 
 
 
 0 [  0.   0.   5.  13.   9.   1.   0.   0.   0.   0.  13.  15.  10.  15.   5.
   0.   0.   3.  15.   2.   0.  11.   8.   0.   0.   4.  12.   0.   0.   8.
   8.   0.   0.   5.   8.   0.   0.   9.   8.   0.   0.   4.  11.   0.   1.
  12.   7.   0.   0.   2.  14.   5.  10.  12.   0.   0.   0.   0.   6.  13.
  10.   0.   0.   0.]
[[  0.   0.   5.  13.   9.   1.   0.   0.]
 [  0.   0.  13.  15.  10.  15.   5.   0.]
 [  0.   3.  15.   2.   0.  11.   8.   0.]
 [  0.   4.  12.   0.   0.   8.   8.   0.]
 [  0.   5.   8.   0.   0.   9.   8.   0.]
 [  0.   4.  11.   0.   1.  12.   7.   0.]
 [  0.   2.  14.   5.  10.  12.   0.   0.]
 [  0.   0.   6.  13.  10.   0.   0.   0.]]
 
 
 
 
 
 
 
 
 
 Learning and Predicting 
 
 
 
 
 
 
 We want to predict for a given image, which digit it depicts. Our data set contains samples
for the classes 0 (zero) to 9 (nine). 
We will use these samples to fit an estimator so that we can predict unseen samples as well. 
 In scikit-learn, an estimator for classification is a Python object that implements the methods fit(X,y) and
predict(T). 
 An example of an estimator is the class sklearn.svm.SVC that implements support vector classification. The constructor of an estimator takes as arguments the parameters of the model, but for the time being, we will consider the estimator as a black box: 
 
 
 
 
 
 
 
 
 from   sklearn   import   svm              # import support vector machine 
 classifier   =   svm . SVC ( gamma = 0.001 ,   C = 100. ) 

 classifier . fit ( digits . data [: - 3 ],   digits . target [: - 3 ]) 
 
 
 
 
 
 
 
 Output:: 
 
 SVC(C=100.0, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape=None, degree=3, gamma=0.001, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False) 
 
 
 
 
 
 
 
 
 The classifier, which we have created with svm.SVC, is an estimator object. 
In general the scikit-learn API provides estimator objects, which can be any object that can learn from data. Learning can be done by classification, regression or clustering algorithm or a transformer that extracts/filters useful features from raw data. 
 All estimator objects expose a fit method that takes a dataset (usually a 2-d array): 
 
 
 
 
 
 
 
 
 classifier . predict ( digits . data [ - 3 :]) 
 
 
 
 
 
 
 
 Output:: 
 
 array([8, 9, 8]) 
 
 
 
 
 
 
 
 
 
 
 digits . target [ - 3 :] 
 
 
 
 
 
 
 
 Output:: 
 
 array([8, 9, 8]) 
 
 
 
 
 
 
 
 
 
 
 digits . data [ - 3 ] 
 
 
 
 
 
 
 
 Output:: 
 
 array([  0.,   0.,   1.,  11.,  15.,   1.,   0.,   0.,   0.,   0.,  13.,
        16.,   8.,   2.,   1.,   0.,   0.,   0.,  16.,  15.,  10.,  16.,
         5.,   0.,   0.,   0.,   8.,  16.,  16.,   7.,   0.,   0.,   0.,
         0.,   9.,  16.,  16.,   4.,   0.,   0.,   0.,   0.,  16.,  14.,
        16.,  15.,   0.,   0.,   0.,   0.,  15.,  15.,  15.,  16.,   0.,
         0.,   0.,   0.,   2.,   9.,  13.,   6.,   0.,   0.]) 
 
 
 
 
 
 
 
 
 
 
 import   matplotlib.pyplot   as   plt 
 from   PIL   import   Image 
 img   =   Image . fromarray ( np . uint8 ( digits . images [ - 2 ])) 

 plt . gray () 
 plt . imshow ( img ) 
 plt . show () 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 plt . imshow ( digits . images [ - 2 ],   cmap = plt . cm . gray_r ) 
 
 
 
 
 
 
 
 Output:: 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 Iris Dataset The Iris flower data set is a multivariate data set introduced by Ronald Fisher in his 1936 paper ""The use of multiple measurements in taxonomic problems as an example of linear discriminant analysis."" 
 The data set consists of 50 samples from each of three species of Iris 
 
 Iris setosa,  
 Iris virginica and  
 Iris versicolor).  
 
 Four features were measured from each sample the length and the width of the sepals and petals, in centimetres. 
 Based on the combination of these four features, Fisher developed a linear discriminant model to distinguish the species from each other. 
 
 
 
 
 
 
 Saving Trained Models It's possible to keep a trained model persistently with the pickle module. 
 In the following example, we want to demonstrate how to learn a classifier and save it for later usage with the pickle module of Python: 
 
 
 
 
 
 
 
 
 from   sklearn   import   svm ,   datasets 
 import   pickle 

 iris   =   datasets . load_iris () 

 clf   =   svm . SVC () 

 X ,   y   =   iris . data ,   iris . target 
 clf . fit ( X ,   y ) 
 
 
 
 
 
 
 
 Output:: 
 
 SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False) 
 
 
 
 
 
 
 
 
 
 
 fname   =   open ( ""classifiers/iris.pkl"" ,   ""bw"" ) 
 pickle . dump ( clf ,   fname ) 

 # load the saved classifier: 
 fname   =   open ( ""classifiers/iris.pkl"" ,   ""br"" ) 
 clf2   =   pickle . load ( fname ) 
 
 
 
 
 
 
 
 
 
 
 clf2 . predict ( iris . data [:: 5 ]) 
 
 
 
 
 
 
 
 Output:: 
 
 array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2]) 
 
 
 
 
 
 
 
 
 
 
 iris . target [:: 5 ] 
 
 
 
 
 
 
 
 Output:: 
 
 array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2]) 
 
 
 
 
 
 
 
 
 Now, we will do the same with joblib package from sklearn.externals. joblib is more efficient on big data: 
 
 
 
 
 
 
 
 
 from   sklearn.externals   import   joblib 
 joblib . dump ( clf ,   'classifiers/iris2.pkl' ) 

 clf3   =   joblib . load ( 'classifiers/iris2.pkl' ) 

 clf3 . predict ( iris . data [:: 5 ]) 
 
 
 
 
 
 
 
 Output:: 
 
 array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2,
       2, 2, 2, 2, 2, 2, 2]) 
 
 
 
 
 
 
 
 
 Statistical-learning for Scientific Data Processing We saw that the ""iris dataset"" consists of 150 observations of irises, i.e. the samples. Each oberservation is described by four features (the length and the width of the sepals and petals). 
 In general, we can say that Scikit-learn deals with learning information from one or more datasets that are represented as 2D arrays. Such an array can be seen as a list of multi-dimensional observations. The first axis of such an array is the samples axis and the second one is the features axis. 
 Supervised Learning Supervised learning consists in the task of finding or deducing a function from labeled training data. The training data consist of a set of training examples. In other words: We have the actual data X and the corresponding ""targets"" y, also called ""labels"". Often y is a one dimensional array. 
 An estimator in scikit-learn provides a fit method to fit the model: fit(X, y). It also supplies a predict method which returns predicted labels y for (unlabeled) observations X: predict(X) --> y. 
 
 
 
 
 
 
 Instance Based Learning -- -k-nearest-neighbor Instance based learning works directly on the learned samples, instead of creating rules compared to other classification methods. 
 Way of working: Each new instance is compared with the already existing instances. The instances are compared by using a distance metric. The instance with the closest distance value detwermines the class for the new instance. This classification method is called nearest-neighbor classification. 
 
 
 
 
 
 In [ ]: 
 
 
 ### k-nearest-neighbor from Scratch 
 
 
 
 
 
 
 
 In [ ]: 
 
 
 import   numpy   as   np 
 from   sklearn   import   datasets 
 iris   =   datasets . load_iris () 
 iris_X   =   iris . data 
 iris_y   =   iris . target 
 print ( iris_X [: 8 ]) 
 
 
 
 
 
 
 
 
 We create a learnsetfrom the sets above. We use permutation from np.random to split the data randomly: 
 
 
 
 
 
 
 
 
 np . random . seed ( 42 ) 
 indices   =   np . random . permutation ( len ( iris_X )) 
 n_training_samples   =   12 
 iris_X_train   =   iris_X [ indices [: - n_training_samples ]] 
 iris_y_train   =   iris_y [ indices [: - n_training_samples ]] 
 iris_X_test   =   iris_X [ indices [ - n_training_samples :]] 
 iris_y_test   =   iris_y [ indices [ - n_training_samples :]] 
 print ( iris_X_test ) 
 
 
 
 
 
 
 
 
 
 [[ 5.7  2.8  4.1  1.3]
 [ 6.5  3.   5.5  1.8]
 [ 6.3  2.3  4.4  1.3]
 [ 6.4  2.9  4.3  1.3]
 [ 5.6  2.8  4.9  2. ]
 [ 5.9  3.   5.1  1.8]
 [ 5.4  3.4  1.7  0.2]
 [ 6.1  2.8  4.   1.3]
 [ 4.9  2.5  4.5  1.7]
 [ 5.8  4.   1.2  0.2]
 [ 5.8  2.6  4.   1.2]
 [ 7.1  3.   5.9  2.1]]
 
 
 
 
 
 
 
 
 
 To determine the similarity between to instances, we need a distance function. In our example, the Euclidean distance is ideal: 
 
 
 
 
 
 
 
 
 def   distance ( instance1 ,   instance2 ): 
     # just in case, if the instances are lists or tuples: 
     instance1   =   np . array ( instance1 )  
     instance2   =   np . array ( instance2 ) 
    
     return   np . linalg . norm ( instance1   -   instance2 ) 

 print ( distance ([ 4 ,   3 ,   2 ],   [ 1 ,   1 , 1 ])) 
 
 
 
 
 
 
 
 
 
 3.74165738677
 
 
 
 
 
 
 
 
 
 
 
 def   get_neighbors ( training_set ,   test_instance ,   k ): 
     distances   =   [] 
     for   training_instance   in   training_set : 
         dist   =   distance ( test_instance ,   training_instance [: - 1 ]) 
         distances . append (( training_instance ,   dist )) 
     distances . sort ( key = lambda   x :   x [ 1 ]) 
     neighbors   =   [] 
     for   i   in   range ( k ): 
         neighbors . append ( distances [ i ][ 0 ]) 
     return   neighbors 

 train_set   =   [( 1 ,   2 ,   2 ,   'apple' ),  
              ( - 3 ,   - 2 ,   0 ,    'banana' ), 
              ( 1 ,   1 ,   3 ,   'apple' ),  
              ( - 3 ,   - 3 ,   - 1 ,    'banana' ) 
             ] 

 k   =   1 
 for   test_instance   in   [( 0 ,   0 ,   0 ),   ( 2 ,   2 ,   2 ),   ( - 3 ,   - 1 ,   0 )]: 
     neighbors   =   get_neighbors ( train_set ,   test_instance ,   2 ) 
     print ( test_instance ,   neighbors ) 
 
 
 
 
 
 
 
 
 
 (0, 0, 0) [(1, 2, 2, 'apple'), (1, 1, 3, 'apple')]
(2, 2, 2) [(1, 2, 2, 'apple'), (1, 1, 3, 'apple')]
(-3, -1, 0) [(-3, -2, 0, 'banana'), (-3, -3, -1, 'banana')]
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 In [ ]: 
 
 
  
 
 
 
 
 
 Previous Chapter:  Neural Networks with Scikit 
 Next Chapter:  Introduction Naive Bayes Classifier 
 
   © 2011 - 2019, Bernd Klein,
Bodenseo; 
Design by Denise Mitchinson adapted for python-course.eu by Bernd Klein "," None,None,None,None,None,None,None,None,None,None,None,Supervised Learning,None,None,None,None,", https://www.python-course.eu/http://www.python-kurs.eu/stellengesuch/Stellenanzeige.pdf
10,R Algorithms in AI and computing forces working together:...,https://www.hackerearth.com/blog/developers/r-algorithms-in-ai-and-computing-forces-working-together-a-small-industry-insight/,"R Algorithms in AI and computing forces working together: A small industry insight | HackerEarth Blog 
 Hackathons Technical Recruitment For Developers 
 
 
 
 Recruitment Blog Developers Blog Webinars Algorithms Competitive Programming Machine Learning Interview Tips More Categories ≫ 
 Menu 
 
 Toggle navigation 
 
 
 
 Recruitment Blog Developers Blog Webinars 
 
 
 
   
R Algorithms in AI and computing forces working together: A small industry insight 
 Developers 
 Machine Learning 
 R 
 June 25, 2019 
    3   mins When it comes to understanding computing processes, especially in today’s front end and backend development world, most of the times everything revolves heavily around analyzing the algorithmic architecture in tools, applications, or more complex pieces of software. In fact, a thorough analysis of what concerns the algorithmic side of things within the computing processing industry has led to a common conclusion—  algorithmic functions are moving with architectural rendering languages to build much more complex tools.  Let’s analyze some of these.  Algorithmic Retargeting in R and Python  The biggest Python application currently available for the mass market is the one related to front-end tools installed on enterprise sites.  This includes tools related to the web personalization industry, retargeting, remarketing, and Big Data manipulation, which are, in fact, a massive part of this statement.  The way these tools work is by restructuring a catalog onto specific user preferences.  This is done with the combination of Python features and R-rendering algorithms. Python scripts are gathering big data from specific landing pages, which are then stored into a Javascript (generally) container.  After this is done,  R algorithms  are set up to render automatically the data, via (generally) AngularJS-coded scripts. In this particular case, R functions are simply acting as a processing functionality.  Which Rendering Languages are Used The above-mentioned process (gathering via Python, processed in R, and then exported in JS) is pretty common in a variety of architecture and, depending on the usage, the only variable for what concerns which programming languages are used is related to the “export” side of the matter.  To better explain this, let’s analyze the most common programming languages— JavaScript and C#.  JavaScript exports are common within CMS-based tools (the ones, to reference, installed on architecture like WordPress, Magento, Shopify, etc) given the easiness of its application to these very portals.  C#, on the other hand, is used when the tool (or software) is native and, therefore, the rendering langue used to print the pieces of information must be tailored onto the building architecture.  Why is this Considered AI?  Although for many, the matter could sound a bit dark and complicated, the combination of R algorithms to rendering languages (and computing power in general) could be aggregated within the AI sphere.  This is possible because, technically, those features (data gathering, processing, and printing) are related to AI as a whole.  Artificial pieces of intelligence in 2019 have moved, in fact, to this very matter: fast processing, personalization, and projections tailored onto Big Data, automatically gathered without any human input.  Futuristic projections of AI controlling our lives still live in science fiction and sometimes, given how they’re covered in many  technology blogs/newspaper s, these statements are extremely downgrading for an industry that is moving massively for what concerns both development and business awareness.  The Market Value  Pieces of software that are combining R algorithms and rendering languages as well as data automation have been covered by a variety of industry analysts.  These industry analysts have pointed out how they are building a futuristic architecture that is very likely to dominate the way we perceive data processing.  On top of everything that was said above, there is a significant part of the mobile market which is approaching the matter.  As we know, mobile has definitely become quite important, both from a development point of view (with new applications) and a purely business-related one (with many investors and new startups becoming enterprises).  Any  app developers  who have pointed out how algorithmic features within complex builds (especially on iOS) are now being embraced in the UK, which was recently selected as the European technological powerhouse.  We can safely say that this will become the industry standard in the near future.  Take a free tutorial to Python & Machine learning programming for better understanding. Learn Now           About the  Author 
 
 Paul Matthews 
Paul Matthews is a Manchester based business and tech writer who writes in order to better inform business owners on how to run a successful business. You can usually find him at the local library or browsing Forbes' latest pieces. Want to stay ahead of the technology curve? Subscribe to our Developers blog 
 
 
 
 
 
 
 Please leave this field empty. 
 Yes, I would like to receive the latest information on emerging technology trends, as well as relevant marketing communication about hackathons, events and challenges.  By signing up you agree to our  Terms of service  and  Privacy policy . 
     Related Posts 
   
 6 things business owners should do before inter... 
 Developers 
 Startup 
 
November 25, 2019 
   
 8 Steps to acing your next system design interview 
 Developers 
 Interview tips 
 
November 19, 2019 
   
 7 steps to improve your data structure and algo... 
 Algorithms 
 Developer Tips 
 Developers 
 
November 13, 2019 
   
 HackerEarth Community—Get ready for spooktacula... 
 Community 
 Developers 
 
October 30, 2019 
   
 What’s the difference between front-end, ... 
 Developer Tips 
 Developers 
 
October 16, 2019 
   
 How to use mock interviews to streamline your t... 
 Developer Tips 
 Developers 
 
September 27, 2019 
   
 Hackathons simplified 
 Developers 
 Hackathons 
 
September 25, 2019 
   
 Top tips to prepare for software engineering in... 
 Developer Tips 
 Interview tips 
 
September 18, 2019 
   
 Do you really need a degree to build a career i... 
 Developer Tips 
 Interview tips 
 
September 6, 2019 
   
 6 Avenger powers developers need to be ready fo... 
 Community 
 Competitive Programming 
 Developers 
 
May 6, 2019         comments powered by Disqus.           Blog Engineering Blog Updates & Releases Team Careers In the Press 
 
© 2019 HackerEarth Terms & Conditions Privacy "," Algorithmic Retargeting in R and Python ,Which Rendering Languages are Used,Why is this Considered AI? ,The Market Value ,", http://engineering.hackerearth.com/http://news.hackerearth.com/
11,Object detection for self-driving cars,https://www.hackerearth.com/blog/developers/object-detection-for-self-driving-cars/,"Object detection for self-driving cars | Deep Learning | HackerEarth Blog 
 Hackathons Technical Recruitment For Developers 
 
 
 
 Recruitment Blog Developers Blog Webinars Algorithms Competitive Programming Machine Learning Interview Tips More Categories ≫ 
 Menu 
 
 Toggle navigation 
 
 
 
 Recruitment Blog Developers Blog Webinars 
 
 
 
   
Object detection for self-driving cars 
 Artificial Intelligence 
 Cognitive 
 Data Science 
 Developers 
 Machine Learning 
 September 24, 2018 
    14   mins In the previous blog,  Introduction to Object detection , we learned the basics of object detection. We also got an overview of the YOLO (You Look Only Once algorithm). In this blog, we will extend our learning and will dive deeper into the YOLO algorithm. We will learn topics such as intersection over area metrics, non maximal suppression, multiple object detection, anchor boxes, etc. Finally, we will build an object detection detection system for a  self-driving car  using the YOLO algorithm. We will be using the Berkeley driving dataset to train our model. Data Preprocessing Before, we get into building the various components of the object detection model, we will perform some preprocessing steps. The preprocessing steps involve resizing the images (according to the input shape accepted by the model) and converting the box coordinates into the appropriate form. Since we will be building a object detection for a self-driving car, we will be detecting and localizing eight different classes. These classes are ‘bike’, ‘bus’, ‘car’, ‘motor’, ‘person’, ‘rider’, ‘train’, and ‘truck’. Therefore, our target variable will be defined as: where, \begin{equation} 
\hat{y} ={ 
\begin{bmatrix} 
{p_c}& {b_x} & {b_y} & {b_h} & {b_w} & {c_1} & {c_2} & … & {c_8} 
\end{bmatrix}}^T 
\end{equation} p c  : Probability/confidence of an object being present in the bounding box b x , b y  : coordinates of the center of the bounding box  b w  : width of the bounding box w.r.t the image width  b h  : height of the bounding box w.r.t the image height  c i  = Probability of the  i th  class But since the box coordinates provided in the dataset are in the following format: x min , y min , x max , y max  (see Fig 1.), we need to convert them according to the target variable defined above. This can be implemented as follows: W  : width of the original image 
 H  : height of the original image \begin{equation} 
b_x = \frac{(x_{min} + x_{max})}{2 * W}\ , \ b_y = \frac{(y_{min} + y_{max})}{2 * H} \\ 
b_w = \frac{(x_{max} – x_{min})}{2 * W}\ , \ b_y = \frac{(y_{max} + y_{min})}{2 * W} 
\end{equation} Fig 1. Bounding Box Coordinates in the target variable Data Preprocessing Python 
def process_data(images, boxes=None):
    """"""
    Process the data
    """"""
    images = [PIL.Image.fromarray(i) for i in images]
    orig_size = np.array([images[0].width, images[0].height])
    orig_size = np.expand_dims(orig_size, axis=0)
    
    #Image preprocessing 
    processed_images = [i.resize((416, 416), PIL.Image.BICUBIC) for i in images]
    processed_images = [np.array(image, dtype=np.float) for image in processed_images]
    processed_images = [image/255. for image in processed_images]
    
    if boxes is not None:
        # Box preprocessing
        # Original boxes stored as as 1D list of class, x_min, y_min, x_max, y_max
        boxes = [box.reshape((-1, 5)) for box in boxes]
        # Get extents as y_min, x_min, y_max, x_max, class for comparison with 
        # model output
        box_extents = [box[:, [2,1,4,3,0]] for box in boxes]
        
        # Get box parameters as x_center, y_center, box_width, box_height, class.
        boxes_xy = [0.5* (box[:, 3:5] + box[:, 1:3]) for box in boxes]
        boxes_wh = [box[:, 3:5] - box[:, 1:3] for box in boxes]
        boxes_xy = [box_xy / orig_size for box_xy in boxes_xy]
        boxes_wh = [box_wh / orig_size for box_wh in boxes_wh]
        boxes = [np.concatenate((boxes_xy[i], boxes_wh[i], box[:, 0:1]), axis=-1) for i, box in enumerate(boxes)]
        
        # find the max number of boxes 
        max_boxes = 0
        for boxz in boxes:
            if boxz.shape[0] > max_boxes:
                max_boxes = boxz.shape[0]
        # add zero pad for training 
        for i, boxz in enumerate(boxes):
            if boxz.shape[0]    max_boxes :                  max_boxes   =   boxz . shape [ 0 ]          # add zero pad for training           for   i ,   boxz  in   enumerate ( boxes ) :              if   boxz . shape [ 0 ]    Center of the box 
           h, w -> Height and width of the box w.r.t the image size
    box_class_probs: Probability of all the classes for each box
    threshold: Threshold value for box confidence
    
    Returns: 
    scores: containing the class probability score for the selected boxes
    boxes: contains box coordinates for the selected boxes
    classes: contains the index of the class detected by the selected boxes
    """"""
    
    # Compute the box scores: 
    box_scores = box_confidence * box_class_probs
    
    # Find the box classes index with the maximum box score
    box_classes = K.argmax(box_scores)
    # Find the box classes with maximum box score
    box_class_scores = K.max(box_scores, axis=-1)
    
    # Creating a mask for selecting the boxes that have box score greater than threshold
    thresh_mask = box_class_scores >= threshold
    # Selecting the scores, boxes and classes with box score greater than 
    # threshold by filtering the box score with the help of thresh_mask.
    scores = tf.boolean_mask(tensor=box_class_scores, mask=thresh_mask)
    classes = tf.boolean_mask(tensor=box_classes, mask=thresh_mask)
    boxes = tf.boolean_mask(tensor=boxes, mask=thresh_mask)
    
    return scores, classes, boxes 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 def   yolo_filter_boxes ( box_confidence ,   boxes ,   box_class_probs ,   threshold = 0.6 ) :      """"""     Filters YOLO boxes by thresholding on object and class confidence     Arguments:      box_confidence: Probability of the box containing the object     boxes: The box parameters : (x, y, h, w)             x, y -> Center of the box             h, w -> Height and width of the box w.r.t the image size     box_class_probs: Probability of all the classes for each box     threshold: Threshold value for box confidence          Returns:      scores: containing the class probability score for the selected boxes     boxes: contains box coordinates for the selected boxes     classes: contains the index of the class detected by the selected boxes     """"""           # Compute the box scores:       box_scores   =   box_confidence   *   box_class_probs           # Find the box classes index with the maximum box score      box_classes   =   K . argmax ( box_scores )      # Find the box classes with maximum box score      box_class_scores   =   K . max ( box_scores ,   axis = - 1 )           # Creating a mask for selecting the boxes that have box score greater than threshold      thresh_mask   =   box_class_scores   >=   threshold      # Selecting the scores, boxes and classes with box score greater than       # threshold by filtering the box score with the help of thresh_mask.      scores   =   tf . boolean_mask ( tensor = box_class_scores ,   mask = thresh_mask )      classes   =   tf . boolean_mask ( tensor = box_classes ,   mask = thresh_mask )      boxes   =   tf . boolean_mask ( tensor = boxes ,   mask = thresh_mask )           return   scores ,   classes ,   boxes Non-max Suppression Even after filtering by thresholding over the classes score, we may still end up with a lot of overlapping bounding boxes. This is because the YOLO algorithm may detect an object multiple times, which is one of its drawbacks. A second filter called non-maximal suppression (NMS) is used to remove duplicate detections of an object. Non-max suppression uses ‘Intersection over Union’ (IoU) to fix multiple detections. Non-maximal suppression is implemented as follows: Find the box confidence ( p c ) (Probability of the box containing the object) for each detection. Pick the bounding box with the maximum box confidence. Output this box as prediction. Discard any remaining bounding boxes which have an IoU greater than 0.5 with the bounding box selected as output in the previous step i.e. any bounding box with high overlap is discarded. In case there are multiple classes/ objects, i.e., if there are four objects/classes, then non-max suppression will run four times, once for every output class. Anchor boxes One of the drawbacks of YOLO algorithm is that each grid can only detect one object. What if we want to detect multiple distinct objects in each grid. For example, if two objects or classes are overlapping and share the same grid as shown in the image (see Fig 4.), Fig 4. Two Overlapping bounding boxes with two overlapping classes. We make use of  anchor boxes  to tackle the issue. Let’s assume the predicted variable is defined as \begin{equation} 
\hat{y} ={ 
\begin{bmatrix} 
{p_c}& {b_x} & {b_y} & {b_h} & {b_w} & {c_1} & {c_2} & {…} & {c_8} 
\end{bmatrix}}^T 
\end{equation} then, we can use two  anchor boxes  in the following manner to detect two objects in the image simultaneously. Fig 5. Target variable with two bounding boxes Earlier, the target variable was defined such that each object in the training image is assigned to grid cell that contains that object’s midpoint. Now, with two anchor boxes, each object in the training images is assigned to a grid cell that contains the object’s midpoint and anchor box for the grid cell with the highest IOU. So, with the help of two anchor boxes, we can detect at most two objects simultaneously in an image. Fig 6. shows the shape of the final output layer with and without the use of anchor boxes. Fig 6. Shape of the output layer with two anchor boxes Although, we can detect multiple images using Anchor boxes, but they still have limitations. For example, if there are two anchor boxes defined in the target variable and the image has three overlapping objects, then the algorithm fails to detect all three objects. Secondly, if two anchor boxes are associated with two objects but have the same midpoint in the box coordinates, then the algorithm fails to differentiate between the objects. Now, that we know the basics of anchor boxes, let’s code it. In the following code we will use 10 anchor boxes. As a result, the algorithm can detect at maximum of 10 objects in a given image. Non Max Suppression Python 
def non_max_suppression(scores, classes, boxes, max_boxes=10, iou_threshold = 0.5):
    """"""
    Non-maximal suppression is used to fix the multiple detections of the same object.
    - Find the box_confidence (Probability of the box containing the object) for each detection.
    - Find the bounding box with the highest box_confidence
    - Suppress all the bounding boxes which have an IoU greater than 0.5 with the bounding box with the maximum box confidence.
    
    scores    -> containing the class probability score for the selected boxes.
    boxes     -> contains box coordinates for the boxes selected after threshold masking.
    classes   -> contains the index of the classes detected by the selected boxes.
    max_boxes -> maximum number of predicted boxes to be returned after NMS filtering.
    
    Returns: 
    scores  -> predicted score for each box.
    classes -> predicted class for each box.
    boxes   -> predicted box coordinates.
    """"""
    
    # Converting max_boxes to tensor 
    max_boxes_tensor = K.variable(max_boxes, dtype='int32')
    # Initialize the max_boxes_tensor
    K.get_session().run(tf.variables_initializer([max_boxes_tensor]))
    
    # Implement non-max suppression using tf.image.non_max_suppression()
    # tf.image.non_max_suppression() ->  Returns the indices corresponding to the boxes you want to keep
    
    indices = tf.image.non_max_suppression(boxes=boxes, scores=scores, max_output_size=max_boxes_tensor, iou_threshold=iou_threshold)
    
    # K.gather() is used to select only indices present in 'indices' variable from scores, boxes and classe
    
    scores = tf.gather(scores, indices)
    classes = tf.gather(classes, indices)
    boxes = tf.gather(boxes, indices)
    
    return scores, classes , boxes  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 def   non_max_suppression ( scores ,   classes ,   boxes ,   max_boxes = 10 ,   iou_threshold   =   0.5 ) :      """"""     Non-maximal suppression is used to fix the multiple detections of the same object.     - Find the box_confidence (Probability of the box containing the object) for each detection.     - Find the bounding box with the highest box_confidence     - Suppress all the bounding boxes which have an IoU greater than 0.5 with the bounding box with the maximum box confidence.          scores    -> containing the class probability score for the selected boxes.     boxes     -> contains box coordinates for the boxes selected after threshold masking.     classes   -> contains the index of the classes detected by the selected boxes.     max_boxes -> maximum number of predicted boxes to be returned after NMS filtering.          Returns:      scores  -> predicted score for each box.     classes -> predicted class for each box.     boxes   -> predicted box coordinates.     """"""           # Converting max_boxes to tensor       max_boxes_tensor   =   K . variable ( max_boxes ,   dtype = 'int32' )      # Initialize the max_boxes_tensor      K . get_session ( ) . run ( tf . variables_initializer ( [ max_boxes_tensor ] ) )           # Implement non-max suppression using tf.image.non_max_suppression()      # tf.image.non_max_suppression() ->  Returns the indices corresponding to the boxes you want to keep           indices   =   tf . image . non_max_suppression ( boxes = boxes ,   scores = scores ,   max_output_size = max_boxes_tensor ,   iou_threshold = iou_threshold )           # K.gather() is used to select only indices present in 'indices' variable from scores, boxes and classe           scores   =   tf . gather ( scores ,   indices )      classes   =   tf . gather ( classes ,   indices )      boxes   =   tf . gather ( boxes ,   indices )           return   scores ,   classes   ,   boxes   We can combine both the concepts threshold filtering and non-maximal suppression and apply it on the output predicted by the YOLO model. This is implemented in the code below. Process Output Python 
def yolo_eval(yolo_outputs, image_shape = (720., 1280.), max_boxes = 10, score_threshold = 0.6, iou_threshold = 0.5):
    """"""
    The function takes the output of the YOLO encoding/ model and filters the boxes using 
    score threshold and non-maximal suppression. Returns the predicted boxes along with their scores,
    box coordinates and classes.
    
    Arguments: 
    yolo_outputs    -> Output of the encoding model. 
    image_shape     -> Input shape 
    max_boxes       -> Maximum number of predicted boxes to be returned after NMS filtering.
    score_threshold -> Threshold value for box class score, if the maximum class probability score  'Intersection over Union' threshold used for NMS filtering
    
    Returns: 
    scores  -> predicted score for each box.
    classes -> predicted class for each box.
    boxes   -> predicted box coordinates.
    """"""
    
    box_xy, box_wh, box_confidence, box_class_probs = yolo_outputs
    
    # Convert boxes to be ready for filtering functions
    boxes = yolo_boxes_to_corners(box_xy, box_wh)
    
    scores, classes, boxes = yolo_filter_boxes(box_confidence, boxes, box_class_probs, score_threshold)
    
    # Scale boxes back to original image shape.
    boxes = scale_boxes(boxes, image_shape)
    
    # Perform non-max suppression
    scores, classes , boxes = non_max_suppression(scores, classes, boxes, max_boxes, iou_threshold)
    
    return scores, boxes, classes 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 def   yolo_eval ( yolo_outputs ,   image_shape   =   ( 720. ,   1280. ) ,   max_boxes   =   10 ,   score_threshold   =   0.6 ,   iou_threshold   =   0.5 ) :      """"""     The function takes the output of the YOLO encoding/ model and filters the boxes using      score threshold and non-maximal suppression. Returns the predicted boxes along with their scores,     box coordinates and classes.          Arguments:      yolo_outputs    -> Output of the encoding model.      image_shape     -> Input shape      max_boxes       -> Maximum number of predicted boxes to be returned after NMS filtering.     score_threshold -> Threshold value for box class score, if the maximum class probability score  'Intersection over Union' threshold used for NMS filtering          Returns:      scores  -> predicted score for each box.     classes -> predicted class for each box.     boxes   -> predicted box coordinates.     """"""           box_xy ,   box_wh ,   box_confidence ,   box_class_probs   =   yolo_outputs           # Convert boxes to be ready for filtering functions      boxes   =   yolo_boxes_to_corners ( box_xy ,   box_wh )           scores ,   classes ,   boxes   =   yolo_filter_boxes ( box_confidence ,   boxes ,   box_class_probs ,   score_threshold )           # Scale boxes back to original image shape.      boxes   =   scale_boxes ( boxes ,   image_shape )           # Perform non-max suppression      scores ,   classes   ,   boxes   =   non_max_suppression ( scores ,   classes ,   boxes ,   max_boxes ,   iou_threshold )           return   scores ,   boxes ,   classes Object Detection on Sample Test Image We will use the trained model to predict the respective classes and the corresponding bounding boxes on a sample of images. The function ‘draw’ runs a tensorflow session and calculates the confidence scores, bounding box coordinates and the output class probabilities for the given sample image. Finally, it computes the x min , x max , y min , y max  from b x ,b y ,b w ,b h , scales the bounding boxes according to the input sample image and draws the bounding boxes and class probability for the objects in the input sample image. Drawing the bounding boxes Python 
# Loading the path of the test image data
test = glob('data/test/*.jpg')
# Reading and storing the test image data
test_data = []
for i in test:
    test_data.append(plt.imread(i))
# Processing the test image data 
test_data = process_data(test_data)

# Predicting the scores, boxes, classes for the given input image
scores, boxes, classes, model_body, input_image_shape = load_yolo(model_body, class_names, anchors)
# Drawing the bounding boxes
draw(model_body, scores, boxes, classes,input_image_shape, test_data, image_set='all', out_path='data/test/output/',save_all=False) 1 2 3 4 5 6 7 8 9 10 11 12 13 # Loading the path of the test image data test   =   glob ( 'data/test/*.jpg' ) # Reading and storing the test image data test_data   =   [ ] for   i   in   test :      test_data . append ( plt . imread ( i ) ) # Processing the test image data  test_data   =   process_data ( test_data )   # Predicting the scores, boxes, classes for the given input image scores ,   boxes ,   classes ,   model_body ,   input_image_shape   =   load_yolo ( model_body ,   class_names ,   anchors ) # Drawing the bounding boxes draw ( model_body ,   scores ,   boxes ,   classes , input_image_shape ,   test_data ,   image_set = 'all' ,   out_path = 'data/test/output/' , save_all = False ) Fig. 7, shows the class probabilities and bounding boxes on the test images.  Fig 7. Sample images with the predicted classes and bounding boxes Implementing the Model on Real Time Video Next, we will implement the model on a real time video. Since, video is a sequence of images at different time frames, so we will predict the class probabilities and bounding boxes for the image captured at each time frame. We will use OpenCV video capture function to read the video and convert it into image/ frames at different time steps. The video below demonstrates the implementation of the algorithm on a real time video. Using OpenCV to capture video Python 
#Path of the stored video file
videopath = 'data/real_time/bdd-videos-sample.mp4'

# Loads the saved trained YOLO model
scores, boxes, classes, model_body, input_image_shape = load_yolo(model_body, class_names, anchors)

# Catures and splits the video into images at different time frames 
vc = cv2.VideoCapture(videopath) 1 2 3 4 5 6 7 8 #Path of the stored video file videopath   =   'data/real_time/bdd-videos-sample.mp4'   # Loads the saved trained YOLO model scores ,   boxes ,   classes ,   model_body ,   input_image_shape   =   load_yolo ( model_body ,   class_names ,   anchors )   # Catures and splits the video into images at different time frames  vc   =   cv2 . VideoCapture ( videopath ) Detecting objects on Real time video Python 
while(True):
    # Load the image at each time frame
    check, frame = vc.read()
    # Preprocess the input image frame
    frame = process_data(np.expand_dims(frame, axis=0))
    # Predict and draw the class probabilities and bounding boxes for the given frame
    img_data = draw(model_body, scores, boxes, classes, input_image_shape, frame, image_set='real', save_all=False, real_time=True)
    img_data = np.array(img_data)
    # Display the image/ frame with the predicted class probability and bounding boxes back on the screen.
    cv2.imshow('Capture:', img_data)
    key = cv2.waitKey(1)
    if key == ord('q'):
        break
vc.release()
cv2.destroyAllWindows()  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 while ( True ) :      # Load the image at each time frame      check ,   frame   =   vc . read ( )      # Preprocess the input image frame      frame   =   process_data ( np . expand_dims ( frame ,   axis = 0 ) )      # Predict and draw the class probabilities and bounding boxes for the given frame      img_data   =   draw ( model_body ,   scores ,   boxes ,   classes ,   input_image_shape ,   frame ,   image_set = 'real' ,   save_all = False ,   real_time = True )      img_data   =   np . array ( img_data )      # Display the image/ frame with the predicted class probability and bounding boxes back on the screen.      cv2 . imshow ( 'Capture:' ,   img_data )      key   =   cv2 . waitKey ( 1 )      if   key   ==   ord ( 'q' ) :          break vc . release ( ) cv2 . destroyAllWindows ( )   [Source Code] Conclusion This brings us to the end of this article. Congratulate yourself on reaching to the end of this blog. As a reward you now have a better understanding of how object detection works (using the YOLO algorithm) and how self driving cars implement this technique to differentiate between cars, trucks, pedestrians, etc. to make better decisions. Finally, I encourage you to implement and play with the code yourself. You can find the full source code related to this article  here . Have anything to say? Feel free to comment below for any questions, suggestions, and discussions related to this article. Till then, keep hacking with  HackerEarth . Struggling to compose your own music, check out this blog on how to  Compose Jazz Music with Deep Learning . References DarkNet (YOLOv2)  https://pjreddie.com/darknet/yolov2/ You Only Look Once: Unified, Real-Time Object Detection – Joseph Redmon, Santosh Divvala, Ross Girshick, Ali Farhadi.  arXiv:1612.08242  [cs.CV] YAD2K: Yet Another Darknet 2 Keras – Allan Zelener :  https://github.com/allanzelener/YAD2K Berkley Deep Driving Dataset :  http://bdd-data.berkeley.edu/   124 Shares 124       About the  Author 
 
 Shubham Gupta 
 
 
 
 
 
 
Trying to solve problems through machine learning and help others evolve in the field of machine learning. Currently working as a Data Science Intern at HackerEarth. Highly enthusiastic about autonomous driven systems. Want to stay ahead of the technology curve? Subscribe to our Developers blog 
 
 
 
 
 
 
 Please leave this field empty. 
 Yes, I would like to receive the latest information on emerging technology trends, as well as relevant marketing communication about hackathons, events and challenges.  By signing up you agree to our  Terms of service  and  Privacy policy . 
     Related Posts 
   
 6 things business owners should do before inter... 
 Developers 
 Startup 
 
November 25, 2019 
   
 8 Steps to acing your next system design interview 
 Developers 
 Interview tips 
 
November 19, 2019 
   
 7 steps to improve your data structure and algo... 
 Algorithms 
 Developer Tips 
 Developers 
 
November 13, 2019 
   
 HackerEarth Community—Get ready for spooktacula... 
 Community 
 Developers 
 
October 30, 2019 
   
 What’s the difference between front-end, ... 
 Developer Tips 
 Developers 
 
October 16, 2019 
   
 How to use mock interviews to streamline your t... 
 Developer Tips 
 Developers 
 
September 27, 2019 
   
 Hackathons simplified 
 Developers 
 Hackathons 
 
September 25, 2019 
   
 Top tips to prepare for software engineering in... 
 Developer Tips 
 Interview tips 
 
September 18, 2019 
   
 Do you really need a degree to build a career i... 
 Developer Tips 
 Interview tips 
 
September 6, 2019 
   
 R Algorithms in AI and computing forces working... 
 Developers 
 Machine Learning 
 R 
 
June 25, 2019         comments powered by Disqus.           Blog Engineering Blog Updates & Releases Team Careers In the Press 
 
© 2019 HackerEarth Terms & Conditions Privacy "," Data Preprocessing,None,Intersection Over Union,Defining the Model,None,Object Detection on Sample Test Image,Implementing the Model on Real Time Video,Conclusion,", http://bdd-data.berkeley.edu/http://engineering.hackerearth.com/http://news.hackerearth.com/
12,Introduction to Object Detection,https://www.hackerearth.com/blog/developers/introduction-to-object-detection/,"Introduction to Object Detection | Machine Learning | HackerEarth Blog 
 Hackathons Technical Recruitment For Developers 
 
 
 
 Recruitment Blog Developers Blog Webinars Algorithms Competitive Programming Machine Learning Interview Tips More Categories ≫ 
 Menu 
 
 Toggle navigation 
 
 
 
 Recruitment Blog Developers Blog Webinars 
 
 
 
   
Introduction to Object Detection 
 Artificial Intelligence 
 Cognitive 
 Developers 
 Machine Learning 
 Python 
 August 7, 2018 
    7   mins Humans can easily detect and identify objects present in an image. The human visual system is fast and accurate and can perform complex tasks like identifying multiple objects and detect obstacles with little conscious thought. With the availability of large amounts of data, faster GPUs, and better algorithms, we can now easily train computers to detect and classify multiple objects within an image with high accuracy. In this blog, we will explore terms such as object detection, object localization, loss function for object detection and localization, and finally explore an object detection algorithm known as “You only look once” (YOLO).  Object Localization An image classification or image recognition model simply detect the probability of an object in an image. In contrast to this, object localization refers to identifying the location of an object in the image. An object localization algorithm will output the coordinates of the location of an object with respect to the image. In computer vision, the most popular way to localize an object in an image is to represent its location with the help of bounding boxes. Fig. 1 shows an example of a bounding box. Fig 1. Bounding box representation used for object localization A bounding box can be initialized using the following parameters: bx, by : coordinates of the center of the bounding box bw : width of the bounding box w.r.t the image width bh : height of the bounding box w.r.t the image height Defining the target variable The target variable for a multi-class image classification problem is defined as: \(\hat{y} = {c_i}\) where, 
$#\smash{c_i}$# = Probability of the $#i_{th}$# class. 
For example, if there are four classes, the target variable is defined as \begin{equation} 
y = 
\begin{bmatrix} 
{c_1} & \\ 
{c_2} & \\ 
{c_3} & \\ 
{c_4} 
\end{bmatrix} 
\end{equation} 
We can extend this approach to define the target variable for object localization. The target variable is defined as 
\begin{equation} 
y = 
\begin{bmatrix} 
{p_c} & \\ 
{b_x} & \\ 
{b_y} & \\ 
{b_h} & \\ 
{b_w} & \\ 
{c_1} & \\ 
{c_2} & \\ 
{c_3} & \\ 
{c_4} 
\end{bmatrix} 
\end{equation} 
where, 
$#\smash{p_c}$# = Probability/confidence of an object (i.e the four classes) being present in the bounding box. 
$#\smash{b_x, b_y, b_h, b_w}$# = Bounding box coordinates. 
$#\smash{c_i}$# = Probability of the $#\smash{i_{th}}$# class the object belongs to. For example, the four classes be ‘truck’, ‘car’, ‘bike’, ‘pedestrian’ and their probabilities are represented as  $#c_1, c_2, c_3, c_4$#.  So, \begin{equation} 
p_c = 
\begin{cases} 
1,\ \ c_i: \{c_1, c_2, c_3, c_4\} && \\ 
0,\ \ otherwise 
\end{cases} 
\end{equation} Loss Function Let the values of the target variable $#y$# are represented as $#y_1$#, $#y_2$#, $#…,\ y_9$#. \begin{equation} 
y ={ 
\begin{bmatrix} 
{p_c}& {b_x} & {b_y} & {b_h} & {b_w} & {c_1} & {c_2} & {c_3} & {c_4} 
\end{bmatrix}}^T \\ 
\begin{matrix} 
& {y_1}& {y_2} & {y_3} & {y_4} & {y_5} & {y_6} & {y_7} & {y_8} & {y_9} 
\end{matrix} 
\end{equation} The loss function for object localization will be defined as \begin{equation} 
\mathcal{L(\hat{y}, y)} = 
\begin{cases} 
(\hat{y_1} – y_1)^2 + (\hat{y_8} – y_8)^2 + … + (\hat{y_9} – y_9)^2 &&, y_1=1 \\ 
(\hat{y_1} – y_1)^2 &&, y_1=0 
\end{cases} 
\end{equation} In practice, we can use a log function considering the softmax output in case of the predicted classes ($#c_1, c_2, c_3, c_4$#). While for the bounding box coordinates, we can use something like a squared error and for $#p_c$# (confidence of object) we can use logistic regression loss. Since we have defined both the target variable and the loss function, we can now use neural networks to both classify and localize objects. Object Detection An approach to building an object detection is to first build a classifier that can classify closely cropped images of an object. Fig 2. shows an example of such a model, where a model is trained on a dataset of closely cropped images of a car and the model predicts the probability of an image being a car. Fig 2. Image classification of cars Now, we can use this model to detect cars using a  sliding window mechanism . In a sliding window mechanism, we use a sliding window (similar to the one used in convolutional networks) and crop a part of the image in each slide. The size of the crop is the same as the size of the sliding window. Each cropped image is then passed to a ConvNet model (similar to the one shown in Fig 2.), which in turn predicts the probability of the cropped image is a car. Fig 3. Sliding windows mechanism After running the sliding window through the whole image, we resize the sliding window and run it again over the image again. We repeat this process multiple times. Since we crop through a number of images and pass it through the ConvNet, this approach is both computationally expensive and time-consuming, making the whole process really slow. Convolutional implementation of the sliding window helps resolve this problem. Convolutional implementation of sliding windows Before we discuss the implementation of the sliding window using convents, let’s analyze how we can convert the fully connected layers of the network into convolutional layers. Fig. 4 shows a simple convolutional network with two fully connected layers each of shape (400, ). Fig 4. Sliding windows mechanism A fully connected layer can be converted to a convolutional layer with the help of a  1D convolutional layer . The width and height of this layer are equal to one and the number of filters are equal to the shape of the fully connected layer. An example of this is shown in Fig 5. Fig 5. Converting a fully connected layer into a convolutional layer We can apply this concept of conversion of a fully connected layer into a convolutional layer to the model by replacing the fully connected layer with a 1-D convolutional layer. The number of the filters of the 1D convolutional layer is equal to the shape of the fully connected layer. This representation is shown in Fig 6. Also, the output softmax layer is also a convolutional layer of shape (1, 1, 4), where 4 is the number of classes to predict . Fig 6. Convolutional representation of fully connected layers. Now, let’s extend the above approach to implement a convolutional version of sliding window. First, let’s consider the ConvNet that we have trained to be in the following representation (no fully connected layers). Let’s assume the size of the input image to be  16 × 16 × 3 . If we’re to use a sliding window approach, then we would have passed this image to the above ConvNet four times, where each time the sliding window crops a part of the input image of size  14 × 14 × 3  and pass it through the ConvNet. But instead of this, we feed the full image (with shape  16 × 16 × 3 ) directly into the trained ConvNet (see Fig. 7). This results in an output matrix of shape  2 × 2 × 4 . Each cell in the output matrix represents the result of a possible crop and the classified value of the cropped image. For example, the left cell of the output (the green one) in Fig. 7 represents the result of the first sliding window. The other cells represent the results of the remaining sliding window operations. Fig 7. Convolutional implementation of the sliding window Note that the stride of the sliding window is decided by the number of filters used in the Max Pool layer. In the example above, the Max Pool layer has two filters, and as a result, the sliding window moves with a stride of two resulting in four possible outputs. The main advantage of using this technique is that the sliding window runs and computes all values simultaneously. Consequently, this technique is really fast. Although a  weakness  of this technique is that the position of the bounding boxes is not very accurate. The YOLO (You Only Look Once) Algorithm A better algorithm that tackles the issue of predicting accurate bounding boxes while using the convolutional sliding window technique is the  YOLO algorithm . YOLO stands for  you only look once  and was developed in 2015 by Joseph Redmon, Santosh Divvala, Ross Girshick, and Ali Farhadi. It’s popular because it achieves high accuracy while running in real time. This algorithm is called so because it requires only  one forward propagation pass  through the network to make the predictions. The algorithm divides the image into grids and runs the image classification and localization algorithm (discussed under object localization) on each of the grid cells. For example, we have an input image of size  256 × 256 . We place a  3 × 3  grid on the image (see Fig. 8). Fig. 8 Grid (3 x 3) representation of the image Next, we apply the image classification and localization algorithm on each grid cell. For each grid cell, the target variable is defined as \begin{equation} 
y_{i, j} ={ 
\begin{bmatrix} 
{p_c}& {b_x} & {b_y} & {b_h} & {b_w} & {c_1} & {c_2} & {c_3} & {c_4} 
\end{bmatrix}}^T 
\end{equation} Do everything once with the convolution sliding window. Since the shape of the target variable for each grid cell is  1 × 9  and there are 9 ( 3 × 3 ) grid cells, the final output of the model will be: The advantages of the YOLO algorithm is that it is very fast and predicts much more accurate bounding boxes. Also, in practice to get more accurate predictions, we use a much finer grid, say  19 × 19 , in which case the target output is of the shape  19 × 19 × 9 . Conclusion With this, we come to the end of the introduction to object detection. We now have a better understanding of how we can localize objects while classifying them in an image. We also learned to combine the concept of classification and localization with the convolutional implementation of the sliding window to build an object detection system. In the next blog, we will go deeper into the YOLO algorithm, loss function used, and implement some ideas that make the YOLO algorithm better. Also, we will learn to implement the YOLO algorithm in real time. Have anything to say? Feel free to comment below for any questions, suggestions, and discussions related to this article. Till then, keep hacking with  HackerEarth .   120 Shares 120       About the  Author 
 
 Shubham Gupta 
 
 
 
 
 
 
Trying to solve problems through machine learning and help others evolve in the field of machine learning. Currently working as a Data Science Intern at HackerEarth. Highly enthusiastic about autonomous driven systems. Want to stay ahead of the technology curve? Subscribe to our Developers blog 
 
 
 
 
 
 
 Please leave this field empty. 
 Yes, I would like to receive the latest information on emerging technology trends, as well as relevant marketing communication about hackathons, events and challenges.  By signing up you agree to our  Terms of service  and  Privacy policy . 
     Related Posts 
   
 6 things business owners should do before inter... 
 Developers 
 Startup 
 
November 25, 2019 
   
 8 Steps to acing your next system design interview 
 Developers 
 Interview tips 
 
November 19, 2019 
   
 7 steps to improve your data structure and algo... 
 Algorithms 
 Developer Tips 
 Developers 
 
November 13, 2019 
   
 HackerEarth Community—Get ready for spooktacula... 
 Community 
 Developers 
 
October 30, 2019 
   
 What’s the difference between front-end, ... 
 Developer Tips 
 Developers 
 
October 16, 2019 
   
 How to use mock interviews to streamline your t... 
 Developer Tips 
 Developers 
 
September 27, 2019 
   
 Hackathons simplified 
 Developers 
 Hackathons 
 
September 25, 2019 
   
 Top tips to prepare for software engineering in... 
 Developer Tips 
 Interview tips 
 
September 18, 2019 
   
 Do you really need a degree to build a career i... 
 Developer Tips 
 Interview tips 
 
September 6, 2019 
   
 R Algorithms in AI and computing forces working... 
 Developers 
 Machine Learning 
 R 
 
June 25, 2019         comments powered by Disqus.           Blog Engineering Blog Updates & Releases Team Careers In the Press 
 
© 2019 HackerEarth Terms & Conditions Privacy "," None,None,None,None,", http://engineering.hackerearth.com/http://news.hackerearth.com/
13,Data Visualization for Beginners-Part 3,https://www.hackerearth.com/blog/developers/data-visualization-for-beginners-part-3/,"Data Visualization for Beginners-Part 3 | HackerEarth Blog 
 Hackathons Technical Recruitment For Developers 
 
 
 
 Recruitment Blog Developers Blog Webinars Algorithms Competitive Programming Machine Learning Interview Tips More Categories ≫ 
 Menu 
 
 Toggle navigation 
 
 
 
 Recruitment Blog Developers Blog Webinars 
 
 
 
   
Data Visualization for Beginners-Part 3 
 Big Data 
 Data Science 
 Developers 
 Machine Learning 
 Python 
 July 9, 2018 
    8   mins B onjour! Welcome to another part of the series on data visualization techniques. In the previous two articles, we discussed different data visualization techniques that can be applied to visualize and gather insights from categorical and continuous variables. You can check out the first two articles here: Data visualization for beginners – Part 1 Data visualization for beginners – Part 2 In this article, we’ll go through the implementation and use of a bunch of data visualization techniques such as heat maps, surface plots, correlation plots, etc. We will also look at different techniques that can be used to visualize unstructured data such as images, text, etc. 
 ### Importing the required libraries   
 import pandas as pd   
 import numpy as np  
 import seaborn as sns   
 import matplotlib.pyplot as plt   
 import plotly.plotly as py  
 import plotly.graph_objs as go  
 %matplotlib inline   1 2 3 4 5 6 7 8   ### Importing the required libraries      import  pandas  as   pd      import  numpy  as   np     import  seaborn  as   sns      import  matplotlib . pyplot  as   plt      import  plotly . plotly  as   py     import  plotly . graph_objs  as   go      % matplotlib  inline    Heatmaps A  heat map (or  heatmap ) is a two-dimensional graphical representation of the data which uses colour to represent data points on the graph. It is useful in understanding underlying relationships between data values that would be much harder to understand if presented numerically in a table/ matrix. 
### We can create a heatmap by simply using the seaborn library.   
 sample_data = np.random.rand(8, 12)  
 ax = sns.heatmap(sample_data)   1 2 3 ### We can create a heatmap by simply using the seaborn library.      sample_data   =   np . random . rand ( 8 ,   12 )      ax   =   sns . heatmap ( sample_data )    Fig 1. Heatmap using the seaborn library Let’s understand this using an example. We’ll be using the metadata from Deep Learning 3 challenge .  Link  to the dataset.  Deep Learning 3 challenged the participants to predict the attributes of animals by looking at their images. 
 ### Training metadata contains the name of the image and the corresponding attributes associated with the animal in the image.  
 train = pd.read_csv('meta-data/train.csv')  
 train.head()  
 1 2 3 4   ### Training metadata contains the name of the image and the corresponding attributes associated with the animal in the image.     train   =   pd . read_csv ( 'meta-data/train.csv' )      train . head ( )      We will be analyzing how often an attribute occurs in relationship with the other attributes. To analyze this relationship, we will compute the co-occurrence matrix. 
 ### Extracting the attributes  
 cols = list(train.columns)  
 cols.remove('Image_name')  
 attributes = np.array(train[cols])  
 print('There are {} attributes associated with {} images.'.format(attributes.shape[1],attributes.shape[0]))  
 1 2 3 4 5 6   ### Extracting the attributes     cols   =   list ( train . columns )      cols . remove ( 'Image_name' )      attributes   =   np . array ( train [ cols ] )      print ( 'There are {} attributes associated with {} images.' . format ( attributes . shape [ 1 ] , attributes . shape [ 0 ] ) )      
 Out: There are 85 attributes associated with 12,600 images.  
 1 2   Out :   There  are   85   attributes  associated  with   12 , 600   images .      
 # Compute the co-occurrence matrix  
 cooccurrence_matrix = np.dot(attributes.transpose(), attributes)  
 print('\n Co-occurrence matrix: \n', cooccurrence_matrix)  
 Out: Co-occurrence matrix:   
  [[5091 728 797 ... 3797 728 2024]  
  [ 728 1614  0 ... 669 1614 1003]  
  [ 797  0 1188 ... 1188  0 359]  
  ...  
  [3797 669 1188 ... 8305 743 3629]  
  [ 728 1614  0 ... 743 1933 1322]  
  [2024 1003 359 ... 3629 1322 6227]]  
 1 2 3 4 5 6 7 8 9 10 11 12   # Compute the co-occurrence matrix     cooccurrence_matrix   =   np . dot ( attributes . transpose ( ) ,   attributes )      print ( '\n Co-occurrence matrix: \n' ,   cooccurrence_matrix )      Out :   Co - occurrence  matrix :        [ [ 5091   728   797   . . .   3797   728   2024 ]       [   728   1614    0   . . .   669   1614   1003 ]       [   797    0   1188   . . .   1188    0   359 ]       . . .       [ 3797   669   1188   . . .   8305   743   3629 ]       [   728   1614    0   . . .   743   1933   1322 ]       [ 2024   1003   359   . . .   3629   1322   6227 ] ]      
 # Normalizing the co-occurrence matrix, by converting the values into a matrix  
 # Compute the co-occurrence matrix in percentage  
 #Reference:https://stackoverflow.com/questions/20574257/constructing-a-co-occurrence-matrix-in-python-pandas/20574460  
 cooccurrence_matrix_diagonal = np.diagonal(cooccurrence_matrix)  
 with np.errstate(divide = 'ignore', invalid='ignore'):  
   cooccurrence_matrix_percentage = np.nan_to_num(np.true_divide(cooccurrence_matrix, cooccurrence_matrix_diagonal))  
 print('\n Co-occurrence matrix percentage: \n', cooccurrence_matrix_percentage)  
 1 2 3 4 5 6 7 8   # Normalizing the co-occurrence matrix, by converting the values into a matrix     # Compute the co-occurrence matrix in percentage     #Reference:https://stackoverflow.com/questions/20574257/constructing-a-co-occurrence-matrix-in-python-pandas/20574460     cooccurrence_matrix_diagonal   =   np . diagonal ( cooccurrence_matrix )      with  np . errstate ( divide   =   'ignore' ,   invalid = 'ignore' ) :        cooccurrence_matrix_percentage   =   np . nan_to_num ( np . true_divide ( cooccurrence_matrix ,   cooccurrence_matrix_diagonal ) )      print ( '\n Co-occurrence matrix percentage: \n' ,   cooccurrence_matrix_percentage )      We can see that the values in the co-occurrence matrix represent the occurrence of each attribute with the other attributes. Although the matrix contains all the information, it is visually hard to interpret and infer from the matrix. To counter this problem, we will use heat maps, which can help relate the co-occurrences graphically. 
 fig = plt.figure(figsize=(10, 10))  
 sns.set(style='white')  
 # Draw the heatmap with the mask and correct aspect ratio   
 ax = sns.heatmap(cooccurrence_matrix_percentage, cmap='viridis', center=0, square=True, linewidths=0.15, cbar_kws={""shrink"": 0.5, ""label"": ""Co-occurrence frequency""}, )  
 ax.set_title('Heatmap of the attributes')  
 ax.set_xlabel('Attributes')  
 ax.set_ylabel('Attributes')  
 plt.show()   1 2 3 4 5 6 7 8   fig   =   plt . figure ( figsize = ( 10 ,   10 ) )      sns . set ( style = 'white' )      # Draw the heatmap with the mask and correct aspect ratio      ax   =   sns . heatmap ( cooccurrence_matrix_percentage ,   cmap = 'viridis' ,   center = 0 ,   square = True ,   linewidths = 0.15 ,   cbar_kws = { ""shrink"" :   0.5 ,   ""label"" :   ""Co-occurrence frequency"" } ,   )      ax . set_title ( 'Heatmap of the attributes' )      ax . set_xlabel ( 'Attributes' )      ax . set_ylabel ( 'Attributes' )      plt . show ( )    Fig 2. Heatmap of the co-occurrence matrix indicating the frequency of occurrence of one attribute with other Since the frequency of the co-occurrence is represented by a colour pallet, we can now easily interpret which attributes appear together the most. Thus, we can infer that these attributes are common to most of the animals. Choropleth Choropleths are a type of map that provides an easy way to show how some quantity varies across a geographical area or show the level of variability within a region. A heat map is similar but doesn’t include geographical boundaries. Choropleth maps are also appropriate for indicating differences in the distribution of the data over an area, like ownership or use of land or type of forest cover, density information, etc. We will be using the geopandas library to implement the choropleth graph. We will be using choropleth graph to visualize the GDP across the globe.  Link  to the dataset. 
 # Importing the required libraries  
 import geopandas as gpd   
 from shapely.geometry import Point  
 from matplotlib import cm  
 # GDP mapped to the corresponding country and their acronyms  
 df =pd.read_csv('GDP.csv')  
 df.head()  
 1 2 3 4 5 6 7 8   # Importing the required libraries     import  geopandas  as   gpd      from  shapely . geometry  import  Point     from  matplotlib  import  cm      # GDP mapped to the corresponding country and their acronyms     df   = pd . read_csv ( 'GDP.csv' )      df . head ( )      COUNTRY GDP (BILLIONS) CODE 0 Afghanistan 21.71 AFG 1 Albania 13.40 ALB 2 Algeria 227.80 DZA 3 American Samoa 0.75 ASM 4 Andorra 4.80 AND 
### Importing the geometry locations of each country on the world map  
 geo = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))[['iso_a3', 'geometry']]  
 geo.columns = ['CODE', 'Geometry']  
 geo.head()  
 1 2 3 4 5 ### Importing the geometry locations of each country on the world map     geo   =   gpd . read_file ( gpd . datasets . get_path ( 'naturalearth_lowres' ) ) [ [ 'iso_a3' ,   'geometry' ] ]      geo . columns   =   [ 'CODE' ,   'Geometry' ]      geo . head ( )      
# Mapping the country codes to the geometry locations  
 df = pd.merge(df, geo, left_on='CODE', right_on='CODE', how='inner')  
 #converting the dataframe to geo-dataframe  
 geometry = df['Geometry']  
 df.drop(['Geometry'], axis=1, inplace=True)  
 crs = {'init':'epsg:4326'}  
 geo_gdp = gpd.GeoDataFrame(df, crs=crs, geometry=geometry)  
 ## Plotting the choropleth  
 cpleth = geo_gdp.plot(column='GDP (BILLIONS)', cmap=cm.Spectral_r, legend=True, figsize=(8,8))  
 cpleth.set_title('Choropleth Graph - GDP of different countries')  
 1 2 3 4 5 6 7 8 9 10 11 # Mapping the country codes to the geometry locations     df   =   pd . merge ( df ,   geo ,   left_on = 'CODE' ,   right_on = 'CODE' ,   how = 'inner' )      #converting the dataframe to geo-dataframe     geometry   =   df [ 'Geometry' ]      df . drop ( [ 'Geometry' ] ,   axis = 1 ,   inplace = True )      crs   =   { 'init' : 'epsg:4326' }      geo_gdp   =   gpd . GeoDataFrame ( df ,   crs = crs ,   geometry = geometry )      ## Plotting the choropleth     cpleth   =   geo_gdp . plot ( column = 'GDP (BILLIONS)' ,   cmap = cm . Spectral_r ,   legend = True ,   figsize = ( 8 , 8 ) )      cpleth . set_title ( 'Choropleth Graph - GDP of different countries' )      Fig 3. Choropleth graph indicating the GDP according to geographical locations Surface plot Surface plots are used for the three-dimensional representation of the data. Rather than showing individual data points, surface plots show a functional relationship between a dependent variable (Z) and two independent variables (X and Y). It is useful in analyzing relationships between the dependent and the independent variables and thus helps in establishing desirable responses and operating conditions. 
 from mpl_toolkits.mplot3d import Axes3D  
 from matplotlib.ticker import LinearLocator, FormatStrFormatter  
 # Creating a figure  
 # projection = '3d' enables the third dimension during plot  
 fig = plt.figure(figsize=(10,8))  
 ax = fig.gca(projection='3d')  
 # Initialize data   
 X = np.arange(-5,5,0.25)  
 Y = np.arange(-5,5,0.25)  
 # Creating a meshgrid  
 X, Y = np.meshgrid(X, Y)  
 R = np.sqrt(np.abs(X**2 - Y**2))  
 Z = np.exp(R)  
 # plot the surface   
 surf = ax.plot_surface(X, Y, Z, cmap=cm.GnBu, antialiased=False)  
 # Customize the z axis.  
 ax.zaxis.set_major_locator(LinearLocator(10))  
 ax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))  
 ax.set_title('Surface Plot')  
 # Add a color bar which maps values to colors.  
 fig.colorbar(surf, shrink=0.5, aspect=5)  
 plt.show()  
 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23   from  mpl_toolkits . mplot3d  import  Axes3D     from  matplotlib . ticker  import  LinearLocator ,   FormatStrFormatter      # Creating a figure     # projection = '3d' enables the third dimension during plot     fig   =   plt . figure ( figsize = ( 10 , 8 ) )      ax   =   fig . gca ( projection = '3d' )      # Initialize data      X   =   np . arange ( - 5 , 5 , 0.25 )      Y   =   np . arange ( - 5 , 5 , 0.25 )      # Creating a meshgrid     X ,   Y   =   np . meshgrid ( X ,   Y )      R   =   np . sqrt ( np . abs ( X* * 2   -   Y* * 2 ) )      Z   =   np . exp ( R )      # plot the surface      surf   =   ax . plot_surface ( X ,   Y ,   Z ,   cmap = cm . GnBu ,   antialiased = False )      # Customize the z axis.     ax . zaxis . set_major_locator ( LinearLocator ( 10 ) )      ax . zaxis . set_major_formatter ( FormatStrFormatter ( '%.02f' ) )      ax . set_title ( 'Surface Plot' )      # Add a color bar which maps values to colors.     fig . colorbar ( surf ,   shrink = 0.5 ,   aspect = 5 )      plt . show ( )      One of the main applications of surface plots in machine learning or data science is the analysis of the loss function. From a surface plot, we can analyze how the hyperparameters affect the loss function and thus help prevent overfitting of the model. Fig 4. Surface plot visualizing the dependent variable w.r.t the independent variables in 3-dimensions Visualizing high-dimensional datasets Dimensionality refers to the number of attributes present in the dataset. For example, consumer-retail datasets can have a vast amount of variables (e.g. sales, promos, products, open, etc.). As a result, visually exploring the dataset to find potential correlations between variables becomes extremely challenging. Therefore, we use a technique called dimensionality reduction to visualize higher dimensional datasets. Here, we will focus on two such techniques : Principal Component Analysis (PCA) T-distributed Stochastic Neighbor Embedding (t-SNE) Principal Component Analysis (PCA) Before we jump into understanding PCA, let’s review some terms: Variance: Variance is simply the measure of the spread or extent of the data. Mathematically, it is the average squared deviation from the mean position. Covariance: Covariance is the measure of the extent to which corresponding elements from two sets of ordered data move in the same direction. It is the measure of how two random variables vary together. It is similar to variance, but where variance tells you the extent of one variable, covariance tells you the extent to which the two variables vary together. Mathematically, it is defined as: A positive covariance means X and Y are positively related, i.e., if X increases, Y increases, while negative covariance means the opposite relation. However, zero variance means X and Y are not related. Fig 5. Different types of covariance PCA is the orthogonal projection of data onto a lower-dimension linear space that maximizes variance (green line) of the projected data and minimizes the mean squared distance between the data point and the projects (blue line). The variance describes the direction of maximum information while the mean squared distance describes the information lost during projection of the data onto the lower dimension. Thus, given a set of data points in a d-dimensional space, PCA projects these points onto a lower dimensional space while preserving as much information as possible. Fig 6. Illustration of principal component analysis In the figure, the component along the direction of maximum variance is defined as the first principal axis. Similarly, the component along the direction of second maximum variance is defined as the second principal component, and so on. These principal components are referred to the new dimensions carrying the maximum information. 
 # We will use the breast cancer dataset as an example  
 # The dataset is a binary classification dataset  
 # Importing the dataset  
 from sklearn.datasets import load_breast_cancer  
 data = load_breast_cancer()  
 X = pd.DataFrame(data=data.data, columns=data.feature_names) # Features   
 y = data.target # Target variable   
 # Importing PCA function  
 from sklearn.decomposition import PCA  
 pca = PCA(n_components=2) # n_components = number of principal components to generate  
 # Generating pca components from the data  
 pca_result = pca.fit_transform(X)  
 print(""Explained variance ratio : \n"",pca.explained_variance_ratio_)  
 1 2 3 4 5 6 7 8 9 10 11 12 13 14   # We will use the breast cancer dataset as an example     # The dataset is a binary classification dataset     # Importing the dataset     from  sklearn . datasets  import  load_breast_cancer     data   =   load_breast_cancer ( )      X   =   pd . DataFrame ( data = data . data ,   columns = data . feature_names )   # Features      y   =   data . target   # Target variable      # Importing PCA function     from  sklearn . decomposition  import  PCA     pca   =   PCA ( n_components = 2 )   # n_components = number of principal components to generate     # Generating pca components from the data     pca_result   =   pca . fit_transform ( X )      print ( ""Explained variance ratio : \n"" , pca . explained_variance_ratio_ )      
 Out: Explained variance ratio :   
  [0.98204467 0.01617649]  
 1 2 3   Out :   Explained  variance  ratio   :        [ 0.98204467   0.01617649 ]      We can see that 98% (approx) variance of the data is along the first principal component, while the second component only expresses 1.6% (approx) of the data. 
 # Creating a figure   
 fig = plt.figure(1, figsize=(10, 10))  
 # Enabling 3-dimensional projection   
 ax = fig.gca(projection='3d')  
 for i, name in enumerate(data.target_names):  
   ax.text3D(np.std(pca_result[:, 0][y==i])-i*500 ,np.std(pca_result[:, 1][y==i]),0,s=name, horizontalalignment='center', bbox=dict(alpha=.5, edgecolor='w', facecolor='w'))  
 # Plotting the PCA components    
 ax.scatter(pca_result[:,0], pca_result[:, 1], c=y, cmap = plt.cm.Spectral,s=20, label=data.target_names)  
 plt.show()   1 2 3 4 5 6 7 8 9   # Creating a figure      fig   =   plt . figure ( 1 ,   figsize = ( 10 ,   10 ) )      # Enabling 3-dimensional projection      ax   =   fig . gca ( projection = '3d' )      for   i ,   name  in   enumerate ( data . target_names ) :        ax . text3D ( np . std ( pca_result [ : ,   0 ] [ y == i ] ) - i* 500   , np . std ( pca_result [ : ,   1 ] [ y == i ] ) , 0 , s = name ,   horizontalalignment = 'center' ,   bbox = dict ( alpha = . 5 ,   edgecolor = 'w' ,   facecolor = 'w' ) )      # Plotting the PCA components       ax . scatter ( pca_result [ : , 0 ] ,   pca_result [ : ,   1 ] ,   c = y ,   cmap   =   plt . cm . Spectral , s = 20 ,   label = data . target_names )      plt . show ( )    Fig 7. Visualizing the distribution of cancer across the data Thus, with the help of PCA, we can get a visual perception of how the labels are distributed across given data (see Figure). T-distributed Stochastic Neighbour Embedding (t-SNE) T-distributed Stochastic Neighbour Embeddings (t-SNE) is a non-linear dimensionality reduction technique that is well suited for visualization of high-dimensional data. It was developed by Laurens van der Maten and Geoffrey Hinton. In contrast to PCA, which is a mathematical technique, t-SNE adopts a probabilistic approach. PCA can be used for capturing the global structure of the high-dimensional data but fails to describe the local structure within the data. Whereas, “t-SNE” is capable of capturing the local structure of the high-dimensional data very well while also revealing global structure such as the presence of clusters at several scales. t-SNE converts the similarity between data points to joint probabilities and tries to maximize the Kullback-Leibler divergence between the joint probabilities of the low-dimensional embeddings and high-dimension data. In doing so, it preserves the original structure of the data. 
 # We will be using the scikit learn library to implement t-SNE  
 # Importing the t-SNE library   
 from sklearn.manifold import TSNE  
 # We will be using the iris dataset for this example  
 from sklearn.datasets import load_iris  
 1 2 3 4 5 6   # We will be using the scikit learn library to implement t-SNE     # Importing the t-SNE library      from  sklearn . manifold  import  TSNE      # We will be using the iris dataset for this example     from  sklearn . datasets  import  load _ iris      
 # Loading the iris dataset   
 data = load_iris()  
 # Extracting the features   
 X = data.data  
 # Extracting the labels   
 y = data.target  
 # There are four features in the iris dataset with three different labels.  
 print('Features in iris data:\n', data.feature_names)  
 print('Labels in iris data:\n', data.target_names)  
 1 2 3 4 5 6 7 8 9 10   # Loading the iris dataset      data   =   load_iris ( )      # Extracting the features      X   =   data . data      # Extracting the labels      y   =   data . target      # There are four features in the iris dataset with three different labels.     print ( 'Features in iris data:\n' ,   data . feature_names )      print ( 'Labels in iris data:\n' ,   data . target_names )      
 Out: Features in iris data:  
  ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']  
 Labels in iris data:  
  ['setosa' 'versicolor' 'virginica']  
 1 2 3 4 5   Out :   Features  in   iris  data :       [ 'sepal length (cm)' ,   'sepal width (cm)' ,   'petal length (cm)' ,   'petal width (cm)' ]      Labels  in   iris  data :       [ 'setosa'   'versicolor'   'virginica' ]      
 # Loading the TSNE model   
 # n_components = number of resultant components   
 # n_iter = Maximum number of iterations for the optimization.  
 tsne_model = TSNE(n_components=3, n_iter=2500, random_state=47)  
 # Generating new components   
 new_values = tsne_model.fit_transform(X)  
 labels = data.target_names  
 # Plotting the new dimensions/ components  
 fig = plt.figure(figsize=(5, 5))  
 ax = Axes3D(fig, rect=[0, 0, .95, 1], elev=48, azim=134)  
 for label, name in enumerate(labels):  
   ax.text3D(new_values[y==label, 0].mean(),  
        new_values[y==label, 1].mean() + 1.5,  
        new_values[y==label, 2].mean(), name,  
        horizontalalignment='center',  
        bbox=dict(alpha=.5, edgecolor='w', facecolor='w'))  
 ax.scatter(new_values[:,0], new_values[:,1], new_values[:,2], c=y)  
 ax.set_title('High-Dimension data visualization using t-SNE', loc='right')  
 plt.show()  
 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20   # Loading the TSNE model      # n_components = number of resultant components      # n_iter = Maximum number of iterations for the optimization.     tsne_model   =   TSNE ( n_components = 3 ,   n_iter = 2500 ,   random_state = 47 )      # Generating new components      new_values   =   tsne_model . fit_transform ( X )      labels   =   data . target_names      # Plotting the new dimensions/ components     fig   =   plt . figure ( figsize = ( 5 ,   5 ) )      ax   =   Axes3D ( fig ,   rect = [ 0 ,   0 ,   . 95 ,   1 ] ,   elev = 48 ,   azim = 134 )      for   label ,   name  in   enumerate ( labels ) :        ax . text3D ( new_values [ y == label ,   0 ] . mean ( ) ,             new_values [ y == label ,   1 ] . mean ( )   +   1.5 ,             new_values [ y == label ,   2 ] . mean ( ) ,   name ,             horizontalalignment = 'center' ,             bbox = dict ( alpha = . 5 ,   edgecolor = 'w' ,   facecolor = 'w' ) )      ax . scatter ( new_values [ : , 0 ] ,   new_values [ : , 1 ] ,   new_values [ : , 2 ] ,   c = y )      ax . set_title ( 'High-Dimension data visualization using t-SNE' ,   loc = 'right' )      plt . show ( )      Fig 8. Visualizing the feature space of the iris dataset using t-SNE Thus, by reducing the dimensions using t-SNE, we can visualize the distribution of the labels over the feature space. We can see that in the figure the labels are clustered in their own little group. So, if we’re to use a clustering algorithm to generate clusters using the new features/components, we can accurately assign new points to a label.  Conclusion Let’s quickly summarize the topics we covered. We started with the generation of heatmaps using random numbers and extended its application to a real-world example. Next, we implemented choropleth graphs to visualize the data points with respect to geographical locations. We moved on to implement surface plots to get an idea of how we can visualize the data in a three-dimensional surface. Finally, we used two- dimensional reduction techniques, PCA and t-SNE, to visualize high-dimensional datasets. I encourage you to implement the examples described in this article to get a hands-on experience. Hope you enjoyed the article. Do let me know if you have any feedback, suggestions, or thoughts on this article in the comments below!     8 Shares 8       About the  Author 
 
 Shubham Gupta 
 
 
 
 
 
 
Trying to solve problems through machine learning and help others evolve in the field of machine learning. Currently working as a Data Science Intern at HackerEarth. Highly enthusiastic about autonomous driven systems. Want to stay ahead of the technology curve? Subscribe to our Developers blog 
 
 
 
 
 
 
 Please leave this field empty. 
 Yes, I would like to receive the latest information on emerging technology trends, as well as relevant marketing communication about hackathons, events and challenges.  By signing up you agree to our  Terms of service  and  Privacy policy . 
     Related Posts 
   
 6 things business owners should do before inter... 
 Developers 
 Startup 
 
November 25, 2019 
   
 8 Steps to acing your next system design interview 
 Developers 
 Interview tips 
 
November 19, 2019 
   
 7 steps to improve your data structure and algo... 
 Algorithms 
 Developer Tips 
 Developers 
 
November 13, 2019 
   
 HackerEarth Community—Get ready for spooktacula... 
 Community 
 Developers 
 
October 30, 2019 
   
 What’s the difference between front-end, ... 
 Developer Tips 
 Developers 
 
October 16, 2019 
   
 How to use mock interviews to streamline your t... 
 Developer Tips 
 Developers 
 
September 27, 2019 
   
 Hackathons simplified 
 Developers 
 Hackathons 
 
September 25, 2019 
   
 Top tips to prepare for software engineering in... 
 Developer Tips 
 Interview tips 
 
September 18, 2019 
   
 Do you really need a degree to build a career i... 
 Developer Tips 
 Interview tips 
 
September 6, 2019 
   
 R Algorithms in AI and computing forces working... 
 Developers 
 Machine Learning 
 R 
 
June 25, 2019         comments powered by Disqus.           Blog Engineering Blog Updates & Releases Team Careers In the Press 
 
© 2019 HackerEarth Terms & Conditions Privacy "," Heatmaps,Choropleth,Surface plot,Visualizing high-dimensional datasets,Conclusion,", http://engineering.hackerearth.com/http://news.hackerearth.com/
14,Composing Jazz Music with Deep Learning,https://www.hackerearth.com/blog/developers/jazz-music-using-deep-learning/,"Composing Jazz Music with Deep Learning | HackerEarth Blog 
 Hackathons Technical Recruitment For Developers 
 
 
 
 Recruitment Blog Developers Blog Webinars Algorithms Competitive Programming Machine Learning Interview Tips More Categories ≫ 
 Menu 
 
 Toggle navigation 
 
 
 
 Recruitment Blog Developers Blog Webinars 
 
 
 
   
Composing Jazz Music with Deep Learning 
 Artificial Intelligence 
 Data Science 
 Developers 
 Machine Learning 
 May 29, 2018 
    7   mins D eep Learning is on the rise, extending its application in every field, ranging from computer vision to natural language processing, healthcare, speech recognition, generating art, addition of sound to silent movies, machine translation, advertising, self-driving cars, etc. In this blog, we will extend the power of deep learning to the domain of music production. We will talk about how we can use deep learning to generate new musical beats. The current technological advancements have transformed the way we produce music, listen, and work with music. With the advent of deep learning, it has now become possible to generate music without the need for working with instruments artists may not have had access to or the skills to use previously. This offers artists more creative freedom and ability to explore different domains of music. Recurrent Neural Networks Since music is a sequence of notes and chords, it doesn’t have a fixed dimensionality. Traditional deep neural network techniques cannot be applied to generate music as they assume the inputs and targets/outputs to have fixed dimensionality and outputs to be independent of each other. It is therefore clear that a domain-independent method that learns to map sequences to sequences would be useful. Recurrent neural networks ( RNNs ) are a class of artificial neural networks that make use of sequential information present in the data.   Fig. 1 A basic RNN unit. A recurrent neural network has looped, or recurrent, connections which allow the network to hold information across inputs. These connections can be thought of as memory cells. In other words, RNNs can make use of information learned in the previous time step. As seen in Fig. 1, the output of the previous hidden/activation layer is fed into the next hidden layer. Such an architecture is efficient in learning sequence-based data. In this blog, we will be using the Long Short-Term Memory ( LSTM ) architecture. LSTM is a type of recurrent neural network (proposed by Hochreiter and Schmidhuber, 1997) that can remember a piece of information and keep it saved for many timesteps. Dataset Our dataset includes piano tunes stored in the  MIDI  format. MIDI (Musical Instrument Digital Interface) is a protocol which allows electronic instruments and other digital musical tools to communicate with each other. Since a MIDI file only represents player information, i.e., a series of messages like ‘note on’, ‘note off, it is more compact, easy to modify, and can be adapted to any instrument. Before we move forward, let us understand some music related terminologies: Note: A note is either a single sound or its representation in notation. Each note consist of pitch, octave, and an offset. Pitch: Pitch refers to the frequency of the sound. Octave: An octave is the interval between one musical pitch and another with half or double its frequency. Offset: Refers to the location of the note. Chord: Playing multiple notes at the same time constitutes a chord. Data Preprocessing We will use the music21  toolkit  (a toolkit for computer-aided musicology, MIT) to extract data from these MIDI files. Notes Extraction 
 def get_notes():  
   notes = []  
   for file in songs:  
     # converting .mid file to stream object  
     midi = converter.parse(file)  
     notes_to_parse = []  
     try:  
       # Given a single stream, partition into a part for each unique instrument  
       parts = instrument.partitionByInstrument(midi)  
     except:  
       pass  
     if parts: # if parts has instrument parts   
       notes_to_parse = parts.parts[0].recurse()  
     else:  
       notes_to_parse = midi.flat.notes  
     for element in notes_to_parse:   
       if isinstance(element, note.Note):  
         # if element is a note, extract pitch   
         notes.append(str(element.pitch))  
       elif(isinstance(element, chord.Chord)):  
         # if element is a chord, append the normal form of the   
         # chord (a list of integers) to the list of notes.   
         notes.append('.'.join(str(n) for n in element.normalOrder))  
   with open('data/notes', 'wb') as filepath:  
     pickle.dump(notes, filepath)  
   return notes  
 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27   def  get_notes ( ) :        notes   =   [ ]        for   file  in   songs :          # converting .mid file to stream object         midi   =   converter . parse ( file )          notes_to_parse   =   [ ]          try :            # Given a single stream, partition into a part for each unique instrument           parts   =   instrument . partitionByInstrument ( midi )          except :            pass         if   parts :   # if parts has instrument parts            notes_to_parse   =   parts . parts [ 0 ] . recurse ( )          else :            notes_to_parse   =   midi . flat . notes         for   element  in   notes_to_parse :             if   isinstance ( element ,   note . Note ) :              # if element is a note, extract pitch              notes . append ( str ( element . pitch ) )            elif ( isinstance ( element ,   chord . Chord ) ) :              # if element is a chord, append the normal form of the              # chord (a list of integers) to the list of notes.              notes . append ( '.' . join ( str ( n )   for   n   in   element . normalOrder ) )        with  open ( 'data/notes' ,   'wb' )   as   filepath :          pickle . dump ( notes ,   filepath )        return   notes      The function get_notes returns a list of notes and chords present in the .mid file. We use the converter.parse function to convert the midi file in a stream object, which in turn is used to extract notes and chords present in the file. The list returned by the function  get_notes()  looks as follows: 
 Out:  
   ['F2', '4.5.7', '9.0', 'C3', '5.7.9', '7.0', 'E4', '4.5.8', '4.8', '4.8', '4', 'G#3',  
   'D4', 'G#3', 'C4', '4', 'B3', 'A2', 'E3', 'A3', '0.4', 'D4', '7.11', 'E3', '0.4.7', 'B4', 'C3', 'G3', 'C4', '4.7', '11.2', 'C3', 'C4', '11.2.4', 'G4', 'F2', 'C3', '0.5', '9.0', '4.7', 'F2', '4.5.7.9.0', '4.8', 'F4', '4', '4.8', '2.4', 'G#3',  
  '8.0', 'E2', 'E3', 'B3', 'A2', '4.9', '0.4', '7.11', 'A2', '9.0.4', ...........]   1 2 3 4   Out :        [ 'F2' ,   '4.5.7' ,   '9.0' ,   'C3' ,   '5.7.9' ,   '7.0' ,   'E4' ,   '4.5.8' ,   '4.8' ,   '4.8' ,   '4' ,   'G#3' ,        'D4' ,   'G#3' ,   'C4' ,   '4' ,   'B3' ,   'A2' ,   'E3' ,   'A3' ,   '0.4' ,   'D4' ,   '7.11' ,   'E3' ,   '0.4.7' ,   'B4' ,   'C3' ,   'G3' ,   'C4' ,   '4.7' ,   '11.2' ,   'C3' ,   'C4' ,   '11.2.4' ,   'G4' ,   'F2' ,   'C3' ,   '0.5' ,   '9.0' ,   '4.7' ,   'F2' ,   '4.5.7.9.0' ,   '4.8' ,   'F4' ,   '4' ,   '4.8' ,   '2.4' ,   'G#3' ,       '8.0' ,   'E2' ,   'E3' ,   'B3' ,   'A2' ,   '4.9' ,   '0.4' ,   '7.11' ,   'A2' ,   '9.0.4' ,   . . . . . . . . . . . ]    We can see that the list consists of pitches and chords (represented as a list of integers separated by a dot). We assume each new chord to be a new pitch on the list. As letters are used to generate words in a sentence, similarly the music vocabulary used to generate music is defined by the unique pitches in the notes list. Generating Input and Output Sequences A neural network accepts only real values as input and since the pitches in the notes list are in string format, we need to map each pitch in the notes list to an integer. We can do so as follows: 
 # Extract the unique pitches in the list of notes.   
 pitchnames = sorted(set(item for item in notes))  
 # create a dictionary to map pitches to integers  
 note_to_int = dict((note, number) for number, note in enumerate(pitchnames))  
 1 2 3 4 5   # Extract the unique pitches in the list of notes.      pitchnames   =   sorted ( set ( item  for   item  in   notes ) )      # create a dictionary to map pitches to integers     note_to_int   =   dict ( ( note ,   number )   for   number ,   note  in   enumerate ( pitchnames ) )      Next, we will create an array of input and output sequences to train our model. Each input sequence will consist of 100 notes, while the output array stores the 101st note for the corresponding input sequence. So, the objective of the model will be to predict the 101st note of the input sequence of notes. 
 # create input sequences and the corresponding outputs  
 for i in range(0, len(notes) - sequence_length, 1):  
   sequence_in = notes[i: i + sequence_length]  
   sequence_out = notes[i + sequence_length]  
   network_input.append([note_to_int[char] for char in sequence_in])  
   network_output.append(note_to_int[sequence_out])  
 1 2 3 4 5 6 7   # create input sequences and the corresponding outputs     for   i   in   range ( 0 ,   len ( notes )   -   sequence_length ,   1 ) :        sequence_in   =   notes [ i :   i   +   sequence_length ]        sequence_out   =   notes [ i   +   sequence_length ]        network_input . append ( [ note_to_int [ char ]   for   char   in   sequence_in ] )        network_output . append ( note_to_int [ sequence_out ] )      Next, we reshape and normalize the input vector sequence before feeding it to the model. Finally, we one-hot encode our output vector. 
 n_patterns = len(network_input)  
 # reshape the input into a format compatible with LSTM layers   
 network_input = np.reshape(network_input, (n_patterns, sequence_length, 1))  
 # normalize input  
 network_input = network_input / float(n_vocab)  
 # One hot encode the output vector  
 network_output = np_utils.to_categorical(network_output)  
 1 2 3 4 5 6 7 8   n_patterns   =   len ( network_input )      # reshape the input into a format compatible with LSTM layers      network_input   =   np . reshape ( network_input ,   ( n_patterns ,   sequence_length ,   1 ) )      # normalize input     network_input   =   network_input   /   float ( n_vocab )      # One hot encode the output vector     network_output   =   np_utils . to_categorical ( network_output )      Model Architecture We will use keras to build our model architecture. We use a character level-based architecture to train the model. So each input note in the music file is used to predict the next note in the file, i.e., each LSTM cell takes the previous layer activation ( a ⟨t−1⟩ ) and the previous layers actual output (y ⟨t−1⟩ ) as input at the current time step  t t. This is depicted in the following figure (Fig 2.). Fig 2. One to Many LSTM architecture Our model architecture is defined as: 
 model = Sequential()  
 model.add(LSTM(128, input_shape=network_in.shape[1:], return_sequences=True))  
 model.add(Dropout(0.2))  
 model.add(LSTM(128, return_sequences=True))  
 model.add(Flatten())  
 model.add(Dense(256))  
 model.add(Dropout(0.3))  
 model.add(Dense(n_vocab))  
 model.add(Activation('softmax'))  
 model.compile(loss='categorical_crossentropy', optimizer='adam')  
 1 2 3 4 5 6 7 8 9 10 11   model   =   Sequential ( )      model . add ( LSTM ( 128 ,   input_shape = network_in . shape [ 1 : ] ,   return_sequences = True ) )      model . add ( Dropout ( 0.2 ) )      model . add ( LSTM ( 128 ,   return_sequences = True ) )      model . add ( Flatten ( ) )      model . add ( Dense ( 256 ) )      model . add ( Dropout ( 0.3 ) )      model . add ( Dense ( n_vocab ) )      model . add ( Activation ( 'softmax' ) )      model . compile ( loss = 'categorical_crossentropy' ,   optimizer = 'adam' )      Our music model consists of two LSTM layers with each layer consisting of 128 hidden layers. We use ‘ categorical cross entropy ‘ as the loss function and ‘ adam ‘ as the optimizer. Fig. 3 shows the model summary. Fig 3. Model summary Model Training To train the model, we call the  model . fit  function with the input and output sequences as the input to the function. We also create a model checkpoint which saves the best model weights. 
 from keras.callbacks import ModelCheckpoint  
 def train(model, network_input, network_output, epochs):   
   """"""  
   Train the neural network  
   """"""  
   filepath = 'weights.best.music3.hdf5'  
   checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=0, save_best_only=True)  
   model.fit(network_input, network_output, epochs=epochs, batch_size=32, callbacks=[checkpoint])  
 def train_network():  
   epochs = 200  
   notes = get_notes()  
   print('Notes processed')  
   n_vocab = len(set(notes))  
   print('Vocab generated')  
   network_in, network_out = prepare_sequences(notes, n_vocab)  
   print('Input and Output processed')  
   model = create_network(network_in, n_vocab)  
   print('Model created')  
   return model  
   print('Training in progress')  
   train(model, network_in, network_out, epochs)  
   print('Training completed')  
 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23   from  keras . callbacks  import  ModelCheckpoint     def  train ( model ,   network_input ,   network_output ,   epochs ) :         """" ""      Train the neural network      "" """"        filepath   =   'weights.best.music3.hdf5'        checkpoint   =   ModelCheckpoint ( filepath ,   monitor = 'loss' ,   verbose = 0 ,   save_best_only = True )        model . fit ( network_input ,   network_output ,   epochs = epochs ,   batch_size = 32 ,   callbacks = [ checkpoint ] )      def  train_network ( ) :        epochs   =   200        notes   =   get_notes ( )        print ( 'Notes processed' )        n_vocab   =   len ( set ( notes ) )        print ( 'Vocab generated' )        network_in ,   network_out   =   prepare_sequences ( notes ,   n_vocab )        print ( 'Input and Output processed' )        model   =   create_network ( network_in ,   n_vocab )        print ( 'Model created' )        return   model       print ( 'Training in progress' )        train ( model ,   network_in ,   network_out ,   epochs )        print ( 'Training completed' )      The  train_network  method gets the notes, creates the input and output sequences, creates a model, and trains the model for 200 epochs. Music Sample Generation Now that we have trained our model, we can use it to generate some new notes. To generate new notes, we need a starting note. So, we randomly pick an integer and pick a random sequence from the input sequence as a starting point. 
 def generate_notes(model, network_input, pitchnames, n_vocab):  
   """""" Generate notes from the neural network based on a sequence of notes """"""  
   # Pick a random integer  
   start = np.random.randint(0, len(network_input)-1)  
   int_to_note = dict((number, note) for number, note in enumerate(pitchnames))  
   # pick a random sequence from the input as a starting point for the prediction  
   pattern = network_input[start]  
   prediction_output = []  
   print('Generating notes........')  
   # generate 500 notes  
   for note_index in range(500):  
     prediction_input = np.reshape(pattern, (1, len(pattern), 1))  
     prediction_input = prediction_input / float(n_vocab)  
     prediction = model.predict(prediction_input, verbose=0)  
     # Predicted output is the argmax(P(h|D))  
     index = np.argmax(prediction)  
     # Mapping the predicted interger back to the corresponding note  
     result = int_to_note[index]  
     # Storing the predicted output  
     prediction_output.append(result)  
     pattern.append(index)  
     # Next input to the model  
     pattern = pattern[1:len(pattern)]  
   print('Notes Generated...')  
   return prediction_output  
 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26   def  generate_notes ( model ,   network_input ,   pitchnames ,   n_vocab ) :        """" "" Generate notes from the neural network based on a sequence of notes "" """"        # Pick a random integer       start   =   np . random . randint ( 0 ,   len ( network_input ) - 1 )        int_to_note   =   dict ( ( number ,   note )   for   number ,   note  in   enumerate ( pitchnames ) )        # pick a random sequence from the input as a starting point for the prediction       pattern   =   network_input [ start ]        prediction_output   =   [ ]        print ( 'Generating notes........' )        # generate 500 notes       for   note_index  in   range ( 500 ) :          prediction_input   =   np . reshape ( pattern ,   ( 1 ,   len ( pattern ) ,   1 ) )          prediction_input   =   prediction_input   /   float ( n_vocab )          prediction   =   model . predict ( prediction_input ,   verbose = 0 )          # Predicted output is the argmax(P(h|D))         index   =   np . argmax ( prediction )          # Mapping the predicted interger back to the corresponding note         result   =   int_to_note [ index ]          # Storing the predicted output         prediction_output . append ( result )          pattern . append ( index )          # Next input to the model         pattern   =   pattern [ 1 : len ( pattern ) ]        print ( 'Notes Generated...' )        return   prediction _ output      Next, we use the trained model to predict the next 500 notes. At each time step, the output of the previous layer ( y ̂ ⟨t−1⟩ ) is provided as input ( x ⟨t⟩ ) to the LSTM layer at the current time step  t . This is depicted in the following figure (see Fig. 4). Fig 4. Sampling from a trained network. Since the predicted output is an array of probabilities, we choose the output at the index with the maximum probability. Finally, we map this index to the actual note and add this to the list of predicted output. Since the predicted output is a list of strings of notes and chords, we cannot play it. Hence, we encode the predicted output into the MIDI format using the create_midi method. 
 ### Converts the predicted output to midi format  
 create_midi(prediction_output)  
 1 2 3   ### Converts the predicted output to midi format     create_midi ( prediction_output )      To create some new jazz music, you can simply call the  generate()  method, which calls all the related methods and saves the predicted output as a MIDI file. 
 #### Generate a new jazz music   
 generate()  
 Out:   
   Initiating music generation process.......  
   Loading Model weights.....  
   Model Loaded  
   Generating notes........  
   Notes Generated...  
   Saving Output file as midi....  
 1 2 3 4 5 6 7 8 9 10   #### Generate a new jazz music      generate ( )      Out :         Initiating  music  generation  process . . . . . . .        Loading  Model  weights . . . . .        Model  Loaded       Generating  notes . . . . . . . .        Notes  Generated . . .        Saving  Output  file  as   midi . . . .      To play the generated MIDI in the Jupyter Notebook you can import the  play_midi  method from the  play.py  file or use an external MIDI player or convert the MIDI file to the mp3. Let’s listen to our generated jazz piano music. 
 ### Play the Jazz music  
 play.play_midi('test_output3.mid')   1 2   ### Play the Jazz music     play . play_midi ( 'test_output3.mid' )    [if lt IE 9]>document.createElement('audio');<![endif] 
 
 Generated Track 1     Conclusion Congratulations! You can now generate your own jazz music. You can find the full code in this  Github  repository. I encourage you to play with the parameters of the model and train the model with input sequences of different sequence lengths. Try to implement the code for some other instrument (such as guitar). Furthermore, such a character-based model can also be applied to a text corpus to generate sample texts, such as a poem. Also, you can showcase your own personal composer and any similar idea in the  World Music Hackathon  by HackerEarth. Have anything to say? Feel free to comment below for any questions, suggestions, and discussions related to this article. Till then, happy coding.   31 Shares 31       About the  Author 
 
 Shubham Gupta 
 
 
 
 
 
 
Trying to solve problems through machine learning and help others evolve in the field of machine learning. Currently working as a Data Science Intern at HackerEarth. Highly enthusiastic about autonomous driven systems. Want to stay ahead of the technology curve? Subscribe to our Developers blog 
 
 
 
 
 
 
 Please leave this field empty. 
 Yes, I would like to receive the latest information on emerging technology trends, as well as relevant marketing communication about hackathons, events and challenges.  By signing up you agree to our  Terms of service  and  Privacy policy . 
     Related Posts 
   
 6 things business owners should do before inter... 
 Developers 
 Startup 
 
November 25, 2019 
   
 8 Steps to acing your next system design interview 
 Developers 
 Interview tips 
 
November 19, 2019 
   
 7 steps to improve your data structure and algo... 
 Algorithms 
 Developer Tips 
 Developers 
 
November 13, 2019 
   
 HackerEarth Community—Get ready for spooktacula... 
 Community 
 Developers 
 
October 30, 2019 
   
 What’s the difference between front-end, ... 
 Developer Tips 
 Developers 
 
October 16, 2019 
   
 How to use mock interviews to streamline your t... 
 Developer Tips 
 Developers 
 
September 27, 2019 
   
 Hackathons simplified 
 Developers 
 Hackathons 
 
September 25, 2019 
   
 Top tips to prepare for software engineering in... 
 Developer Tips 
 Interview tips 
 
September 18, 2019 
   
 Do you really need a degree to build a career i... 
 Developer Tips 
 Interview tips 
 
September 6, 2019 
   
 R Algorithms in AI and computing forces working... 
 Developers 
 Machine Learning 
 R 
 
June 25, 2019         comments powered by Disqus.           Blog Engineering Blog Updates & Releases Team Careers In the Press 
 
© 2019 HackerEarth Terms & Conditions Privacy "," Recurrent Neural Networks,None,None,None,None,None,", http://web.mit.edu/music21/doc/moduleReference/moduleConverter.htmlhttp://engineering.hackerearth.com/http://news.hackerearth.com/
15,Data visualization for beginners – Part 2,https://www.hackerearth.com/blog/developers/data-visualization-for-beginners-part-2/,"Data visualization for beginners - Part 2 | HackerEarth Blog 
 Hackathons Technical Recruitment For Developers 
 
 
 
 Recruitment Blog Developers Blog Webinars Algorithms Competitive Programming Machine Learning Interview Tips More Categories ≫ 
 Menu 
 
 Toggle navigation 
 
 
 
 Recruitment Blog Developers Blog Webinars 
 
 
 
   
Data visualization for beginners – Part 2 
 Big Data 
 Data Science 
 Developers 
 Machine Learning 
 Python 
 May 16, 2018 
    8   mins Welcome to Part II of the series on data visualization. In the last blog post, we explored different ways to visualize continuous variables and infer information. If you haven’t visited that article, you can find it  here.  In this blog, we will expand our exploration to categorical variables and investigate ways in which we can visualize and gain insights from them, in isolation and in combination with variables (both categorical and continuous). Before we dive into the different graphs and plots, let’s define a categorical variable. In statistics, a categorical variable is one which has two or more categories, but there is no intrinsic ordering to them, for example, gender, color, cities, age group, etc. If there is some kind of ordering between the categories, the variables are classified as ordinal variables, for example, if you categorize car prices by cheap, moderate and expensive. Although these are categories, there is a clear ordering between the categories. 
# Importing the necessary libraries.  
import numpy as np  
import pandas as pd  
import seaborn as sns  
import matplotlib.pyplot as plt  
%matplotlib inline   1 2 3 4 5 6 # Importing the necessary libraries.   import  numpy  as   np   import  pandas  as   pd   import  seaborn  as   sns   import  matplotlib . pyplot  as   plt    % matplotlib  inline    We will be using the Adult data set, which is an extraction of the 1994 census dataset. The prediction task is to determine whether a person makes more than 50K a year.  Here   is the link to the dataset. In this blog, we will be using the dataset only for data analysis. 
# Since the dataset doesn't contain the column header, we need to specify it manually.   
cols = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'gender', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'annual-income']  

# Importing dataset   
data = pd.read_csv('adult dataset/adult.data', names=cols)  
 1 2 3 4 5 6 # Since the dataset doesn't contain the column header, we need to specify it manually.    cols   =   [ 'age' ,   'workclass' ,   'fnlwgt' ,   'education' ,   'education-num' ,   'marital-status' ,   'occupation' ,   'relationship' ,   'race' ,   'gender' ,   'capital-gain' ,   'capital-loss' ,   'hours-per-week' ,   'native-country' ,   'annual-income' ]      # Importing dataset    data   =   pd . read_csv ( 'adult dataset/adult.data' ,   names = cols )      
# The first five columns of the dataset.   
data.head()  
 1 2 3 # The first five columns of the dataset.    data . head ( )      Bar graph A bar chart or graph is a graph with rectangular bars or bins that are used to plot categorical values. Each bar in the graph represents a categorical variable and the height of the bar is proportional to the value represented by it. Bar graphs are used: To make comparisons between variables To visualize any trend in the data, i.e., they show the dependence of one variable on another Estimate values of a variable 
# Let's start by visualizing the distribution of gender in the dataset.  
fig, ax = plt.subplots()  
x = data.gender.unique()  
# Counting 'Males' and 'Females' in the dataset  
y = data.gender.value_counts()  
# Plotting the bar graph  
ax.bar(x, y)  
ax.set_xlabel('Gender')  
ax.set_ylabel('Count')  
plt.show()  
 1 2 3 4 5 6 7 8 9 10 11 # Let's start by visualizing the distribution of gender in the dataset.   fig ,   ax   =   plt . subplots ( )    x   =   data . gender . unique ( )    # Counting 'Males' and 'Females' in the dataset   y   =   data . gender . value_counts ( )    # Plotting the bar graph   ax . bar ( x ,   y )    ax . set_xlabel ( 'Gender' )    ax . set_ylabel ( 'Count' )    plt . show ( )      Fig 1. Bar plot showing the distribution of gender in the dataset From the figure, we can infer that there are more number of males than females in the dataset. Next, we will use the bar graph to visualize the distribution of annual income based on both gender and hours per week (i.e. the number of hours they work per week).  
# For this plot, we will be using the seaborn library as it provides more flexibility with dataframes.   
sns.barplot(data.gender, data['hours-per-week'], hue=data['annual-income'])  
plt.show() 1 2 3 # For this plot, we will be using the seaborn library as it provides more flexibility with dataframes.    sns . barplot ( data . gender ,   data [ 'hours-per-week' ] ,   hue = data [ 'annual-income' ] )    plt . show ( ) So from the figure above, we can infer that males and females with annual income less than 50K tend to work more per week. Countplot This is a seaborn-specific function which is used to plot the count or frequency distribution of each unique observation in the categorical variable. It is similar to a histogram over a categorical rather than quantitative variable. So, let’s plot the number of males and females in the dataset using the countplot function. 
# Using Countplot to count number of males and females in the dataset.  
sns.countplot(data.gender)  
plt.show()  
 1 2 3 4 # Using Countplot to count number of males and females in the dataset.   sns . countplot ( data . gender )    plt . show ( )      Fig 3. Distribution of gender using countplot. Earlier, we plotted the same thing using a bar graph, and it required some external calculations on our part to do so. But we can do the same thing using the countplot function in just a single line of code. Next, we will see how we can use countplot for deeper insights. 
# ‘hue’ is used to visualize the effect of an additional variable to the current distribution.  
sns.countplot(data.gender, hue=data['annual-income'])  
plt.show()  
 1 2 3 4 # ‘hue’ is used to visualize the effect of an additional variable to the current distribution.   sns . countplot ( data . gender ,   hue = data [ 'annual-income' ] )    plt . show ( )      Fig 4. Distribution of gender based on annual income using countplot. From the figure above, we can count that number of males and females whose annual income is  50K. We can see that the approximate number of Males with annual income  50K: 7000 Females with annual income  50K: 1000 So, we can infer that out of 32,500 (approx) people, only 8000 people have income greater than 50K, out of which only 1000 of them are females. Box plot Box plots are widely used in data visualization. Box plots, also known as box and whisker plots are used to visualize variations and compare different categories in a given set of data. It doesn’t display the distribution in detail but is useful in detecting whether a distribution is skewed and detect outliers in the data. In a box and whisker plot: the box spans the interquartile range a vertical line inside the box represents the median two lines outside the box, the whiskers, extending to the highest and the lowest observations represent the possible outliers in the data Fig 5. Box and whisker plot. Let’s use a box and whisker plot to find a correlation between ‘hours-per-week’ and ‘relationship’ based on their annual income. 
# Creating a box plot  
fig, ax = plt.subplots(figsize=(15, 8))  
sns.boxplot(x='relationship', y='hours-per-week', hue='annual-income', data=data, ax=ax)  
ax.set_title('Annual Income of people based on relationship and hours-per-week')  
plt.show()  
 1 2 3 4 5 6 # Creating a box plot   fig ,   ax   =   plt . subplots ( figsize = ( 15 ,   8 ) )    sns . boxplot ( x = 'relationship' ,   y = 'hours-per-week' ,   hue = 'annual-income' ,   data = data ,   ax = ax )    ax . set_title ( 'Annual Income of people based on relationship and hours-per-week' )    plt . show ( )      Fig 6. Using box plot to visualize how people in different relationships earn based on the number of hours they work per week. We can interpret some interesting results from the box plot. People with the same relationship status and an annual income more than 50K often work for more hours per week. Similarly, we can also infer that people who have a child and earn less than 50K tend to have more flexible working hours. 
Apart from this, we can also detect outliers in the data. For example, people with relationship status ‘Not in family’ (see Fig 6.) and an income less than 50K have a large number of outliers at both the high and low ends. This also seems to be logically correct as a person who earns less than 50K annually may work more or less depending on the type of job and employment status. Strip plot Strip plot is a data analysis technique used to plot the sorted values of a variable along one axis. It is used to represent the distribution of a continuous variable with respect to the different levels of a categorical variable. For example, a strip plot can be used to show the distribution of the variable ‘gender’, i.e., males and females, with respect to the number of hours they work each week. A strip plot is also a good complement to a box plot or a violin plot in cases where you want to showcase all the observations along with some representation of the underlying distribution. 
# Using Strip plot to visualize the data.  
fig, ax= plt.subplots(figsize=(10, 8))  
sns.stripplot(data['annual-income'], data['hours-per-week'], jitter=True, ax=ax)  
ax.set_title('Strip plot')  
plt.show()  
 1 2 3 4 5 6 # Using Strip plot to visualize the data.   fig ,   ax =   plt . subplots ( figsize = ( 10 ,   8 ) )    sns . stripplot ( data [ 'annual-income' ] ,   data [ 'hours-per-week' ] ,   jitter = True ,   ax = ax )    ax . set_title ( 'Strip plot' )    plt . show ( )      Fig 7. Strip plot showing the distribution of the earnings based on the number of hours they work per week. In the figure, by looking at the distribution of the data points, we can deduce that most of the people with an annual income greater than 50K work between 40 and 60 hours per week. While those with income less than 50K work can work between 0 and 60 hours per week. Violin plot Sometimes the mean and median may not be enough to understand the distribution of the variable in the dataset. The data may be clustered around the maximum or minimum with nothing in the middle. Box plots are a great way to summarize the statistical information related to the distribution of the data (through the interquartile range, mean, median), but they cannot be used to visualize the variations in the distributions. A violin plot is a combination of a box plot and kernel density function (KDE, described in Part I of this blog series) which can be used to visualize the probability distribution of the data. Violin plots can be interpreted as follows: The outer layer shows the probability distribution of the data points and indicates 95% confidence interval. The thicker the layer, the higher the probability of the data points, and vice-versa. The second layer shows a box plot indicating the interquartile range. The third layer, or the dot, indicates the median of the data. Fig 8. Representation of a violin plot. Let’s now build a violin plot. To start with, we will analyze the distribution of annual income of the people w.r.t. the number of hours they work per week. 
fig, ax = plt.subplots(figsize=(10, 8))  
sns.violinplot(x='annual-income', y='hours-per-week', data=data, ax=ax)  
ax.set_title('Violin plot')  
plt.show()  
 1 2 3 4 5 fig ,   ax   =   plt . subplots ( figsize = ( 10 ,   8 ) )    sns . violinplot ( x = 'annual-income' ,   y = 'hours-per-week' ,   data = data ,   ax = ax )    ax . set_title ( 'Violin plot' )    plt . show ( )      Fig 9. Violin plot showing the distribution of the annual income based on the number of hours they work per week. In Fig 9, the median number working hours per week is same (40 approximately) for both people earning less than 50K and greater than 50K. Although people earning less than 50K can have a varied range of the hours they spend working per week, most of the people who earn more than 50K work in the range of 40 – 80 hours per week. Next, we can visualize the same distribution, but this grouping them according to their gender. 
# Violin plot  
fig, ax = plt.subplots(figsize=(10, 8))  
sns.violinplot(x='annual-income', y='hours-per-week', hue='gender', data=data, ax=ax)  
ax.set_title('Violin plot grouped according to gender')  
plt.show()  
 1 2 3 4 5 6 # Violin plot   fig ,   ax   =   plt . subplots ( figsize = ( 10 ,   8 ) )    sns . violinplot ( x = 'annual-income' ,   y = 'hours-per-week' ,   hue = 'gender' ,   data = data ,   ax = ax )    ax . set_title ( 'Violin plot grouped according to gender' )    plt . show ( )      Fig 10. Distribution of annual income based on the number of hours worked per week and gender. Adding the variable ‘gender’, gives us insights into how much each gender spends working per week based upon their annual income. From the figure, we can infer that males with annual income less than 50K tends to spend more hours working per week than females. But for people earning greater than 50K, both males and females spend an equal amount of hours per week working. Violin plots, although more informative, are less frequently used in data visualization. It may be because they are hard to grasp and understand at first glance. But their ability to represent the variations in the data are making them popular among machine learning and data enthusiasts. PairGrid PairGrid is used to plot the pairwise relationship of all the variables in a dataset. This may seem to be similar to the pairplot we discussed in part I of this series. The difference is that instead of plotting all the plots automatically, as in the case of pairplot, Pair Grid creates a class instance, allowing us to map specific functions to the different sections of the grid. Let’s start by defining the class. 
# Creating an instance of the pair grid plot.  
g = sns.PairGrid(data=data, hue='annual-income')  
 1 2 3 # Creating an instance of the pair grid plot.   g   =   sns . PairGrid ( data = data ,   hue = 'annual-income' )      The variable ‘g’ here is a class instance. If we were to display ‘g’, then we will get a grid of empty plots. There are four grid sections to fill in a Pair Grid: upper triangle, lower triangle, the diagonal, and off-diagonal. To fill all the sections with the same plot, we can simply call ‘g.map’ with the type of plot and plot parameters. 
# Creating a scatter plots for all pairs of variables.  
g = sns.PairGrid(data=data, hue='capital-gain')  
g.map(plt.scatter)  
 1 2 3 4 # Creating a scatter plots for all pairs of variables.   g   =   sns . PairGrid ( data = data ,   hue = 'capital-gain' )    g . map ( plt . scatter )      Fig 11. Scatter plot between each variable pair in the dataset. The ‘g.map_lower’ method only fills the lower triangle of the grid while the ‘g.map_upper’ method only fills the upper triangle of the grid. Similarly, ‘g.map_diag’ and ‘g.map_offdiag’ fills the diagonal and off-diagonal of the grid, respectively. 
#Here we plot scatter plot, histogram and violin plot using Pair grid.  
g = sns.PairGrid(data=data, vars = ['age', 'education-num', 'hours-per-week'])  
# with the help of the vars parameter we can select the variables between which we want the plot to be constructed.  

g.map_lower(plt.scatter, color='red')  
g.map_diag(plt.hist, bins=15)  
g.map_upper(sns.violinplot)  
 1 2 3 4 5 6 7 8 #Here we plot scatter plot, histogram and violin plot using Pair grid.   g   =   sns . PairGrid ( data = data ,   vars   =   [ 'age' ,   'education-num' ,   'hours-per-week' ] )    # with the help of the vars parameter we can select the variables between which we want the plot to be constructed.     g . map_lower ( plt . scatter ,   color = 'red' )    g . map_diag ( plt . hist ,   bins = 15 )    g . map_upper ( sns . violinplot )      Fig 12. Pair Grid showing different plot between the different pair of variables. Thus with the help of Pair Grid, we can visualize the relationship between the three variables (‘hours-per-week’, ‘education-num’ and ‘age’) using three different plots all in the same figure. Pair grid comes in handy when visualizing multiple plots in the same figure. Conclusion Let’s summarize what we learned. So, we started with visualizing the distribution of categorical variables in isolation. Then, we moved on to visualize the relationship between a categorical and a continuous variable. Finally, we explored visualizing relationships when more than two variables are involved. Next week, we will explore how we can visualize unstructured data. Finally, I encourage you to download the given census data (used in this blog) or any other dataset of your choice and play with all the variations of the plots learned in this blog. Till then, Adiós!   2 Shares 2       About the  Author 
 
 Shubham Gupta 
 
 
 
 
 
 
Trying to solve problems through machine learning and help others evolve in the field of machine learning. Currently working as a Data Science Intern at HackerEarth. Highly enthusiastic about autonomous driven systems. Want to stay ahead of the technology curve? Subscribe to our Developers blog 
 
 
 
 
 
 
 Please leave this field empty. 
 Yes, I would like to receive the latest information on emerging technology trends, as well as relevant marketing communication about hackathons, events and challenges.  By signing up you agree to our  Terms of service  and  Privacy policy . 
     Related Posts 
   
 6 things business owners should do before inter... 
 Developers 
 Startup 
 
November 25, 2019 
   
 8 Steps to acing your next system design interview 
 Developers 
 Interview tips 
 
November 19, 2019 
   
 7 steps to improve your data structure and algo... 
 Algorithms 
 Developer Tips 
 Developers 
 
November 13, 2019 
   
 HackerEarth Community—Get ready for spooktacula... 
 Community 
 Developers 
 
October 30, 2019 
   
 What’s the difference between front-end, ... 
 Developer Tips 
 Developers 
 
October 16, 2019 
   
 How to use mock interviews to streamline your t... 
 Developer Tips 
 Developers 
 
September 27, 2019 
   
 Hackathons simplified 
 Developers 
 Hackathons 
 
September 25, 2019 
   
 Top tips to prepare for software engineering in... 
 Developer Tips 
 Interview tips 
 
September 18, 2019 
   
 Do you really need a degree to build a career i... 
 Developer Tips 
 Interview tips 
 
September 6, 2019 
   
 R Algorithms in AI and computing forces working... 
 Developers 
 Machine Learning 
 R 
 
June 25, 2019         comments powered by Disqus.           Blog Engineering Blog Updates & Releases Team Careers In the Press 
 
© 2019 HackerEarth Terms & Conditions Privacy "," Bar graph,Countplot,Box plot,None,Violin plot,None,None,", http://engineering.hackerearth.com/http://news.hackerearth.com/
16,Data visualization for beginners – Part 1,https://www.hackerearth.com/blog/developers/data-visualization-techniques/,"Data visualization for beginners - Part 1 | HackerEarth Blog 
 Hackathons Technical Recruitment For Developers 
 
 
 
 Recruitment Blog Developers Blog Webinars Algorithms Competitive Programming Machine Learning Interview Tips More Categories ≫ 
 Menu 
 
 Toggle navigation 
 
 
 
 Recruitment Blog Developers Blog Webinars 
 
 
 
   
Data visualization for beginners – Part 1 
 Big Data 
 Data Science 
 Developers 
 Machine Learning 
 Python 
 May 10, 2018 
    7   mins This is a series of blogs dedicated to different data visualization techniques used in various domains of machine learning. Data Visualization is a critical step for building a powerful and efficient machine learning model. It helps us to better understand the data, generate better insights for feature engineering, and, finally, make better decisions during modeling and training of the model. For this blog, we will use the seaborn and matplotlib libraries to generate the visualizations. Matplotlib is a MATLAB-like plotting framework in python, while seaborn is a python visualization library based on matplotlib. It provides a high-level interface for producing statistical graphics. In this blog, we will explore different statistical graphical techniques that can help us in effectively interpreting and understanding the data. Although all the plots using the seaborn library can be built using the matplotlib library, we usually prefer the seaborn library because of its ability to handle DataFrames. We will start by importing the two libraries. Here is the guide to installing the matplotlib library and seaborn library. (Note that I’ll be using matplotlib and seaborn libraries interchangeably depending on the plot.) 
### Importing necessary library  
import random  
import numpy as np  
import pandas as pd  
import seaborn as sns  
import matplotlib.pyplot as plt  
%matplotlib inline  
 1 2 3 4 5 6 7 8 9 ### Importing necessary library   import  random   import  numpy  as   np   import  pandas  as   pd   import  seaborn  as   sns   import  matplotlib . pyplot  as   plt    % matplotlib   inline        Simple Plot Let’s begin by plotting a simple line plot which is used to plot a mathematical. A line plot is used to plot the relationship or dependence of one variable on another. Say, we have two variables ‘x’ and ‘y’ with the following values: 
x = np.array([ 0, 0.53, 1.05, 1.58, 2.11, 2.63, 3.16, 3.68, 4.21,  
        4.74, 5.26, 5.79, 6.32, 6.84])  
y = np.array([ 0, 0.51, 0.87, 1. , 0.86, 0.49, -0.02, -0.51, -0.88,  
        -1. , -0.85, -0.47, 0.04, 0.53])  
 1 2 3 4 5 x   =   np . array ( [   0 ,   0.53 ,   1.05 ,   1.58 ,   2.11 ,   2.63 ,   3.16 ,   3.68 ,   4.21 ,             4.74 ,   5.26 ,   5.79 ,   6.32 ,   6.84 ] )    y   =   np . array ( [   0 ,   0.51 ,   0.87 ,   1.   ,   0.86 ,   0.49 ,   - 0.02 ,   - 0.51 ,   - 0.88 ,             - 1.   ,   - 0.85 ,   - 0.47 ,   0.04 ,   0.53 ] )      To plot the relationship between the two variables, we can simply call the plot function. 
### Creating a figure to plot the graph.  
fig, ax = plt.subplots()  
ax.plot(x, y)  
ax.set_xlabel('X data')  
ax.set_ylabel('Y data')  
ax.set_title('Relationship between variables X and Y')  
plt.show() # display the graph  
### if %matplotlib inline has been invoked already, then plt.show() is automatically invoked and the plot is displayed in the same window.  
 1 2 3 4 5 6 7 8 9 ### Creating a figure to plot the graph.   fig ,   ax   =   plt . subplots ( )    ax . plot ( x ,   y )    ax . set_xlabel ( 'X data' )    ax . set_ylabel ( 'Y data' )    ax . set_title ( 'Relationship between variables X and Y' )    plt . show ( )   # display the graph   ### if %matplotlib inline has been invoked already, then plt.show() is automatically invoked and the plot is displayed in the same window.     Fig. 1. Line Plot between X and Y Here, we can see that the variables ‘x’ and ‘y’ have a sinusoidal relationship. Generally, .plot() function is used to find any mathematical relationship between the variables. Histogram A histogram is one of the most frequently used data visualization techniques in machine learning. It represents the distribution of a continuous variable over a given interval or period of time. Histograms plot the data by dividing it into intervals called ‘bins’. It is used to inspect the underlying frequency distribution (eg. Normal distribution), outliers, skewness, etc. Let’s assume some data ‘x’ and analyze its distribution and other related features. 
### Let 'x' be the data with 1000 random points.   
x = np.random.randn(1000)  
 1 2 3 ### Let 'x' be the data with 1000 random points.    x   =   np . random . randn ( 1000 )      Let’s plot a histogram to analyze the distribution of ‘x’. 
plt.hist(x)  
plt.xlabel('Intervals')  
plt.ylabel('Value')  
plt.title('Distribution of the variable x')  
plt.show()   1 2 3 4 5 plt . hist ( x )    plt . xlabel ( 'Intervals' )    plt . ylabel ( 'Value' )    plt . title ( 'Distribution of the variable x' )    plt . show ( )    Fig 2. Histogram showing the distribution of the variable ‘x’. The above plot shows a normal distribution, i.e., the variable ‘x’ is normally distributed. We can also infer that the distribution is somewhat negatively skewed. We usually control the ‘bins’ parameters to produce a distribution with smooth boundaries. For example, if we set the number of ‘bins’ too low, say bins=5, then most of the values get accumulated in the same interval, and as a result they produce a distribution which is hard to predict. 
plt.hist(x, bins=5)  
plt.xlabel('Intervals')  
plt.ylabel('Value')  
plt.title('Distribution of the variable x')  
plt.show()  
 1 2 3 4 5 6 plt . hist ( x ,   bins = 5 )    plt . xlabel ( 'Intervals' )    plt . ylabel ( 'Value' )    plt . title ( 'Distribution of the variable x' )    plt . show ( )      Fig 3. Histogram with low number of bins. Similarly, if we increase the number of ‘bins’ to a high value, say bins=1000, each value will act as a separate bin, and as a result the distribution seems to be too random. 
plt.hist(x, bins=1000)  
plt.xlabel('Intervals')  
plt.ylabel('Value')  
plt.title('Distribution of the variable x')  
plt.show()  
 1 2 3 4 5 6 plt . hist ( x ,   bins = 1000 )    plt . xlabel ( 'Intervals' )    plt . ylabel ( 'Value' )    plt . title ( 'Distribution of the variable x' )    plt . show ( )      Fig. 4. Histogram with a large number of bins. Kernel Density Function Before we dive into understanding KDE, let’s understand what parametric and non-parametric data are. Parametric Data: When the data is assumed to have been drawn from a particular distribution and some parametric test can be applied to it Non-Parametric Data: When we have no knowledge about the population and the underlying distribution Kernel Density Function is the non-parametric way of representing the probability distribution function of a random variable. It is used when the parametric distribution of the data doesn’t make much sense, and you want to avoid making assumptions about the data. The kernel density estimator is the estimated pdf of a random variable. It is defined as 
 
Similar to histograms, KDE plots the density of observations on one axis with height along the other axis. 
### We will use the seaborn library to plot KDE.  
### Let's assume random data stored in variable 'x'.  
fig, ax = plt.subplots()  
### Generating random data  
x = np.random.rand(200)   
sns.kdeplot(x, shade=True, ax=ax)  
plt.show()  
 1 2 3 4 5 6 7 8 ### We will use the seaborn library to plot KDE.   ### Let's assume random data stored in variable 'x'.   fig ,   ax   =   plt . subplots ( )    ### Generating random data   x   =   np . random . rand ( 200 )     sns . kdeplot ( x ,   shade = True ,   ax = ax )    plt . show ( )      Fig 5. KDE plot for the random variable ‘x’. Distplot combines the function of the histogram and the KDE plot into one figure. 
### Generating a random sample  
x = np.random.random_sample(1000)  
### Plotting the distplot  
sns.distplot(x, bins=20)  
 1 2 3 4 5 ### Generating a random sample   x   =   np . random . random_sample ( 1000 )    ### Plotting the distplot   sns . distplot ( x ,   bins = 20 )      Fig 6. Displot for the random variable ‘x’. So, the distplot function plots the histogram and the KDE for the sample data in the same figure. You can tune the parameters of the displot to only display the histogram or kde or both. Distplot comes in handy when you want to visualize how close your assumption about the distribution of the data is to the actual distribution. Scatter Plot Scatter plots are used to determine the relationship between two variables. They show how much one variable is affected by another. It is the most commonly used data visualization technique and helps in drawing useful insights when comparing two variables. The relationship between two variables is called correlation. If the data points fit a line or curve with a positive slope, then the two variables are said to show positive correlation. If the line or curve has a negative slope, then the variables are said to have a negative correlation. A perfect positive correlation has a value of 1 and a perfect negative correlation has a value of -1. The closer the value is to 1 or -1, the stronger the relationship between the variables. The closer the value is to 0, the weaker the correlation. For our example, let’s define three variables ‘x’, ‘y’, and ‘z’, where ‘x’ and ‘z’ are randomly generated data and ‘y’ is defined as 
 We will use a scatter plot to find the relationship between the variables ‘x’ and ‘y’. 
### Let's define the variables we want to find the relationship between.  
x = np.random.rand(500)  
z = np.random.rand(500)  
### Defining the variable 'y'  
y = x * (z + x)  
fig, ax = plt.subplots()  
ax.set_xlabel('X')  
ax.set_ylabel('Y')  
ax.set_title('Scatter plot between X and Y')  
plt.scatter(x, y, marker='.')  
plt.show()  
 1 2 3 4 5 6 7 8 9 10 11 12 ### Let's define the variables we want to find the relationship between.   x   =   np . random . rand ( 500 )    z   =   np . random . rand ( 500 )    ### Defining the variable 'y'   y   =   x *   ( z   +   x )    fig ,   ax   =   plt . subplots ( )    ax . set_xlabel ( 'X' )    ax . set_ylabel ( 'Y' )    ax . set_title ( 'Scatter plot between X and Y' )    plt . scatter ( x ,   y ,   marker = '.' )    plt . show ( )      Fig 7. Scatter plot between X and Y. From the figure above we can see that the data points are very close to each other and also if we fit a curve, along with the points, it will have a positive slope. Therefore, we can infer that there is a strong positive correlation between the values of the variable ‘x’ and variable ‘y’. Also, we can see that the curve that best fits the graph is quadratic in nature and this can be confirmed by looking at the definition of the variable ‘y’. Joint Plot Jointplot is seaborn library specific and can be used to quickly visualize and analyze the relationship between two variables and describe their individual distributions on the same plot. Let’s start with using joint plot for producing the scatter plot. 
### Defining the data.   
mean, covar = [0, 1], [[1, 0,], [0, 50]]  
### Drawing random samples from a multivariate normal distribution.  
### Two random variables are created, each containing 500 values, with the given mean and covariance.  
data = np.random.multivariate_normal(mean, covar, 500)  
### Storing the variables in a dataframe.  
df = pd.DataFrame(data=data, columns=['X', 'Y'])  
 1 2 3 4 5 6 7 8 ### Defining the data.    mean ,   covar   =   [ 0 ,   1 ] ,   [ [ 1 ,   0 , ] ,   [ 0 ,   50 ] ]    ### Drawing random samples from a multivariate normal distribution.   ### Two random variables are created, each containing 500 values, with the given mean and covariance.   data   =   np . random . multivariate_normal ( mean ,   covar ,   500 )    ### Storing the variables in a dataframe.   df   =   pd . DataFrame ( data = data ,   columns = [ 'X' ,   'Y' ] )      
### Joint plot between X and Y  
sns.jointplot(df.X, df.Y, kind='scatter')  
plt.show()  
 1 2 3 4 ### Joint plot between X and Y   sns . jointplot ( df . X ,   df . Y ,   kind = 'scatter' )    plt . show ( )      Fig 8. Joint plot (scatter plot) between X and Y. Next, we can use the joint point to find the best line or curve that fits the plot. 
sns.jointplot(df.X, df.Y, kind='reg')  
plt.show()  
 1 2 3 sns . jointplot ( df . X ,   df . Y ,   kind = 'reg' )    plt . show ( )      Fig 9. Using joint plot to plot the regression line that best fits the data points. Apart from this, jointplot can also be used to plot ‘kde’, ‘hex plot’, and ‘residual plot’. PairPlot We can use scatter plot to plot the relationship between two variables. But what if the dataset has more than two variables (which is quite often the case), it can be a tedious task to visualize the relationship between each variable with the other variables. The seaborn pairplot function does the same thing for us and in just one line of code. It is used to plot multiple pairwise bivariate (two variable) distribution in a dataset. It creates a matrix and plots the relationship for each pair of columns. It also draws a univariate distribution for each variable on the diagonal axes. 
### Loading a dataset from the sklearn toy datasets  
from sklearn.datasets import load_linnerud  
### Loading the data  
linnerud_data = load_linnerud()  
### Extracting the column data  
data = linnerud_data.data  
 1 2 3 4 5 6 7 ### Loading a dataset from the sklearn toy datasets   from  sklearn . datasets  import  load_linnerud    ### Loading the data   linnerud_data   =   load_linnerud ( )    ### Extracting the column data   data   =   linnerud_data . data      Sklearn stores data in the form of a numpy array and not data frames, thereby storing the data in a dataframe. 
### Creating a dataframe  
data = pd.DataFrame(data=data, columns=diabetes_data.feature_names)  
### Plotting a pairplot  
sns.pairplot(data=data)  
 1 2 3 4 5 ### Creating a dataframe   data   =   pd . DataFrame ( data = data ,   columns = diabetes_data . feature_names )    ### Plotting a pairplot   sns . pairplot ( data = data )      Fig 10. Pair plot showing the relationships between the columns of the dataset. So, in the graph above, we can see the relationships between each of the variables with the other and thus infer which variables are most correlated. Conclusion Visualizations play an important role in data analysis and exploration. In this blog, we got introduced to different kinds of plots used for data analysis of continuous variables. Next week, we will explore the various data visualization techniques that can be applied to categorical variables or variables with discrete values. Next, I encourage you to download the iris dataset or any other dataset of your choice and apply and explore the techniques learned in this blog. Have anything to say? Feel free to comment below for any questions, suggestions, and discussions related to this article. Till then, Sayōnara.   2 Shares 2       About the  Author 
 
 Shubham Gupta 
 
 
 
 
 
 
Trying to solve problems through machine learning and help others evolve in the field of machine learning. Currently working as a Data Science Intern at HackerEarth. Highly enthusiastic about autonomous driven systems. Want to stay ahead of the technology curve? Subscribe to our Developers blog 
 
 
 
 
 
 
 Please leave this field empty. 
 Yes, I would like to receive the latest information on emerging technology trends, as well as relevant marketing communication about hackathons, events and challenges.  By signing up you agree to our  Terms of service  and  Privacy policy . 
     Related Posts 
   
 6 things business owners should do before inter... 
 Developers 
 Startup 
 
November 25, 2019 
   
 8 Steps to acing your next system design interview 
 Developers 
 Interview tips 
 
November 19, 2019 
   
 7 steps to improve your data structure and algo... 
 Algorithms 
 Developer Tips 
 Developers 
 
November 13, 2019 
   
 HackerEarth Community—Get ready for spooktacula... 
 Community 
 Developers 
 
October 30, 2019 
   
 What’s the difference between front-end, ... 
 Developer Tips 
 Developers 
 
October 16, 2019 
   
 How to use mock interviews to streamline your t... 
 Developer Tips 
 Developers 
 
September 27, 2019 
   
 Hackathons simplified 
 Developers 
 Hackathons 
 
September 25, 2019 
   
 Top tips to prepare for software engineering in... 
 Developer Tips 
 Interview tips 
 
September 18, 2019 
   
 Do you really need a degree to build a career i... 
 Developer Tips 
 Interview tips 
 
September 6, 2019 
   
 R Algorithms in AI and computing forces working... 
 Developers 
 Machine Learning 
 R 
 
June 25, 2019         comments powered by Disqus.           Blog Engineering Blog Updates & Releases Team Careers In the Press 
 
© 2019 HackerEarth Terms & Conditions Privacy "," None,None,None,None,None,None,None,", http://engineering.hackerearth.com/http://news.hackerearth.com/
17,11 open source frameworks for AI and machine learning models,https://www.hackerearth.com/blog/developers/11-open-source-frameworks-ai-machine-learning-models/,"11 open source frameworks for AI and machine learning models | HackerEarth Blog 
 Hackathons Technical Recruitment For Developers 
 
 
 
 Recruitment Blog Developers Blog Webinars Algorithms Competitive Programming Machine Learning Interview Tips More Categories ≫ 
 Menu 
 
 Toggle navigation 
 
 
 
 Recruitment Blog Developers Blog Webinars 
 
 
 
   
11 open source frameworks for AI and machine learning models 
 Developers 
 Machine Learning 
 February 21, 2018 
    4   mins The meteoric rise of artificial intelligence in the last decade has spurred a huge demand for AI and ML skills in today’s job market. ML-based technology is now used in almost every industry vertical from finance to healthcare. In this blog, we have compiled a list of best frameworks and libraries that you can use to build machine learning models. 1) TensorFlow 
 Developed by Google, TensorFlow is an open-source software library built for deep learning or artificial neural networks. With TensorFlow, you can create neural networks and computation models using flowgraphs. It is one of the most well-maintained and popular open-source libraries available for deep learning. The TensorFlow framework is available in C++ and Python. Other similar deep learning frameworks that are based on Python include  Theano ,  Torch , Lasagne, Blocks, MXNet, PyTorch, and  Caffe . You can use TensorBoard for easy visualization and see the computation pipeline. Its flexible architecture allows you to deploy easily on different kinds of devices 
On the negative side, TensorFlow does not have symbolic loops and does not support distributed learning. Further, it does not support Windows. 2)Theano 
 Theano is a Python library designed for deep learning. Using the tool, you can define and evaluate mathematical expressions including multi-dimensional arrays. Optimized for GPU, the tool comes with features including integration with NumPy, dynamic C code generation, and symbolic differentiation. However, to get a high level of abstraction, the tool will have to be used with other libraries such as Keras, Lasagne, and Blocks. The tool supports platforms such as Linux, Mac OS X, and Windows. 3) Torch 
 The Torch is an easy to use open-source computing framework for ML algorithms. The tool offers an efficient GPU support, N-dimensional array, numeric optimization routines, linear algebra routines, and routines for indexing, slicing, and transposing. Based on a scripting language called Lua, the tool comes with an ample number of pre-trained models. This flexible and efficient ML research tool supports major platforms such as Linux, Android, Mac OS X, iOS, and Windows. 4) Caffe 
 Caffe is a popular deep learning tool designed for building apps. Created by  Yangqing Jia for a project during his Ph.D. at UC Berkeley, the tool has a good Matlab/C++/ Python interface. The tool allows you to quickly apply neural networks to the problem using text, without writing code. Caffe partially supports multi-GPU training. The tool supports operating systems such as Ubuntu, Mac OS X, and Windows. 5) Microsoft CNTK 
 Microsoft cognitive toolkit is one of the fastest deep learning frameworks with C#/C++/Python interface support. The open-source framework comes with powerful C++ API and is faster and more accurate than TensorFlow. The tool also supports distributed learning with built-in data readers. It supports algorithms such as Feed Forward, CNN, RNN, LSTM, and Sequence-to-Sequence. The tool supports Windows and Linux. 6) Keras 
 Written in Python, Keras is an open-source library designed to make the creation of new DL models easy. This high-level neural network API can be run on top of deep learning frameworks like TensorFlow, Microsoft CNTK, etc.  Known for its user-friendliness and modularity, the tool is ideal for fast prototyping. The tool is optimized for both CPU and GPU. 7) SciKit-Learn 
 SciKit-Learn is an open-source Python library designed for machine learning. The tool based on libraries such as NumPy, SciPy, and matplotlib can be used for data mining and data analysis. SciKit-Learn is equipped with a variety of ML models including linear and logistic regressors, SVM classifiers, and random forests. The tool can be used for multiple ML tasks such as classification, regression, and clustering. The tool supports operating systems like Windows and Linux. On the downside, it is not very efficient with GPU. 8)Accord.NET 
 Written in C#, Accord.NET is an ML framework designed for building production-grade computer vision, computer audition, signal processing and statistics applications. It is a well-documented ML framework that makes audio and image processing easy. The tool can be used for numerical optimization, artificial neural networks, and visualization. It supports Windows. 9)Spark MLIib 
 Apache Spark’s MLIib is an ML library that can be used in Java, Scala, Python, and R. Designed for processing large-scale data, this powerful library comes with many algorithms and utilities such as classification, regression, and clustering. The tool interoperates with NumPy in Python and R libraries. It can be easily plugged into Hadoop workflows. 10) Azure ML Studio 
 Azure ML studio is a modern cloud platform for data scientists. It can be used to develop ML models in the cloud. With a wide range of modeling options and algorithms, Azure is ideal for building larger ML models. The service provides 10GB of storage space per account. It can be used with R and Python programs. 11) Amazon Machine Learning 
 Amazon Machine Learning (AML) is an ML service that provides tools and wizards for creating ML models. With visual aids and easy-to-use analytics, AML aims to make ML more accessible to developers. AML can be connected to data stored in Amazon S3, Redshift, or RDS. Machine learning frameworks come with pre-built components that are easy to understand and code. A good ML framework thus reduces the complexity of defining ML models. With these open-source ML frameworks, you build your ML models easily and quickly. Know an ML framework that should be on this list? Share them in comments below.   3 Shares 3       About the  Author 
 
 Tharika Tellicherry 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Marketing professional, blogger, movie buff, music fan, traveler, collector of memories, and tic-tac bottles. Want to stay ahead of the technology curve? Subscribe to our Developers blog 
 
 
 
 
 
 
 Please leave this field empty. 
 Yes, I would like to receive the latest information on emerging technology trends, as well as relevant marketing communication about hackathons, events and challenges.  By signing up you agree to our  Terms of service  and  Privacy policy . 
     Related Posts 
   
 6 things business owners should do before inter... 
 Developers 
 Startup 
 
November 25, 2019 
   
 8 Steps to acing your next system design interview 
 Developers 
 Interview tips 
 
November 19, 2019 
   
 7 steps to improve your data structure and algo... 
 Algorithms 
 Developer Tips 
 Developers 
 
November 13, 2019 
   
 HackerEarth Community—Get ready for spooktacula... 
 Community 
 Developers 
 
October 30, 2019 
   
 What’s the difference between front-end, ... 
 Developer Tips 
 Developers 
 
October 16, 2019 
   
 How to use mock interviews to streamline your t... 
 Developer Tips 
 Developers 
 
September 27, 2019 
   
 Hackathons simplified 
 Developers 
 Hackathons 
 
September 25, 2019 
   
 Top tips to prepare for software engineering in... 
 Developer Tips 
 Interview tips 
 
September 18, 2019 
   
 Do you really need a degree to build a career i... 
 Developer Tips 
 Interview tips 
 
September 6, 2019 
   
 R Algorithms in AI and computing forces working... 
 Developers 
 Machine Learning 
 R 
 
June 25, 2019         comments powered by Disqus.           Blog Engineering Blog Updates & Releases Team Careers In the Press 
 
© 2019 HackerEarth Terms & Conditions Privacy ", , http://deeplearning.net/software/theano/http://torch.ch/http://caffe.berkeleyvision.org/http://www.deeplearning.net/software/theano/http://torch.ch/http://caffe.berkeleyvision.org/http://scikit-learn.org/http://accord-framework.net/http://engineering.hackerearth.com/http://news.hackerearth.com/
18,Leverage machine learning to amplify your social impact,https://www.hackerearth.com/blog/developers/machine-learning-amplify-social-impact/,"Leverage machine learning to amplify your social impact | HackerEarth Blog 
 Hackathons Technical Recruitment For Developers 
 
 
 
 Recruitment Blog Developers Blog Webinars Algorithms Competitive Programming Machine Learning Interview Tips More Categories ≫ 
 Menu 
 
 Toggle navigation 
 
 
 
 Recruitment Blog Developers Blog Webinars 
 
 
 
   
Leverage machine learning to amplify your social impact 
 Community 
 Developers 
 Machine Learning 
 January 29, 2018 
    2   mins “Data is abundant and cheap but knowledge is scarce and expensive.” In the last few years, there has been a data revolution that has transformed the way we source, capture, and interact with data. From fortune 500 firms to start-ups, healthcare to fintech, m achine learning and data science have become an integral part of everyday operations of most companies. Of all the sectors, the social good sector has not seen the push the other sectors have. It is not that the machine learning and data science techniques don’t work for this sector, but the lack of financial support and staff has stopped them from creating their special brand of magic here.  At HackerEarth, we intend to tackle this issue by sponsoring machine learning and data science challenges for social good.  Machine learning at HackerEarth Even though machine learning (ML) is a new wing at HackerEarth, this is the fastest growing unit in the company. Also, over the past year, we have grown to a community of 200K+ machine learning and data science enthusiasts. We have conducted 50+ challenges across sectors with an average of 6500+ people participating in each. The initiative The “Machine Learning Challenges for Social Good” initiative is focused toward bringing interesting real-world data problems faced by nonprofits and governmental and non-governmental organizations to the machine learning and data science community’s notice.  This is a win-win for both communities because the nonprofits and governmental and non-governmental organizations get their challenges addressed, and the machine learning and data science community gets to hone their skills while being agents of change.  Our role HackerEarth will contribute by  Working with the organizations to identify  and prepare the data set most suitable for the initiative Hosting the challenge which includes the following (but not limited to) Creating a problem statement with the given dataset Finding support data sets if required  Framing the best evaluation metric to choose the winners Promoting this to our developer community and inviting programmers to contribute to the cause Sharing the winning approaches and ML models built, which the organizations can use Sponsoring prizes  Are you a nonprofit or a governmental/non-governmental organization with a business/social problem for which primary or secondary data is available? If yes, please mail us at  social@hackerearth.com .  [Please use subject line “Reg: Machine Learning for Social Good | {Your Organization Name}]   1 Share 1       About the  Author 
 
 Narendhiran Sundaresan 
 
 
 
 
 
 
 
 
 Want to stay ahead of the technology curve? Subscribe to our Developers blog 
 
 
 
 
 
 
 Please leave this field empty. 
 Yes, I would like to receive the latest information on emerging technology trends, as well as relevant marketing communication about hackathons, events and challenges.  By signing up you agree to our  Terms of service  and  Privacy policy . 
     Related Posts 
   
 6 things business owners should do before inter... 
 Developers 
 Startup 
 
November 25, 2019 
   
 8 Steps to acing your next system design interview 
 Developers 
 Interview tips 
 
November 19, 2019 
   
 7 steps to improve your data structure and algo... 
 Algorithms 
 Developer Tips 
 Developers 
 
November 13, 2019 
   
 HackerEarth Community—Get ready for spooktacula... 
 Community 
 Developers 
 
October 30, 2019 
   
 What’s the difference between front-end, ... 
 Developer Tips 
 Developers 
 
October 16, 2019 
   
 How to use mock interviews to streamline your t... 
 Developer Tips 
 Developers 
 
September 27, 2019 
   
 Hackathons simplified 
 Developers 
 Hackathons 
 
September 25, 2019 
   
 Top tips to prepare for software engineering in... 
 Developer Tips 
 Interview tips 
 
September 18, 2019 
   
 Do you really need a degree to build a career i... 
 Developer Tips 
 Interview tips 
 
September 6, 2019 
   
 R Algorithms in AI and computing forces working... 
 Developers 
 Machine Learning 
 R 
 
June 25, 2019         comments powered by Disqus.           Blog Engineering Blog Updates & Releases Team Careers In the Press 
 
© 2019 HackerEarth Terms & Conditions Privacy "," Machine learning at HackerEarth,The initiative,Our role,", http://engineering.hackerearth.com/http://news.hackerearth.com/
19,Artificial  Intelligence 101: How to get started,https://www.hackerearth.com/blog/developers/artificial-intelligence-101-how-to-get-started/,"Artificial Intelligence 101: How to get started | HackerEarth Blog 
 Hackathons Technical Recruitment For Developers 
 
 
 
 Recruitment Blog Developers Blog Webinars Algorithms Competitive Programming Machine Learning Interview Tips More Categories ≫ 
 Menu 
 
 Toggle navigation 
 
 
 
 Recruitment Blog Developers Blog Webinars 
 
 
 
   
Artificial  Intelligence 101: How to get started 
 Artificial Intelligence 
 Developers 
 Machine Learning 
 Python 
 October 1, 2017 
    4   mins What is Artificial Intelligence (AI)? Are you thinking of Chappie, Terminator, and Lucy? Sentient, self-aware robots are closer to becoming a reality than you think. Developing computer systems that equal or exceed human intelligence is the crux of artificial intelligence. Artificial Intelligence (AI) is the study of computer science focusing on developing software or machines that exhibit human intelligence. A simple enough definition, right? Obviously, there is a lot more to it. AI is a broad topic ranging from simple calculators to self-steering technology to something that might radically change the future. Goals and Applications of AI The primary  goals of AI  include deduction and reasoning, knowledge representation, planning, natural language processing (NLP), learning, perception, and the ability to manipulate and move objects. Long-term goals of AI research include achieving Creativity, Social Intelligence, and General (human level) Intelligence. AI has heavily influenced different sectors that we may not recognize. Ray Kurzweil says “Many thousands of  AI applications  are deeply embedded in the infrastructure of every industry.” John McCarthy, one of the founders of AI, once said that “as soon as it works, no one calls it AI anymore.” Broadly, AI is classified into the following: Source: Bluenotes Types of AI While there are various forms of AI as it’s a broad concept, we can divide it into the following three categories based on AI’s capabilities: Weak AI,  which is also referred to as Narrow AI, focuses on one task. There is no self-awareness or genuine intelligence in case of a weak AI. iOS Siri is a good example of a weak AI combining several weak AI techniques to function. It can do a lot of things for the user, and you’ll see how “narrow” it exactly is when you try having conversations with the virtual assistant. Strong AI,  which is also referred to as True AI, is a computer that is as smart as the human brain. This sort of AI will be able to perform all tasks that a human could do. There is a lot of research going on in this field, but we still have much to do. You should be imagining Matrix or I, Robot here. Artificial Superintelligence  is going to blow your mind if Strong AI impressed you.  Nick Bostrom, leading AI thinker, defines it as “an intellect that is much smarter than the best human brains in practically every field, including scientific creativity, general wisdom and social skills.” Artificial Superintelligence is the reason why many prominent scientists and technologists, including Stephen Hawking and Elon Musk, have raised concerns about the possibility of human extinction. How can you get started? The first thing you need to do is learn a programming language. Though there are a lot of languages that you can start with, Python is what many prefer to start with because its libraries are better suited to Machine Learning. Here are some good resources for Python: CodeAcademy  Learn Python the hard way Coursera Python Introduction to Computer science  Introduction to Bots A  BOT  is the most basic example of a weak AI that can do automated tasks on your behalf. Chatbots were one of the first automated programs to be called “bots.” You need AI and ML for your chatbots. Web crawlers used by Search Engines like Google are a perfect example of a sophisticated and advanced BOT. You should learn the following before you start programming bots to make your life easier. xpath  – This will help you to inspect and target HTML and build your bot from what you see there. regex  – This will help you to process the data you feed your bot by cleaning up or targeting (or both) the parts that matter to your logic. REST  – This is really important as you will eventually work with APIs. You can use requests to do this. How can you build your first bot? You can start learning how to create bots in Python through the following tutorial in the simplest way. How to build a Python Bot You can also start by using APIs and tools that offer the ability to build end-user applications. This helps you by actually building something without worrying too much about the theory at first. Some of the APIs that you can use for this are: Google Cloud Prediction API Documentation DiffBot Machine Learning for Language Toolkit Scrapy Wolfram Alpha API Here’s a listing of a few BOT problems for you to practice and try out before you attempt the ultimate challenge. Tic Tac Toe Hex Dots & Boxes What now? Once you have a thorough understanding of your preferred programming language and enough practice with the basics, you should start to learn more about Machine Learning. In  Python , start learning Scikit-learn, NLTK, SciPy, PyBrain, and Numpy libraries which will be useful while writing Machine Learning algorithms.You need to know Advanced Math and as well. Here is a list of resources for you to learn and practice: A Visual Introduction to Machine Learning Machine Learning  ( By Andrew Ng) Machine Learning Lectures  (Tom Mitchell) Artificial Intelligence  (edX) (Specially for practice exercise in Python) Intro to Statistics  Intro to Artificial Intelligence   (Includes Logic and Robotics) Artificial Intelligence Here are a few more valuable links: Artificial Intelligence: A Modern Approach AI Algorithms, Data Structures, and Idioms in Prolog, Lisp, and Java Computational Cognitive Neuroscience Computational Explorations in Cognitive Neuroscience 13 Free self-study books on Mathematics, Machine learning, and Deep learning 13 Free training courses on Machine learning and Artificial Intelligence Data Tools Deep Dive: Machine Learning You should also take part in various AI and BOT Programming Contests at different places on the Internet: Kaggle Coding Game HackerEarth Robocup Before you start learning and contributing to the field of AI, read how  AI is rapidly changing the world . Popular posts like this: How to hire a data scientist 5 must-have proctoring tips for a developer assessment platform How to ensure your tech talent pool is poaching proof   135 Shares 135       About the  Author 
 
 Shashank Chaudhary 
AI enthusiast. Dreamer. Serial offender. Interested in almost all things science and tech! Want to stay ahead of the technology curve? Subscribe to our Developers blog 
 
 
 
 
 
 
 Please leave this field empty. 
 Yes, I would like to receive the latest information on emerging technology trends, as well as relevant marketing communication about hackathons, events and challenges.  By signing up you agree to our  Terms of service  and  Privacy policy . 
     Related Posts 
   
 6 things business owners should do before inter... 
 Developers 
 Startup 
 
November 25, 2019 
   
 8 Steps to acing your next system design interview 
 Developers 
 Interview tips 
 
November 19, 2019 
   
 7 steps to improve your data structure and algo... 
 Algorithms 
 Developer Tips 
 Developers 
 
November 13, 2019 
   
 HackerEarth Community—Get ready for spooktacula... 
 Community 
 Developers 
 
October 30, 2019 
   
 What’s the difference between front-end, ... 
 Developer Tips 
 Developers 
 
October 16, 2019 
   
 How to use mock interviews to streamline your t... 
 Developer Tips 
 Developers 
 
September 27, 2019 
   
 Hackathons simplified 
 Developers 
 Hackathons 
 
September 25, 2019 
   
 Top tips to prepare for software engineering in... 
 Developer Tips 
 Interview tips 
 
September 18, 2019 
   
 Do you really need a degree to build a career i... 
 Developer Tips 
 Interview tips 
 
September 6, 2019 
   
 R Algorithms in AI and computing forces working... 
 Developers 
 Machine Learning 
 R 
 
June 25, 2019         comments powered by Disqus.           Blog Engineering Blog Updates & Releases Team Careers In the Press 
 
© 2019 HackerEarth Terms & Conditions Privacy ", , http://learnpythonthehardway.org/http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-00-introduction-to-computer-science-and-programming-fall-2008/http://www.512tech.com/technology/bots-101-what-you-need-know-about-chatbots-and-digital-assistants/WFPvQUyYbgo54y2i3RZP7K/http://regexr.com/http://docs.python-requests.org/en/latest/index.htmlhttp://code.tutsplus.com/tutorials/how-to-build-a-python-bot-that-can-play-web-games--active-11117http://www.diffbot.com/products/http://mallet.cs.umass.edu/http://scrapy.org/http://products.wolframalpha.com/api/http://www.r2d3.us/visual-intro-to-machine-learning-part-1/http://aima.cs.berkeley.edu/http://wps.aw.com/wps/media/objects/5771/5909832/PDF/Luger_0136070477_1.pdfhttp://psych.colorado.edu/~oreilly/comp_ex_cog_neuro.htmlhttp://www.codingame.com/http://www.robocup.org/http://engineering.hackerearth.com/http://news.hackerearth.com/
